{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our library\n",
    "from svetlanna import SimulationParameters\n",
    "from svetlanna.parameters import ConstrainedParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our library\n",
    "from svetlanna import Wavefront\n",
    "from svetlanna import elements\n",
    "from svetlanna.setup import LinearOpticalSetup\n",
    "from svetlanna.detector import Detector, DetectorProcessorClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna.transforms import ToWavefront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets of wavefronts\n",
    "from src.wf_datasets import DatasetOfWavefronts\n",
    "from src.wf_datasets import WavefrontsDatasetSimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simulation Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Defining simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_frequency = 0.4 * 1e12 # [Hz]\n",
    "c_const = 299_792_458  # [m / s]\n",
    "working_wavelength = c_const / working_frequency  # [m]\n",
    "\n",
    "# neuron size (square)\n",
    "neuron_size = 0.53 * working_wavelength  # [m]\n",
    "\n",
    "DETECTOR_SIZE = (1024, 1024)\n",
    "# an actual zone where weights will be updated during a training process\n",
    "\n",
    "# number of neurons in simulation\n",
    "x_layer_nodes = DETECTOR_SIZE[1] * 1\n",
    "y_layer_nodes = DETECTOR_SIZE[0] * 1\n",
    "# Comment: Same size as proposed!\n",
    "\n",
    "# physical size of each layer [cm]\n",
    "x_layer_size_m = x_layer_nodes * neuron_size  # [m]\n",
    "y_layer_size_m = y_layer_nodes * neuron_size  # [m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'lambda = {working_wavelength * 1e6:.3f} um')\n",
    "print(f'neuron size = {neuron_size * 1e6:.3f} um')\n",
    "print(f'Layer size (in neurons): {x_layer_nodes} x {y_layer_nodes} = {x_layer_nodes * y_layer_nodes}')\n",
    "print(f'Layer size (in cm): {x_layer_size_m * 1e2} x {y_layer_size_m * 1e2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Creation of the grid(i.e. numerical mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation parameters for the rest of the notebook\n",
    "SIM_PARAMS = SimulationParameters(\n",
    "    axes={\n",
    "        'W': torch.linspace(-x_layer_size_m / 2, x_layer_size_m / 2, x_layer_nodes),\n",
    "        'H': torch.linspace(-y_layer_size_m / 2, y_layer_size_m / 2, y_layer_nodes),\n",
    "        'wavelength': working_wavelength,  # only one wavelength!\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset preparation (Data Engineer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. [MNIST Dataset](https://www.kaggle.com/datasets/hojjatk/mnist-dataset): loading and conversion to wavefronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a directory for a dataset\n",
    "MNIST_DATA_FOLDER = './data'  # folder to store data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Load Train and Test datasets of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN (images)\n",
    "mnist_train_ds = torchvision.datasets.MNIST(\n",
    "    root=MNIST_DATA_FOLDER,\n",
    "    train=True,  # for train dataset\n",
    "    download=False,\n",
    ")\n",
    "\n",
    "print(f'Train data: {len(mnist_train_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST (images)\n",
    "mnist_test_ds = torchvision.datasets.MNIST(\n",
    "    root=MNIST_DATA_FOLDER,\n",
    "    train=False,  # for test dataset\n",
    "    download=False,\n",
    ")\n",
    "\n",
    "print(f'Test data : {len(mnist_test_ds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Detector\n",
    "\n",
    " `DetectorProcessor` in our library is used to process an information on detector. For example, for the current task `DetectorProcessor` must return only 10 values (1 value per 1 class).\n",
    "\n",
    " \n",
    "\n",
    " Let's define the “Detector” object: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.detector_segmentation as detector_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = 10\n",
    "\n",
    "detector_segment_size = 22 * working_wavelength\n",
    "\n",
    "# size of each segment in neurons\n",
    "x_segment_nodes = int(detector_segment_size / neuron_size)\n",
    "y_segment_nodes = int(detector_segment_size / neuron_size)\n",
    "# each segment of size = (y_segment_nodes, x_segment_nodes)\n",
    "\n",
    "y_boundary_nodes = y_segment_nodes * 9\n",
    "x_boundary_nodes = x_segment_nodes * 9\n",
    "\n",
    "\n",
    "# This mask will be used to generate a target image for each number\n",
    "DETECTOR_MASK = detector_segmentation.squares_mnist(\n",
    "    y_boundary_nodes, x_boundary_nodes,  # size of a detector or an aperture (in the middle of detector)\n",
    "    SIM_PARAMS\n",
    ")\n",
    "# Target image: zeros are everywhere except the necessary zone responsible for the label!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. Conversion images to wavefronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select modulation type\n",
    "MODULATION_TYPE = 'amp'  # using ONLY amplitude to encode each picture in a Wavefront!\n",
    "\n",
    "resize_y = int(DETECTOR_SIZE[0] / 3)\n",
    "resize_x = int(DETECTOR_SIZE[1] / 3)  # shape for transforms.Resize\n",
    "\n",
    "# paddings along OY\n",
    "pad_top = int((y_layer_nodes - resize_y) / 2)\n",
    "pad_bottom = y_layer_nodes - pad_top - resize_y\n",
    "# paddings along OX\n",
    "pad_left = int((x_layer_nodes - resize_x) / 2)\n",
    "pad_right = x_layer_nodes - pad_left - resize_x  # params for transforms.Pad\n",
    "\n",
    "# compose all transforms!\n",
    "image_transform_for_ds = transforms.Compose(\n",
    "  [\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Resize(\n",
    "          size=(resize_y, resize_x),\n",
    "          interpolation=InterpolationMode.NEAREST,\n",
    "      ),\n",
    "      transforms.Pad(\n",
    "          padding=(\n",
    "              pad_left,  # left padding\n",
    "              pad_top,  # top padding\n",
    "              pad_right,  # right padding\n",
    "              pad_bottom  # bottom padding\n",
    "          ),\n",
    "          fill=0,\n",
    "      ),  # padding to match sizes!\n",
    "      ToWavefront(modulation_type=MODULATION_TYPE)  # <- select modulation type!!!\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Comment.</span>** Here `dataset.getitem()` will return a pair of a `Wavefront`, where a number encoded, and a target label (a number from 0 to 9). During the training process we will use MSE loss and we will generate a target detector picture based on a detector zones (will be initialized later in 3.1.3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN dataset of WAVEFRONTS\n",
    "mnist_wf_train_ds = DatasetOfWavefronts(\n",
    "    init_ds=mnist_train_ds,  # dataset of images\n",
    "    transformations=image_transform_for_ds,  # image transformation\n",
    "    sim_params=SIM_PARAMS,  # simulation parameters\n",
    "    target='detector',\n",
    "    detector_mask=DETECTOR_MASK\n",
    ")\n",
    "\n",
    "# TEST dataset of WAVEFRONTS\n",
    "mnist_wf_test_ds = DatasetOfWavefronts(\n",
    "    init_ds=mnist_test_ds,  # dataset of images\n",
    "    transformations=image_transform_for_ds,  # image transformation\n",
    "    sim_params=SIM_PARAMS,  # simulation parameters\n",
    "    target='detector',\n",
    "    detector_mask=DETECTOR_MASK\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Optical network\n",
    "\n",
    "Let's create a neural network that will consist of 512 diffraction layers. 5 layers will be trained: 2 at the beginning, 2 at the end and one in the middle. \n",
    "\n",
    "> Distance between layers will be is set to be $40$ $\\lambda$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1 Neural network parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_DIFF_LAYERS = 5  # number of diffractive layers that will be trained\n",
    "FREE_SPACE_DISTANCE = 40 * working_wavelength  # [m] - distance between difractive layers\n",
    "print(f'Distance between layers is {FREE_SPACE_DISTANCE * 1e2:.3f} cm')\n",
    "\n",
    "MAX_PHASE = 2 * torch.pi  # max phase for phase masks\n",
    "\n",
    "FREESPACE_METHOD = 'AS'  # we use another method in contrast to [2]!!!\n",
    "\n",
    "INIT_PHASE = torch.pi  # initial values for phase masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2 Architecture\n",
    "\n",
    "**<span style=\"color:red\">Comment:</span>**\n",
    "Here we are using a default `ConstrainedParameter` which is using the sigmoid function to limit a parameter range.\n",
    "\n",
    "**<span style=\"color:red\">Comment:</span>** Setup ends with `Detector` that returns an output tensor of intensities for each input `Wavefront`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_setup(\n",
    "    total_number_of_layers: int,\n",
    "    number_of_layers_at_the_beginning: int,\n",
    "):\n",
    "\n",
    "    global FREE_SPACE_DISTANCE, MAX_PHASE, FREESPACE_METHOD, INIT_PHASE\n",
    "    global SIM_PARAMS\n",
    "\n",
    "    elements_list = []\n",
    "\n",
    "    free_space = elements.FreeSpace(\n",
    "        simulation_parameters=SIM_PARAMS,\n",
    "        distance=FREE_SPACE_DISTANCE,\n",
    "        method=FREESPACE_METHOD\n",
    "    )\n",
    "\n",
    "    x_nodes, y_nodes = SIM_PARAMS.axes_size(axs=('W', 'H'))\n",
    "    const_mask = torch.ones(size=(y_nodes, x_nodes)) * INIT_PHASE\n",
    "\n",
    "    trainable_diffractive_layer = elements.DiffractiveLayer(\n",
    "        simulation_parameters=SIM_PARAMS,\n",
    "        mask=ConstrainedParameter(\n",
    "            const_mask,\n",
    "            min_value=0,\n",
    "            max_value=MAX_PHASE\n",
    "        ),\n",
    "    )\n",
    "\n",
    "    untrained_diffractive_layer = elements.DiffractiveLayer(\n",
    "        simulation_parameters=SIM_PARAMS,\n",
    "        mask=const_mask,  # HERE WE ARE DON'T USE CONSTRAINED PARAMETER!\n",
    "    )\n",
    "\n",
    "    elements_list.append(free_space)\n",
    "\n",
    "    for _ in range(2):\n",
    "        elements_list.append(trainable_diffractive_layer)\n",
    "        elements_list.append(free_space)\n",
    "\n",
    "    for _ in range(number_of_layers_at_the_beginning):\n",
    "        elements_list.append(untrained_diffractive_layer)\n",
    "        elements_list.append(free_space)\n",
    "\n",
    "    elements_list.append(trainable_diffractive_layer)\n",
    "    elements_list.append(free_space)\n",
    "\n",
    "    for _ in range(total_number_of_layers - number_of_layers_at_the_beginning):\n",
    "        elements_list.append(untrained_diffractive_layer)\n",
    "        elements_list.append(free_space)\n",
    "\n",
    "    for _ in range(2):\n",
    "        elements_list.append(trainable_diffractive_layer)\n",
    "        elements_list.append(free_space)\n",
    "\n",
    "     # add Detector in the end of the system!\n",
    "    elements_list.append(\n",
    "        Detector(\n",
    "            simulation_parameters=SIM_PARAMS,\n",
    "            func='intensity'  # detector that returns intensity\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return LinearOpticalSetup(elements=elements_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_DIFF_LAYERS_NO_TRAIN = 507\n",
    "NUM_OF_DIFF_LAYERS_BEGINNING = 253"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optical_setup = set_setup(\n",
    "    total_number_of_layers=NUM_OF_DIFF_LAYERS_NO_TRAIN,\n",
    "    number_of_layers_at_the_beginning=NUM_OF_DIFF_LAYERS_BEGINNING\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3 Detector processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALCULATE_ACCURACIES = True\n",
    "\n",
    "# create a DetectorProcessorOzcanClf object\n",
    "if CALCULATE_ACCURACIES:\n",
    "    detector_processor = DetectorProcessorClf(\n",
    "        simulation_parameters=SIM_PARAMS,\n",
    "        num_classes=number_of_classes,\n",
    "        segmented_detector=DETECTOR_MASK,\n",
    "    )\n",
    "else:\n",
    "    detector_processor = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4 Stuff for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bs = 128  # a batch size for training set\n",
    "val_bs = 64  # a batch size for validation set\n",
    "\n",
    "LR = 1e-3  # learning rate\n",
    "\n",
    "loss_func_clf = nn.MSELoss()  # by default: reduction='mean'\n",
    "loss_func_name = 'MSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adam_optimizer(net):\n",
    "    return torch.optim.Adam(\n",
    "        params=net.parameters(),  # NETWORK PARAMETERS!\n",
    "        lr=LR\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_wf_train_ds\n",
    "train_wf_ds, val_wf_ds = torch.utils.data.random_split(\n",
    "    dataset=mnist_wf_train_ds,\n",
    "    lengths=[55000, 5000],  # sizes from the article\n",
    "    generator=torch.Generator().manual_seed(178)  # for reproducibility\n",
    ")\n",
    "\n",
    "train_wf_loader = torch.utils.data.DataLoader(\n",
    "    train_wf_ds,\n",
    "    batch_size=train_bs,\n",
    "    shuffle=True,\n",
    "    # num_workers=2,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "val_wf_loader = torch.utils.data.DataLoader(\n",
    "    val_wf_ds,\n",
    "    batch_size=val_bs,\n",
    "    shuffle=False,\n",
    "    # num_workers=2,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "test_wf_loader = torch.utils.data.DataLoader(\n",
    "    mnist_wf_test_ds,\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    "    # num_workers=2,\n",
    "    drop_last=False,\n",
    ")  # data loader for a test MNIST data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5 Training and evaluation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onn_train_mse(\n",
    "    optical_net, wavefronts_dataloader,\n",
    "    detector_processor_clf,  # DETECTOR PROCESSOR needed for accuracies only!\n",
    "    loss_func, optimizer,\n",
    "    device='cuda', show_process=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to train `optical_net` (classification task)\n",
    "    ...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        optical_net : torch.nn.Module\n",
    "            Neural Network composed of Elements.\n",
    "        wavefronts_dataloader : torch.utils.data.DataLoader\n",
    "            A loader (by batches) for the train dataset of wavefronts.\n",
    "        detector_processor_clf : DetectorProcessorClf\n",
    "            A processor of a detector image for a classification task, that returns `probabilities` of classes.\n",
    "        loss_func :\n",
    "            Loss function for a multi-class classification task.\n",
    "        optimizer: torch.optim\n",
    "            Optimizer...\n",
    "        device : str\n",
    "            Device to computate on...\n",
    "        show_process : bool\n",
    "            Flag to show (or not) a progress bar.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        batches_losses : list[float]\n",
    "            Losses for each batch in an epoch.\n",
    "        batches_accuracies : list[float]\n",
    "            Accuracies for each batch in an epoch.\n",
    "        epoch_accuracy : float\n",
    "            Accuracy for an epoch.\n",
    "    \"\"\"\n",
    "    optical_net.train()  # activate 'train' mode of a model\n",
    "    batches_losses = []  # to store loss for each batch\n",
    "    batches_accuracies = []  # to store accuracy for each batch\n",
    "\n",
    "    correct_preds = 0\n",
    "    size = 0\n",
    "\n",
    "    for batch_wavefronts, batch_targets in tqdm(\n",
    "        wavefronts_dataloader,\n",
    "        total=len(wavefronts_dataloader),\n",
    "        desc='train', position=0,\n",
    "        leave=True, disable=not show_process\n",
    "    ):  # go by batches\n",
    "        # batch_wavefronts - input wavefronts, batch_labels - labels\n",
    "        batch_size = batch_wavefronts.size()[0]\n",
    "\n",
    "        batch_wavefronts = batch_wavefronts.to(device)\n",
    "        batch_targets = batch_targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward of an optical network\n",
    "        detector_output = optical_net(batch_wavefronts)\n",
    "\n",
    "        # calculate loss for a batch\n",
    "        loss = loss_func(detector_output, batch_targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ACCURACY\n",
    "        if CALCULATE_ACCURACIES:\n",
    "            # process a detector image\n",
    "            batch_labels = detector_processor_clf.batch_forward(batch_targets).argmax(1)\n",
    "            batch_probas = detector_processor_clf.batch_forward(detector_output)\n",
    "\n",
    "            batch_correct_preds = (\n",
    "                batch_probas.argmax(1) == batch_labels\n",
    "            ).type(torch.float).sum().item()\n",
    "\n",
    "            correct_preds += batch_correct_preds\n",
    "            size += batch_size\n",
    "\n",
    "        # accumulate losses and accuracies for batches\n",
    "        batches_losses.append(loss.item())\n",
    "        if CALCULATE_ACCURACIES:\n",
    "            batches_accuracies.append(batch_correct_preds / batch_size)\n",
    "        else:\n",
    "            batches_accuracies.append(0.)\n",
    "\n",
    "    if CALCULATE_ACCURACIES:\n",
    "        epoch_accuracy = correct_preds / size\n",
    "    else:\n",
    "        epoch_accuracy = 0.\n",
    "\n",
    "    return batches_losses, batches_accuracies, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onn_validate_mse(\n",
    "    optical_net, wavefronts_dataloader,\n",
    "    detector_processor_clf,  # DETECTOR PROCESSOR NEEDED!\n",
    "    loss_func,\n",
    "    device='cuda', show_process=False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Function to validate `optical_net` (classification task)\n",
    "    ...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        optical_net : torch.nn.Module\n",
    "            Neural Network composed of Elements.\n",
    "        wavefronts_dataloader : torch.utils.data.DataLoader\n",
    "            A loader (by batches) for the train dataset of wavefronts.\n",
    "        detector_processor_clf : DetectorProcessorClf\n",
    "            A processor of a detector image for a classification task, that returns `probabilities` of classes.\n",
    "        loss_func :\n",
    "            Loss function for a multi-class classification task.\n",
    "        device : str\n",
    "            Device to computate on...\n",
    "        show_process : bool\n",
    "            Flag to show (or not) a progress bar.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        batches_losses : list[float]\n",
    "            Losses for each batch in an epoch.\n",
    "        batches_accuracies : list[float]\n",
    "            Accuracies for each batch in an epoch.\n",
    "        epoch_accuracy : float\n",
    "            Accuracy for an epoch.\n",
    "    \"\"\"\n",
    "    optical_net.eval()  # activate 'eval' mode of a model\n",
    "    batches_losses = []  # to store loss for each batch\n",
    "    batches_accuracies = []  # to store accuracy for each batch\n",
    "\n",
    "    correct_preds = 0\n",
    "    size = 0\n",
    "\n",
    "    for batch_wavefronts, batch_targets in tqdm(\n",
    "        wavefronts_dataloader,\n",
    "        total=len(wavefronts_dataloader),\n",
    "        desc='validation', position=0,\n",
    "        leave=True, disable=not show_process\n",
    "    ):  # go by batches\n",
    "        # batch_wavefronts - input wavefronts, batch_labels - labels\n",
    "        batch_size = batch_wavefronts.size()[0]\n",
    "\n",
    "        batch_wavefronts = batch_wavefronts.to(device)\n",
    "        batch_targets = batch_targets.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            detector_outputs = optical_net(batch_wavefronts)\n",
    "            # calculate loss for a batch\n",
    "            loss = loss_func(detector_outputs, batch_targets)\n",
    "\n",
    "        # ACCURACY\n",
    "        if CALCULATE_ACCURACIES:\n",
    "            # process a detector image\n",
    "            batch_labels = detector_processor_clf.batch_forward(batch_targets).argmax(1)\n",
    "            batch_probas = detector_processor_clf.batch_forward(detector_outputs)\n",
    "\n",
    "            batch_correct_preds = (\n",
    "                batch_probas.argmax(1) == batch_labels\n",
    "            ).type(torch.float).sum().item()\n",
    "\n",
    "            correct_preds += batch_correct_preds\n",
    "            size += batch_size\n",
    "\n",
    "        # accumulate losses and accuracies for batches\n",
    "        batches_losses.append(loss.item())\n",
    "        if CALCULATE_ACCURACIES:\n",
    "            batches_accuracies.append(batch_correct_preds / batch_size)\n",
    "        else:\n",
    "            batches_accuracies.append(0.)\n",
    "\n",
    "    if CALCULATE_ACCURACIES:\n",
    "        epoch_accuracy = correct_preds / size\n",
    "    else:\n",
    "        epoch_accuracy = 0.\n",
    "\n",
    "    return batches_losses, batches_accuracies, epoch_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training of the optical network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Before training: transferring objects to the GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optical_setup.net = optical_setup.net.to(DEVICE)\n",
    "SIM_PARAMS = SIM_PARAMS.to(DEVICE)\n",
    "detector_processor = detector_processor.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2\n",
    "print_each = 2  # print each n'th epoch info\n",
    "\n",
    "scheduler = None  # sheduler for a lr tuning during training\n",
    "\n",
    "\n",
    "# Linc optimizer to a recreated net!\n",
    "optimizer_clf = get_adam_optimizer(optical_setup.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_epochs_losses = []\n",
    "val_epochs_losses = []  # to store losses of each epoch\n",
    "\n",
    "train_epochs_acc = []\n",
    "val_epochs_acc = []  # to store accuracies\n",
    "\n",
    "torch.manual_seed(98)  # for reproducability?\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    if (epoch == 0) or ((epoch + 1) % print_each == 0) or (epoch == n_epochs - 1):\n",
    "        print(f'Epoch #{epoch + 1}: ', end='')\n",
    "        show_progress = True\n",
    "    else:\n",
    "        show_progress = False\n",
    "\n",
    "    # TRAIN\n",
    "    start_train_time = time.time()  # start time of the epoch (train)\n",
    "    train_losses, _, train_accuracy = onn_train_mse(\n",
    "        optical_setup.net,  # optical network composed\n",
    "        train_wf_loader,  # dataloader of training set\n",
    "        detector_processor,  # detector processor\n",
    "        loss_func_clf,\n",
    "        optimizer_clf,\n",
    "        device=DEVICE,\n",
    "        show_process=show_progress,\n",
    "    )  # train the model\n",
    "    mean_train_loss = np.mean(train_losses)\n",
    "\n",
    "    if (epoch == 0) or ((epoch + 1) % print_each == 0) or (epoch == n_epochs - 1):  # train info\n",
    "        print('Training results')\n",
    "        print(f'\\t{loss_func_name} : {mean_train_loss:.6f}')\n",
    "        if CALCULATE_ACCURACIES:\n",
    "            print(f'\\tAccuracy : {(train_accuracy*100):>0.1f} %')\n",
    "        print(f'\\t------------   {time.time() - start_train_time:.2f} s')\n",
    "\n",
    "    # VALIDATION\n",
    "    start_val_time = time.time()  # start time of the epoch (validation)\n",
    "    val_losses, _, val_accuracy = onn_validate_mse(\n",
    "        optical_setup.net,  # optical network composed in 3.\n",
    "        val_wf_loader,  # dataloader of validation set\n",
    "        detector_processor,  # detector processor\n",
    "        loss_func_clf,\n",
    "        device=DEVICE,\n",
    "        show_process=show_progress,\n",
    "    )  # evaluate the model\n",
    "    mean_val_loss = np.mean(val_losses)\n",
    "\n",
    "    if (epoch == 0) or ((epoch + 1) % print_each == 0) or (epoch == n_epochs - 1):  # validation info\n",
    "        print('Validation results')\n",
    "        print(f'\\t{loss_func_name} : {mean_val_loss:.6f}')\n",
    "        if CALCULATE_ACCURACIES:\n",
    "            print(f'\\tAccuracy : {(val_accuracy*100):>0.1f} %')\n",
    "        print(f'\\t------------   {time.time() - start_val_time:.2f} s')\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step(mean_val_loss)\n",
    "\n",
    "    # save losses\n",
    "    train_epochs_losses.append(mean_train_loss)\n",
    "    val_epochs_losses.append(mean_val_loss)\n",
    "    # seve accuracies\n",
    "    train_epochs_acc.append(train_accuracy)\n",
    "    val_epochs_acc.append(val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Learning curves (MSELoss and Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curve\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "axs[0].plot(range(1, n_epochs + 1), np.array(train_epochs_losses) * 1e3, label='train')\n",
    "axs[0].plot(range(1, n_epochs + 1), np.array(val_epochs_losses) * 1e3, linestyle='dashed', label='validation')\n",
    "\n",
    "axs[1].plot(range(1, n_epochs + 1), train_epochs_acc, label='train')\n",
    "axs[1].plot(range(1, n_epochs + 1), val_epochs_acc, linestyle='dashed', label='validation')\n",
    "\n",
    "axs[0].set_ylabel(loss_func_name + r' $\\times 10^3$')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array with all losses\n",
    "# TODO: make with PANDAS?\n",
    "all_lasses_header = ','.join([\n",
    "    f'{loss_func_name.split()[0]}_train', f'{loss_func_name.split()[0]}_val',\n",
    "    'accuracy_train', 'accuracy_val'\n",
    "])\n",
    "all_losses_array = np.array(\n",
    "    [train_epochs_losses, val_epochs_losses, train_epochs_acc, val_epochs_acc]\n",
    ").T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4. Trained phase masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Индексы объектов, которые нужно визуализировать\n",
    "target_indices = {1, 3, 511, 1021, 1023}\n",
    "\n",
    "# Определяем количество колонок и строк для визуализации\n",
    "n_cols = len(target_indices)  # Количество колонок равно числу целевых индексов\n",
    "n_rows = 1\n",
    "\n",
    "# Создаем фигуру для визуализации\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 5.2, n_rows * 4.6))\n",
    "\n",
    "cmap = 'rainbow'  # Цветовая карта для визуализации\n",
    "count = 1\n",
    "# Перебираем слои в optical_setup\n",
    "for ind_layer, layer in enumerate(optical_setup.net.to(torch.device(\"cpu\"))):\n",
    "    if ind_layer in target_indices and isinstance(layer, elements.DiffractiveLayer):\n",
    "\n",
    "\n",
    "        # Определяем текущий subplot\n",
    "        ax_this = axs[list(target_indices).index(ind_layer)]\n",
    "\n",
    "        # Добавляем заголовок с индексом слоя\n",
    "        ax_this.set_title(f'DiffractiveLayer {count}')\n",
    "        count += 1\n",
    "\n",
    "        # Получаем mask для визуализации\n",
    "        mask_to_visualize = layer.mask.detach()\n",
    "\n",
    "        # Визуализируем mask\n",
    "        im = ax_this.imshow(\n",
    "            mask_to_visualize, cmap=cmap,\n",
    "            vmin=0, vmax=MAX_PHASE\n",
    "        )\n",
    "        x_frame = (x_layer_nodes - DETECTOR_SIZE[1]) / 2\n",
    "        y_frame = (y_layer_nodes - DETECTOR_SIZE[0]) / 2\n",
    "        ax_this.set_xlim([x_frame, x_layer_nodes - x_frame])\n",
    "        ax_this.set_ylim([y_frame, y_layer_nodes - y_frame])\n",
    "\n",
    "        cbar = fig.colorbar(im, ax=ax_this, orientation='vertical', fraction=0.046, pad=0.04)\n",
    "        cbar.set_label('Mask Value')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.5 Saving the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FOLDER = f'models/reproduced_results/MNIST_MSE_Ozcan_2018-2020_GPU_{512}_DL_{DETECTOR_SIZE[0]}x{DETECTOR_SIZE[1]}_grid'\n",
    "\n",
    "if not os.path.exists(RESULTS_FOLDER):\n",
    "    os.makedirs(RESULTS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath to save the model\n",
    "model_filepath = f'{RESULTS_FOLDER}/optical_setup_net_gpu.pth'\n",
    "# filepath to save losses\n",
    "losses_filepath = f'{RESULTS_FOLDER}/training_curves_gpu.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model weights and learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "torch.save(optical_setup.net.state_dict(), model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving losses\n",
    "np.savetxt(\n",
    "    losses_filepath, all_losses_array,\n",
    "    delimiter=',', header=all_lasses_header, comments=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Load saved weights for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FOLDER = f'models/reproduced_results/MNIST_MSE_Ozcan_2018-2020_GPU_{512}_DL_{DETECTOR_SIZE[0]}x{DETECTOR_SIZE[1]}_grid'\n",
    "\n",
    "load_model_filepath = f'{RESULTS_FOLDER}/optical_setup_net_gpu.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup to load weights\n",
    "ozcan_optical_setup_loaded = set_setup(\n",
    "    total_number_of_layers=NUM_OF_DIFF_LAYERS_NO_TRAIN,\n",
    "    number_of_layers_at_the_beginning=NUM_OF_DIFF_LAYERS_BEGINNING\n",
    ")\n",
    "\n",
    "# LOAD WEIGHTS\n",
    "ozcan_optical_setup_loaded.net.load_state_dict(torch.load(load_model_filepath))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Calculate metrics on test set for the loaded model\n",
    "\n",
    "Checking if the loaded model works correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses_1, _, test_accuracy_1 = onn_validate_mse(\n",
    "    ozcan_optical_setup_loaded.net.to(torch.device(\"cuda\")),  # optical network with loaded weights\n",
    "    test_wf_loader,  # dataloader of training set\n",
    "    detector_processor,  # detector processor\n",
    "    loss_func_clf,\n",
    "    device=DEVICE,\n",
    "    show_process=True,\n",
    ")  # evaluate the model\n",
    "\n",
    "print(\n",
    "    'Results after training on TEST set:\\n' +\n",
    "    f'\\t{loss_func_name} : {np.mean(test_losses_1):.6f}\\n' +\n",
    "    f'\\tAccuracy : {(test_accuracy_1 * 100):>0.1f} %'\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
