{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import functional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import InterpolationMode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our library\n",
    "from svetlanna import SimulationParameters\n",
    "from svetlanna.parameters import ConstrainedParameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# our library\n",
    "from svetlanna import Wavefront\n",
    "from svetlanna import elements\n",
    "from svetlanna.setup import LinearOpticalSetup\n",
    "from svetlanna.detector import Detector, DetectorProcessorClf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from svetlanna.transforms import ToWavefront"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# datasets of wavefronts\n",
    "from src.wf_datasets import DatasetOfWavefronts\n",
    "from src.wf_datasets import WavefrontsDatasetSimple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "plt.style.use('dark_background')\n",
    "%matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Simulation Parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Defining simulation parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "working_frequency = 0.4 * 1e12 # [Hz]\n",
    "c_const = 299_792_458  # [m / s]\n",
    "working_wavelength = c_const / working_frequency  # [m]\n",
    "\n",
    "# neuron size (square)\n",
    "neuron_size = 0.53 * working_wavelength  # [m]\n",
    "\n",
    "DETECTOR_SIZE = (128, 128)\n",
    "# an actual zone where weights will be updated during a training process\n",
    "\n",
    "# number of neurons in simulation\n",
    "x_layer_nodes = DETECTOR_SIZE[1] * 1\n",
    "y_layer_nodes = DETECTOR_SIZE[0] * 1\n",
    "# Comment: Same size as proposed!\n",
    "\n",
    "# physical size of each layer [cm]\n",
    "x_layer_size_m = x_layer_nodes * neuron_size  # [m]\n",
    "y_layer_size_m = y_layer_nodes * neuron_size  # [m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'lambda = {working_wavelength * 1e6:.3f} um')\n",
    "print(f'neuron size = {neuron_size * 1e6:.3f} um')\n",
    "print(f'Layer size (in neurons): {x_layer_nodes} x {y_layer_nodes} = {x_layer_nodes * y_layer_nodes}')\n",
    "print(f'Layer size (in cm): {x_layer_size_m * 1e2} x {y_layer_size_m * 1e2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Creation of the grid(i.e. numerical mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulation parameters for the rest of the notebook\n",
    "SIM_PARAMS = SimulationParameters(\n",
    "    axes={\n",
    "        'W': torch.linspace(-x_layer_size_m / 2, x_layer_size_m / 2, x_layer_nodes),\n",
    "        'H': torch.linspace(-y_layer_size_m / 2, y_layer_size_m / 2, y_layer_nodes),\n",
    "        'wavelength': working_wavelength,  # only one wavelength!\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset preparation (Data Engineer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. [MNIST Dataset](https://www.kaggle.com/datasets/hojjatk/mnist-dataset): loading and conversion to wavefronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a directory for a dataset\n",
    "MNIST_DATA_FOLDER = './data'  # folder to store data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Load Train and Test datasets of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN (images)\n",
    "mnist_train_ds = torchvision.datasets.MNIST(\n",
    "    root=MNIST_DATA_FOLDER,\n",
    "    train=True,  # for train dataset\n",
    "    download=False,\n",
    ")\n",
    "\n",
    "print(f'Train data: {len(mnist_train_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST (images)\n",
    "mnist_test_ds = torchvision.datasets.MNIST(\n",
    "    root=MNIST_DATA_FOLDER,\n",
    "    train=False,  # for test dataset\n",
    "    download=False,\n",
    ")\n",
    "\n",
    "print(f'Test data : {len(mnist_test_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Detector\n",
    "\n",
    " `DetectorProcessor` in our library is used to process an information on detector. For example, for the current task `DetectorProcessor` must return only 10 values (1 value per 1 class).\n",
    "\n",
    " Let's define the “Detector” object: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3. Conversion images to wavefronts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optical Neural Network\n",
    "\n",
    "In that example notebook we will try to realize a simple architecture of an optical neural network from an article [[1]](https://www.science.org/doi/10.1126/science.aat8084).\n",
    "\n",
    "> In general, the phase and amplitude of eachneuron can be learnable parameters, providinga complex-valued modulation at each layer, which improves the inference performance of the diffractive network.\n",
    "\n",
    "> ... we first trained it as a digit classifierto perform automated classification of hand-written digits, from $0$ to $9$. Forthis task, phase-only transmission masks were designed by training **a five-layer** $D^2 NN$ with $55,000$ images ($5000$ validation images) from the MNIST handwritten digit data-base.\n",
    "\n",
    ">  We then used continuous-wave illumination at $0.4$ $THz$...\n",
    "\n",
    "Some info from [a supplementary material](https://www.science.org/doi/suppl/10.1126/science.aat8084/suppl_file/aat8084-lin-sm-rev-3.pdf) (information about MNIST classification):\n",
    "\n",
    "> Because we consider coherent illumination, the input information can be encoded in the amplitude and/or phase channels of the input plane.\n",
    "\n",
    "> For each layer of the $D^2NN$, we set we set the neuron size to be $400$ $\\mu m$...\n",
    "\n",
    "> At the detector/output plane, we measured the intensity of the network output...\n",
    "\n",
    "#### <span style=\"color:red\">Additional information</span>\n",
    "\n",
    "In another article [[2]](https://ieeexplore.ieee.org/abstract/document/8732486) of the same authors sume details were clarified: \n",
    "\n",
    "> In our numerical simulations, we used a neuron size of approximately $0.53 \\times \\lambda $\n",
    "\n",
    ">  In addition, the height and width of each diffractive layer was set to include $200 \\times 200 = 40K$ neurons per layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Dataset preparation (Data Engineer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. [MNIST Dataset](https://www.kaggle.com/datasets/hojjatk/mnist-dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialize a directory for a dataset\n",
    "MNIST_DATA_FOLDER = './data'  # folder to store data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1. Load Train and Test datasets of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN (images)\n",
    "mnist_train_ds = torchvision.datasets.MNIST(\n",
    "    root=MNIST_DATA_FOLDER,\n",
    "    train=True,  # for train dataset\n",
    "    download=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST (images)\n",
    "mnist_test_ds = torchvision.datasets.MNIST(\n",
    "    root=MNIST_DATA_FOLDER,\n",
    "    train=False,  # for test dataset\n",
    "    download=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 60000\n",
      "Test data : 10000\n"
     ]
    }
   ],
   "source": [
    "print(f'Train data: {len(mnist_train_ds)}')\n",
    "print(f'Test data : {len(mnist_test_ds)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2. Create Train and Test datasets of wavefronts\n",
    "\n",
    "From [[2]](https://ieeexplore.ieee.org/abstract/document/8732486):\n",
    "\n",
    "> Input objects were encoded in amplitude channel (MNIST) of the input plane and were illuminated with a uniform plane wave at a wavelength of $\\lambda$ to match the conditions introduced in [[1]](https://www.science.org/doi/10.1126/science.aat8084) for all-optical classification.\n",
    "\n",
    "So, we need to do an amplitude modulation of each image from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Select classes zones on `Detector`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> ... size of these detectors $(6.4 \\lambda \\times 6.4 \\lambda)$ ...\n",
    "\n",
    "**<span style=\"color:red\">Comment:</span>** `DetectorProcessor` in our library is used to process an information on detector. For example, for the current task `DetectorProcessor` must return only 10 values (1 value per 1 class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import src.detector_segmentation as detector_segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_classes = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detector mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_segment_size = 4 * working_wavelength"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# size of each segment in neurons\n",
    "x_segment_nodes = int(detector_segment_size / neuron_size)\n",
    "y_segment_nodes = int(detector_segment_size / neuron_size)\n",
    "# each segment of size = (y_segment_nodes, x_segment_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_boundary_nodes = y_segment_nodes * 9\n",
    "x_boundary_nodes = x_segment_nodes * 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DETECTOR_MASK = detector_segmentation.squares_mnist(\n",
    "    y_boundary_nodes, x_boundary_nodes,  # size of a detector or an aperture (in the middle of detector)\n",
    "    SIM_PARAMS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Comment:</span>** This mask will be used to generate a target image for each number! \n",
    "\n",
    "<span style=\"color:red\">Target image:</span> zeros are everywhere except the necessary zone responsible for the label! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### To visualize detector zones (for further use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ZONES_HIGHLIGHT_COLOR = 'r'\n",
    "ZONES_LW = 0.5\n",
    "selected_detector_mask = DETECTOR_MASK.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zones_patches(detector_mask):\n",
    "    \"\"\"\n",
    "    Returns a list of patches to draw zones in final visualisation\n",
    "    \"\"\"\n",
    "    zones_patches = []\n",
    "\n",
    "    delta = 1 #0.5\n",
    "\n",
    "    for ind_class in range(number_of_classes):\n",
    "        idx_y, idx_x = (detector_mask == ind_class).nonzero(as_tuple=True)\n",
    "\n",
    "        zone_rect = patches.Rectangle(\n",
    "            (idx_x[0] - delta, idx_y[0] - delta),\n",
    "            idx_x[-1] - idx_x[0] + 2 * delta, idx_y[-1] - idx_y[0] + 2 * delta,\n",
    "            linewidth=ZONES_LW,\n",
    "            edgecolor=ZONES_HIGHLIGHT_COLOR,\n",
    "            facecolor='none'\n",
    "        )\n",
    "\n",
    "        zones_patches.append(zone_rect)\n",
    "\n",
    "    return zones_patches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualize mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 300x300 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax0 = plt.subplots(1, 1, figsize=(3, 3))\n",
    "\n",
    "ax0.set_title(f'Detector segments')\n",
    "ax0.imshow(selected_detector_mask, cmap='grey')\n",
    "\n",
    "for zone in get_zones_patches(selected_detector_mask):\n",
    "    # add zone's patches to the axis\n",
    "    # zone_copy = copy(zone)\n",
    "    ax0.add_patch(zone)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dataset of wavefronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select modulation type\n",
    "MODULATION_TYPE = 'amp'  # using ONLY amplitude to encode each picture in a Wavefront!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_y = int(DETECTOR_SIZE[0] / 3)\n",
    "resize_x = int(DETECTOR_SIZE[1] / 3)  # shape for transforms.Resize\n",
    "# Comment: Looks like in [2] article MNIST pictures were resized to ~100 x 100 neurons\n",
    "\n",
    "# paddings along OY\n",
    "pad_top = int((y_layer_nodes - resize_y) / 2)\n",
    "pad_bottom = y_layer_nodes - pad_top - resize_y\n",
    "# paddings along OX\n",
    "pad_left = int((x_layer_nodes - resize_x) / 2)\n",
    "pad_right = x_layer_nodes - pad_left - resize_x  # params for transforms.Pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compose all transforms!\n",
    "image_transform_for_ds = transforms.Compose(\n",
    "  [\n",
    "      transforms.ToTensor(),\n",
    "      transforms.Resize(\n",
    "          size=(resize_y, resize_x),\n",
    "          interpolation=InterpolationMode.NEAREST,\n",
    "      ),\n",
    "      transforms.Pad(\n",
    "          padding=(\n",
    "              pad_left,  # left padding\n",
    "              pad_top,  # top padding\n",
    "              pad_right,  # right padding\n",
    "              pad_bottom  # bottom padding\n",
    "          ),\n",
    "          fill=0,\n",
    "      ),  # padding to match sizes!\n",
    "      ToWavefront(modulation_type=MODULATION_TYPE)  # <- select modulation type!!!\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Comment.</span>** Here `dataset.getitem()` will return a pair of a `Wavefront`, where a number encoded, and a target label (a number from 0 to 9). During the training process we will use MSE loss and we will generate a target detector picture based on a detector zones (will be initialized later in 3.1.3). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRAIN dataset of WAVEFRONTS\n",
    "mnist_wf_train_ds = DatasetOfWavefronts(\n",
    "    init_ds=mnist_train_ds,  # dataset of images\n",
    "    transformations=image_transform_for_ds,  # image transformation\n",
    "    sim_params=SIM_PARAMS,  # simulation parameters\n",
    "    target='detector',\n",
    "    detector_mask=DETECTOR_MASK\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST dataset of WAVEFRONTS\n",
    "mnist_wf_test_ds = DatasetOfWavefronts(\n",
    "    init_ds=mnist_test_ds,  # dataset of images\n",
    "    transformations=image_transform_for_ds,  # image transformation\n",
    "    sim_params=SIM_PARAMS,  # simulation parameters\n",
    "    target='detector',\n",
    "    detector_mask=DETECTOR_MASK\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data: 60000\n",
      "Test data : 10000\n"
     ]
    }
   ],
   "source": [
    "print(f'Train data: {len(mnist_train_ds)}')\n",
    "print(f'Test data : {len(mnist_test_ds)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA9oAAAMWCAYAAAAOPf6IAAAAP3RFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMS5wb3N0MSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8kixA/AAAACXBIWXMAAA9hAAAPYQGoP6dpAAChRklEQVR4nOzdCXwU5f3H8ScQEiQmyBkgIiKnilKJgFG5RBQtiEcFqy1iPYpQFcWCqFUQFY8KVg4VpXjhCXLYqhye3CoqUJEgNyQBhADhTDie/+v3/Dvb3ZDdJJvZnZndz/v1+r3C7szOTpZ8Z/aZ43kSlFJaAQAAAAAAW1SyZzEAAAAAAEDQ0AYAAAAAwEY0tAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARjS0AQAAAACwEQ1tAAAAAABsREMbAAAAAAAb0dB2wM0336y01qpRo0alzrthwwY1efLkqKxXLJDPSj5bqZUrV4a1jF69evmWIZWZmWn7esL7yHHkPProo7787du3L6xlkGNUBPkuH/mc/PN23XXXhbWc3bt3+5YxduxY29cTsY3cRs4XX3zhy+ZHH30U1jLuueeegO1ErVq1VKyjoR0nOnXqFPDH7V/t27cPmHfYsGFq8eLFaseOHerQoUNqzZo1asyYMap27doB89WvX1+9+eabavXq1aqgoMDsIJcuXar69u1b4gYt2PvL8otvJIPVjTfeWOrv+uuvv6o//OEP6oEHHvA9d9JJJ6kBAwao2bNnq9zcXLO+33//verfv7+qVCkwBt999515/csvv1yuzxiItJSUFDV8+HD1ySefqF27dplMSGaKS0hIMM/PnDlTbd68We3fv98ceHrooYdUcnJywLynnnqqeuSRR0x28/PzTX5kh9q1a9cS1+HSSy9V8+fPVwcOHDDzf/DBByV+qZH3kQz+9NNPZt6tW7eq999/X5111lll/n0lh7feeusJz19//fVmGyXbnJ07d6ovv/xSXXnllQHzkGN41XnnnWeyKxmX7Eh277rrrrD2Z6JJkyYmp5JXWZ7kt3PnzmFvM0KRvEnuvvnmm4Dnk5KS1FNPPaVycnLUwYMH1ZIlS8y2pLg77rjDvB6Itf2yZeDAgWrVqlXq8OHDZr/43HPPqWrVqpU47xlnnKGmTJmitm/fbnIj35cff/zxgHlCfWeeM2dO0PWQ79PlPZj9888/m3z+/e9/D3i+d+/epj0g6yfLlO8QJfn000/N6z/88EMVTzQV3apUqZJOTk4u07wbNmzQkydPrvB7durUSYvnn39e33TTTQFVq1atgHmnTp2qX3zxRX3PPffoP/3pT/rZZ5/Ve/bs0WvWrNHVqlXzzXfOOefoL774Qj/++OP6jjvu0AMHDtQzZsww7/PEE08ELLNXr14nvO+DDz5o5h03bpxvvsaNG58wn9R3332njxw5otPT00P+nvJZyWdW/Pmzzz5bHzt2TM+ZM0fff//9Zn2nTZtm3v+1114rcVk333yzmZ6Zmen43wzlvnIix40aNTJ/kxs3btSff/65+bf8nRafLyUlxUxbtGiRydltt92mJ02apI8ePWpe5z+v5PbAgQN6ypQpesCAAfruu+82eRP9+vULmPe3v/2tWcY333yj77rrLv3QQw/pHTt26C1btujatWufsB0pKirS48eP17feeqv+29/+prdt26b37t2rTzvttJC/56OPPmrev6Rpf/nLX8y0jz76SP/5z38226kffvjBPHfNNdecMD85prySb6lu3brpw4cP68WLF+tBgwaZ7I4aNUo//fTTYe3PTj31VJPRvLw8PWzYMJNvyYtks0OHDmFtM0Jtm0raHkm9/fbb5j2feeYZffvtt+uFCxeaxxdddFGJ84uxY8c6/ndAeavcvF+Weuqpp8z0999/3+y//vGPf5gcfPrppyfM27p1a7179279n//8Rw8ZMsTsR0eMGKH/+c9/BsxX0nfmMWPGmPeR7UNJ6yF537p1q963b5+psvye8n1fKti0goIC/dlnn+ldu3YFnU8V28cXb3/EaDm+AlQUG9rXXXddWK+/9tprzev79OlT6ryzZs0ywZUNXqj55Eu6yMrKCjlf1apVzZfz2bNnl/rewRraEuazzjrrhOfli4Ro0qTJCdP4gk65LcdJSUm+g03ydxlsh16lSpUScyWNXdG1a1ffc5KL4js7eZ9Vq1bpzZs3BzwvO3w54CbLt54799xzzZfxv//9777nGjRoYN5HvlT7v75z587meWlAhNvQzs7O1kuXLg14LjU11ezk5UBf8fnJMeWVfMvfsTSIpdGckJAQdL7y7M/kQLZ8kW/evLnvuZNOOklv2rTJHFALZ5tR3oZ227ZtzbTBgwf7npPG0C+//GIa3CUtj4Y2FWv75Xr16pksvv766ycc7BY9evTwPSf5X7FihTngJt+By7tOr7zyijkYl5GRUeJ0OXj3888/6zfffNOWhrYc0LO2WStXrqShrf5XXDruontI5BKtLVu2mEu7Pv/883JdYlkeJ598sqpcuXK5XrNx40bz85RTTinTvHIZjFwqFopctrJ+/XpzCWgoPXv2VGlpaebymXDJ5TxyqU5x06dPNz/PPPPMsJeN+OREjouKiswlZKU5cuRIibkq6e9dciH5KP4+H3/8sWrYsKHZXogaNWqos88+2yxDlm9ZsWKFuZzshhtu8D2XmppqfhZf17y8PPNTbkkJl2wL5LYWf3Lpm1zqWpHlAk7nW/aJ9erVM+8h7y37UbmkuyL7sw4dOqgffvgh4BYtycmsWbNMvwVNmzYt9zajvH73u9+po0ePqokTJ/qeKywsVJMmTVIXXnihuX0FiPX9clZWlqpSpYp69913A563HvvvQy+77DJ1zjnnqBEjRphLzOV2kZJuCymJfPeWPhK++uorc6tGcZL5e++9V913330ml3aQS+D//9g4iks84Rk44rHHHlN/+9vf1L///W/zBbdNmzbm3orijVXZ6dasWbNMy9y7d+8JIZKOH+RLsDwv92n99a9/VcuWLSvx9dJJQWJiomrWrJm5t0peI/dCFle1alVzj4p8IZd7wW+55Razw5aNQzC/+c1vzIau+L0mJbnpppvMvSmRuKdDvtQIuc8T8EqOo/H3LvPKlxLJnrDu0yypMSvztGrVSqWnp5svHOvWrTNfagYPHqyys7PNF/0GDRqoZ555xhxcK/5FozxkGyRf3P/yl7+YDllk+yP3r1avXl394x//CHu5gNP5lnuW5XFGRoaaMWOGatGihTmAJPc+yhdjaZyWN9+SW+nLoDgr19LYXrt2bbmWGc4959LQL34vqHUft3wfkC/qQCzvl4PtQ/2zaLH6L5DMf/vtt+r88883/5YDX9I/Q0mZtkh/JXJgPNjJqeeff97cQy33lMu91Yg8x0+rx1tZlzLKpVbyWO5tlHuy5J5D//nk3mfhf2mLdXlWWcjl4tbr5JKwDz74QN9yyy26Z8+eeujQofrXX3/VBw8e1L/5zW9OWEe5DMafXEJ6/fXXl/j7yLL8zZ0711xGEuozkPu+RcuWLUPOV6NGDfPZvPvuu2X6bINdOl5SyaVycinsunXrdOXKlYP+P3HJKeWWHPtXqEvUgpXc0yn9LVSvXj3kfHLpqWwb/C9xk8vC8vPzTb79561Zs6a59Ey0adMm4HJRuTTU37fffltqPwulXTpep04dsw7+5B7UCy64IOT/Ezmm3J7vH3/8Ue/fv9+U3LspfQ7ITyH3OIezP5s5c6bJ7cknnxwwv1yyLe677z5bthmhLh2XS0nnzZt3wvNnnnmmeY3cY158muDScSqW9svnnXeemSa3Tfo/f9lll5nn5fYn6zmrvyP5ni6Xd8vtm3J/tlx6vmDBgpCfgXzXP3ToUImZvfLKK80yJHvyWH5/Oy4d9y8uHVcBxRltF5AjV3Kkq/hQFnLUSS538bdt27YSe+osyfLly33/ljPM0lOvRc4ETZ061Vz2OWrUKHXFFVcEvFZ6J5X3kbNFcjT62muv9V1CWtw777xjevitU6eO6tGjhzmrJZe5BCNHDeUSGeklVXosD0XOXMlnU5HLxoMZN26cuRRWjv4dO3bM9uUjvkQjxxUhowl069ZN3XnnneZofDCSXemhWI66+/fcL+1e6VFYnnvyySfVP//5T3MZt5ylts4M+Odejrj/+OOPZlnSw7BcribrII9lPUo7OxeMHP2Xs+RyBuxf//qXuUJHzvbJFS9ymaycTQe8mG/Zx8rVYS+++KIZBkfIGSzJl/QoLqMDBDv7HGx/Jsu66qqr1HvvvWfWU65SkTNicoZMhNpXl3WbURp5j5Lybl31FmodgFjZL8uVXbIvHDp0qLmkW84qyy0ZklG5/Nw/B9b3bTmb/cc//tH8W/Zxsv+TK0xlVJDPPvvshPeQ/eFvf/tbc+a+eGblsnUZQeill14yt3shehxv7cf7ETfrjLD0uF18Xum9z67eTEsqOUouR/tK67hMzogL6XW4tGW+/PLLpqOVYB04WB0ilXYkXerLL7/UO3fu1ImJibae0ZaeGEs6sljS/xNnwig35rg8Z7R79+5tOkaRDlJCzSfbATkDJtuELl26lHjWTJYhnZ9ZpLfUCRMmmH9LL6kyX1pamunUqXjGO3bsaObr379/2Ge0P/74Y9PhYvErX2Q7UdKVL+SY8kq+5UyQ8O8NXEoeiz/+8Y9h7c+ksyXrqhMhHRpar5Fe+yuyzbCKM9qUG8rt+2XpKHT+/Pm+LMpoOjKiwJIlS0wP49Z8cga+pMw3bNjQPC+dFJa0fBkpRMgZ8OLTpOdy+Z1lf2k9xxltFfHijLbHSGcIcua4LOSstH+nRSWR+yjlaJ8cRQ81lp6cEZfxOuV+abnPJRQ5Uy5jYXbs2LHEMfxkGXLEXc6EhyIdMckZKulAxa57VK3OMp5++mlzFPGJJ56wbbmAUzkORY7Qv/HGGya3clYslFdeecVclSIZLWkcTFmP22+/3ZwJaN68ubkf+5dffjFXnEimrbNt0hGL3NspHS75+/rrr81R9osuusgcVS+vxo0bm6tvZB38ydnzBQsWmOUCXs237GOlr4PiHStZnf/JfZfh7M/Gjx9v+mc599xzzZkzudLEGp/ev5O0cLYZZSGdIMp958XVr1/f93sD8bBflr91+V4rV3jJPlL2n5J3OcPtn0UrE+XZFgjZd+/Zs8dc7eVPrj57+OGH1YQJE8y/pawz53KVqXQeJ2fLf/3113L/TgiNhrYLbNq0yfyUTsc2bNjge7527dondMwgjU+rB/DSdO7c2fQ6GMoZZ5xhLhGVDldKI5eRS4dDpbEufylpXqs3ROnQyOqBOJjf//73ZsNn52Xjcgndq6++ai7BGThwoG3LBZzMcTDt2rUzl57KrR3S6UmoWyTkEvA//elP5pLV0jork529tcOXjMo6Ll261FyWKuT2EVHS6AbynHSyGI5Qy5XL4sJdLuCGfEvHpNLbsDRK/b90S0eCoviX4PLsz+RLtFy26t+YlucWLlwY9jajrKRh36VLF3NZq/8B/fbt2/umA/GyXxZyUNo6MC2Xj0vGX3vtNd90q5Pi4geogm0LhDTcJWeyHDmg5k8a5pI/uWxdqjj5vaUDxmuuuSbs3wkl41uJC8ybN8+EQnrO9T8DPGjQoBPmDfceEtmoFO81VI5uy45aeh60uuWX4UTk38V7RZR7tGWjJDvfUMsUcqT8+PHj5h7s8vaGWHyoE9lIypkqO8hRRGlAyFk1OerHUATwWo7Lo2XLluaMlOxA5Sx1qFEA7r//fjMCgZwRe+GFF8r1PvJa2fnL722xGgnSF4MMT2KR7Y0cQZd71cIhX0zki3+fPn3M/eIW+TIi+bZrWwE4ke/333/f3Bct+1D/K0puu+02c/bMf9SPiuzPZJgh2afLWfCCgoKwthnlIVe5yfZFrnR77rnnfAfdZYQSafzT4zjiZb9cnJxNloPccpDa/yqvmTNnmlE0JCPScLbyLdsCMXfu3BOWJftbOQhd0vdrOTB+9dVXn/D83XffbbYHcmKrtJNfCA8NbReQxurf//539eCDD5rLPaQTA+mATC6RLH7USjoUKakDhNJIRyjSeF60aJEJnAytJTs9OaLt3+GRHPWTDZPMLx2VSYNZOk35wx/+YI4G+g+fI5ePyqWan376qdq8ebNpiMvZajkiLl/WS+qUSL4QyM572rRpIddXOnVp3bq16ajNDqeddpq5jFU2VrLT9+8YTkincCtXrrTlvRCfopFjIWeuZDx768i2jDNvjUMrHb7IF2dpzM6ePdsc1Hr22WdN5yj+JJvW2S3Z+co80jiWDlIko/5kh26dvZZpknH5ci9XwciXEmn0yiXn/sPvSWeL//nPf0znTXJJmtUZmgzJJZfEyfi54X7G0gmbXDoun5+8pxyll86d5Eoau7YXgBP5ljO7kg1paMvVGXLGTM6cyZll6YDQ+iJcnv2ZzCsNeJlfGhKyb5XLwWUe+V0s5dlmlJcM4yXrIPmsW7euOWAml7yffvrpvkvYgVjfL1udsMnVoZJ1uQpLTijJd2bJg9zKaZFLxuXA98iRI813bDnbLN+JZd/39ttvB5z0ssj+WS5BL2kYXvn+L4334mT/L+9f0rTykAN/cruokMvv5XZUq7O5r7/+2gwnHM8cv1E83jtrsIbOkc4NcnJy9IEDB/Tnn3+uzzrrLNOxlx2dNdx1112mswXpMEi69pf3eeONN8wwPv7zSccEL730kl61apXpIEE6RcrOztajR48+odOCSy+91HRKtHXrVl1YWKj37t1rOnkI1glEamqqGTJo6tSppa7vk08+aT6jVq1alev3DNYZmgzFEIp0zBDs/4lOlCi35FhKlhWMtS6lDVPivy5WpyRlGcZEhuySDgqlQxXJ8g8//FBiR0ZSp5xyin7uuef06tWrzVAjMgSXdL54+umnl/o7huoMTYYuks6dvv/+ezMcitRnn31mOlkM9f9Ejikv5Fs6/nzkkUfMMmW/Kh2XFe+wrDz7M8nh9OnTdW5urtmfy/Bfo0aNOmG4r/JsM8rbGZpUcnKyfuaZZ8x6yPZg6dKlZlijYMsTdIZGxdJ+2Vo/2W/K92v5zixDVQbbd0nJvk72obItkE6GH3vssRI7B27evLl5r7///e/lWm+7OkML9T3i0RK+X8dTZ2g0tKmYKtloyMZIwlvauJ/BSnpWltfLBo4v6BQV/fLfCcs43eEsgxxTVPTKamhL3iR3kr9wliM9IsvraWhTlLtKGtkyhrfkU06chbOM5ORk83rpaT1eGtqVnD6dDthNLpWTy4XCvV9T7iOX18u4pACcIzm0OrMpL3IMRJ/kTXIn/TGEY/369SX2/QLAeXK7qORTLl8PR//+/c3rhwwZouJFwn9b3EBMsHpvFHIPqfSEXF7SyZvcC2ORZZSlV3YA9pBhvGREBCFD+4XTuys5BqJHhgm9+OKLfY/lHvBwhgqS+zzl3lUh96yWNPwYgOhr06aNb1gxybZkvLxOPfVU1aJFC99j2bfbOXyvG9HQBgAAAADARlw6DgAAAACAjWhoAwAAAABgIxraAAAAAADYKFE5aMCAAeqvf/2rqlevnlq+fLm666671Lffflum10qHV/v27Yv4OgJelpqaqnJzc12bY0GWAe9nmRwD3s+xIMuAfVl2rDO03r17qzfeeMN09S69wQ4aNEhdf/31pje60nqqlI1ATk5O1NYV8LKMjIyI7dgrkmNBlgHvZ5kcA97PsSDLgL1ZdqyhvWTJEnOETY60mRVJSDBDOYwdO1Y9/fTTpR5FKCgoML8gR92A4DmRHWZaWlrEclKRHFvrSJYBb2eZHAPez7G1jmQZsC/Ljlw6LmMkZmZmqlGjRvme01qrefPmqaysrDIvR345NgSAM+zKsSDLgHPYJwPexz4ZcB9HGtq1a9dWiYmJavv27QHPy+OWLVueMH9SUpJKTk4OOJIAwFnlzbEgy4D7sE8GvI99MuA+nuh1fNiwYeZSFqu4fwTwJrIMeB85BmIDWQZisKG9c+dOdfToUZWenh7wvDzetm3bCfPLZTByHbxVcu8IAGeVN8eCLAPuwz4Z8D72yYD7ONLQPnLkiFq2bJnq2rWr7znpsEEeL168+IT5i4qKfPeLcN8I4A7lzbEgy4D7sE8GvI99MuBO2onq3bu3PnTokO7bt69u2bKlfumll3R+fr6uW7duqa9NTU3VQn46tf4U5faKRk4qkuNorSNFeb3cnmVyTFHez3G01pGilMernDlxbkUHDhyoN27cqA8fPqyXLFmi27VrF4lfkKLisqKVk3BzHM11pCgvl9uzTI4pyvs5juY6UpTycJUnJ46No10R1jh/kRyLEPA6L+TEC+sIOM3tOXH7+gFu4IWceGEdAS/lxBO9jgMAAAAA4BU0tAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARjS0AQAAAACwEQ1tAAAAAABsREMbAAAAAAAb0dAGAAAAAMBGNLQBAAAAALARDW0AAAAAAGxEQxsAAAAAABvR0AYAAAAAwEY0tAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARjS0AQAAAACwUaKdC0N0zZ07N+i0mjVrhnzt7t27g06bNm1a0Gkff/xx0GmbNm0K+Z4AYsPZZ58ddFqTJk2CTnvooYeCTjv//PPDXp/rrrsu6LQZM2aEvVwglt17771Bpz3wwANBp61evTrotCeffDLke86ePbuMawfADqH2rV999VXQaVdffXXYbRD8D2e0AQAAAACwEQ1tAAAAAABsREMbAAAAAAAb0dAGAAAAAMBGNLQBAAAAALARDW0AAAAAAGzE8F4ud/rppwed1q5du6DTTjrppJDLTUhICDrtkksuCTrtwIEDQae9+eabId/zqaeeCjpt8+bNIV8LwF6/+93vgk4bMGBAyNd26tQp6DStdVjrE+7rStv2dOjQIei0H3/8Mez3BNwu1HB64rHHHgsrjxdffHHQaf/+979DvmdiIl87gWhq1apVWG2FFi1ahFwuw3u5+Iz2o48+ajbi/vXzzz87sSoAwkSOgdhAloHYQJYBd3Hs0OJ//vMfdemll/oeHz161KlVARAmcgzEBrIMxAayDLiHYw1tCf727dudensANiDHQGwgy0BsIMuAezjWGVqzZs1UTk6OWrdunXrrrbdUw4YNg86blJSkUlNTAwqA88qTY0GWAXdinwzEBrIMxHlDe+nSpapfv36qe/fu6s4771SNGzdW8+fPVyeffHKJ8w8bNkwVFBT4SjYgAJxV3hwLsgy4D/tkIDaQZcBdHGlof/rpp2rq1Klq5cqVas6cOerKK69Up5xyiurdu3eJ848aNUqlpaX5KiMjI+rrDKBiORZkGXAf9slAbCDLgLu4YpyFvXv3qjVr1qimTZuWOL2oqMhUPNq4cWPQadWrVw97uTVq1Ag67eqrrw46TY6UBtO/f/+Q79mjR4+whhRbu3ZtyOXCHUrLcbxnOVLkS1Qwr7zyStBpv/3tb0NeThiuPXv2BJ22aNGioNNyc3NDLveGG24IOi3U5Y4V2U7GK/bJ3nHvvfeGNXxXacN8hvu61atXh3xtnTp1gk779ddfw1ofBEeWEeo7fSgvv/yy7esSjxy7R9tfSkqKatKkicrLy3N6VQCEiRwDsYEsA7GBLANx2NB+9tlnVceOHVWjRo1UVlaWmj59ujp27Jh65513nFgdAGEgx0BsIMtAbCDLgLs4cun4qaeeakJfq1Ytc6nQggUL1AUXXKB27tzpxOoACAM5BmIDWQZiA1kG3MWRhvbvf/97J94WgI3IMRAbyDIQG8gy4C6uuEcbAAAAAIBYQUMbAAAAAAAb0dAGAAAAACDWxtFG9O3evTvotMmTJwed9tFHHwWdNmLEiJDv+bvf/S7otDlz5gSd1q5du6DT6OADse6RRx4JOX3AgAFBp9WuXTus9yxtTOv77rsv6LSvvvoqIuPk1qtXL+i0nj17hr1cwMseeOCBoNO01iFf27dv36DTfv7556DTHnzwwbDH7B02bFhY2xUAwdWtWzfotPPOOy+q64JAnNEGAAAAAMBGNLQBAAAAALARDW0AAAAAAGxEQxsAAAAAABvR0AYAAAAAwEY0tAEAAAAAsBHDe6FcQg2nNXDgwJCvnTp1atBp7777btBpkyZNCjrtuuuuC/meR48eDTkdiJaMjIyg0955552g0y666KKQyw01hM+hQ4eCTnvyySfDGuJPbNu2TYUj1FB9mZmZIV9b2vRgWrVqFdZQZEA0paSkBJ32zTffBJ1Wp06doNO+/vrrkO85ZcoUFY5QQ3Vec801IV/78ssvB502e/bssKYB8e6CCy4IOq1hw4ZBp2VnZ4c9PCDKhjPaAAAAAADYiIY2AAAAAAA2oqENAAAAAICNaGgDAAAAAGAjGtoAAAAAANiIhjYAAAAAADZieC9EzRdffBHW8CU9e/YMOq1NmzYh3zPUcgG7JSYG36QOGjQorCG8EhISQr7nZ599FnTagw8+GHTad999p8JVv379oNP+9Kc/hbU+VatWDXt9Qn1GL7zwQtBpc+fODbncNWvWhL1OQHmEGharRYsWQaf9+uuvQafdd999KtqmT58ecvrll18edNrVV18ddBrDewEq7O/CwTzxxBNBpzE8rj04ow0AAAAAgI1oaAMAAAAAYCMa2gAAAAAA2IiGNgAAAAAANqKhDQAAAACAjWhoAwAAAABgI4b3gisMHTo06LRLLrkk6LTx48eHXG7btm0rtF5Aedxyyy1Bp917771Bp2mtg07btGlTyPfs3bt30Gl79uxR4WjatGnYQ/WFGvorlFCfgZgzZ07QaQUFBUGnderUKei0G264IeR7PvbYYyGnA3Z54403wspG//79g077/vvvlZfccccdQac98sgjYQ1xBsSC0047LezvHqGUNsQlXHhGu0OHDmrWrFkqJyfH7Bx69ep1wjwjRoxQubm56uDBg+Y/ubQvdQCijywDsYEsA95HjgHvsb2hnZKSopYvX64GDhxY4vQhQ4aou+++2xyFbd++vTpw4ICaPXu2Sk5OtntVAFQAWQZiA1kGvI8cA95j+6Xjn376qalgBg0apB5//HFzVE707dtXbd++XV199dXqvffes3t1AISJLAOxgSwD3keOAe+JamdojRs3NvfvzZs3L+DeuqVLl6qsrKygr0tKSlKpqakBBcA5ZBmI3yyTY8Bd2CcD7hTVhna9evXMTznC5k8eW9NKMmzYMLPBsEruTwHgHLIMxG+WyTHgLuyTAXfyxPBeo0aNUmlpab7KyMhwepUAhIEsA95HjoHYQJaBGGpob9u2zfxMT08PeF4eW9NKUlRUpPbt2xdQAJxDloH4zTI5BtyFfTLgTlEdR3vDhg0qLy9Pde3a1fScKOR+EOkd8cUXX4zmqsBlVq1aFXTali1bgk5j6ApnkOWSNWjQwPZlnnrqqSGnP/3000GnjRw5Mui0k08+Oei0Tz75JOzfM9SYv6GW+8QTT4R8z++++y7otKNHj4Y1FvY333yj4h1Zjo6HHnoo5PRQuQm1f5w+fbqKFaE+g2uuuSbotIkTJ6p4R45jW2njZDds2DDotC+//DLoNA6seLChLcMP+Dd+pIOG1q1bq/z8fNNgev7559XDDz+sfvnlF7NhkC+CMubfjBkz7F4VABVAloHYQJYB7yPHgPfY3tA+//zzA46ejBkzxvx87bXXzBGZZ555xmws5AjkKaecohYsWKC6d++uCgsL7V4VABVAloHYQJYB7yPHgPfY3tD+6quvVEJCQsh5Hn30UVMA3IssA7GBLAPeR44B7/FEr+MAAAAAAHgFDW0AAAAAAGxEQxsAAAAAAK8O7wUAseyDDz4IOu3ss88OOu3aa68NOq1y5coh3/PWW28NOu0Pf/hD0Gk7d+4MOi0jI0OFK9RwWqGGIotUhz2PPPJIRJYLlNRZVTi5EKHuvX3qqadUrHjllVeCTrv99tujui6AmyQnJwed1rlz55Cv3b9/f9Bpt912W9BpBw8eLOPaIVyc0QYAAAAAwEY0tAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARjS0AQAAAACwEcN7xaiqVauGnH7FFVcEnXbRRRcFnda4ceOwhi+qiNNPPz3otCNHjoR8ba1atYJO27VrV4XWCyhu1apVQafdcsstQacNHz486LSHHnoo5Hv26dMnrOFCKjKE18yZM4NOe+6556I+hBfgBr169Qo6TWsd8rWrV68OOm369OkqHpT2GQGxrFOnTmEP7zVr1qyg09avX1+h9ULFcEYbAAAAAAAb0dAGAAAAAMBGNLQBAAAAALARDW0AAAAAAGxEQxsAAAAAABvR0AYAAAAAwEYM7+VyiYnB/4sGDBgQdNoTTzwRcrkpKSkqFlSpUiXk9JEjRwadNnHixKDTli9fHnQaQ5AgHAcOHAhrWLCbbrop5HIbNGgQdFrHjh1VtIchufDCC4NO++KLL4JOO3r0aIXXC3BSqKH4SttvvP3220GnHTx4UMWK22+/Pei0hISEqK4L4Kahd4cOHRr29mPKlCkVWi9EDme0AQAAAACwEQ1tAAAAAABsREMbAAAAAAAb0dAGAAAAAMBGNLQBAAAAALARDW0AAAAAAGxEQxsAAAAAADePo92hQwf117/+VWVmZprxXa+++mo1c+ZM3/TJkyerfv36Bbzm008/VVdccYWKV6HGgh4/fnzQabfddlvQaUeOHAn5ngsXLgw6bcKECUGnbdmyRYXrjDPOCDrttddeC2uZ2dnZIaf/8Y9/DDqtf//+Qae99957Qac999xzId/zu+++U7GALLvDpZdeGnL6ueeeG9bYm7/++mtYY32KU045Jei0Tz75JOi0F154Iei0WbNmhXzPL7/8MuR0BEeW7dOyZcuw8lbaOLhPPPGEinelfUbxjhx7X6h9Z5cuXYJO+/7770Mu91//+leF1gseOqOdkpKili9frgYOHBjyi1i9evV89fvf/97u1QBQQWQZiA1kGfA+cgx4j+1ntOXomVQohYWFavv27Xa/NQAbkWUgNpBlwPvIMeA9jtyj3blzZ7MhWL16tblMuWbNmiHnT0pKUqmpqQEFwHlkGYi/LJNjwJ3YJwNx3tCWo3F9+/ZVXbt2VUOHDlWdOnUyl7pUqhR8VYYNG6YKCgp8lZOTE9V1BnAisgzEZ5bJMeA+7JOBOLh0vDT+nUz95z//UStWrFDr1683R+E+//zzEl8zatQoNXr0aN9jOeLGxgBwFlkG4jPL5BhwH/bJgPs4PrzXhg0bTO+3TZs2DTpPUVGR2rdvX0ABcBeyDMRHlskx4H7sk4E4PKNdXEZGhqpVq5bKy8tT8Uou7wlnCK/jx48HnXbhhReGfM9ly5Ypu4XamJc2bFi4Q5FdcsklYQ8p9vjjjwed1qdPn6DTrrnmmpDvGaqzkvnz5wedNmPGjKDT1q1bp9yOLEeG//AtJUlOTg5ruJx77rkn6LRt27aFfM/3338/6LTq1asHnXb33XcHndarV6+Q7/nGG28EnTZixIiQr0X5kOXgOnbsGHRaQkJCWNv+eFKnTp2wPr+vv/46QmsUu8hx7Cjt7//gwYNRWxc43NCW4Qf8G1yNGzdWrVu3Vvn5+aYeffRRNW3aNPNFrkmTJuqZZ55Ra9euVbNnz7Z7VQBUAFkGYgNZBryPHAPeY3tD+/zzz1dffvml7/GYMWPMz9dee03deeed6txzz1U333yzGbQ9NzdXzZkzR/3tb38zl68AcA+yDMQGsgx4HzkGvMf2hvZXX30V8vKf7t272/2WACKALAOxgSwD3keOAe9xvDM0AAAAAABiCQ1tAAAAAABsREMbAAAAAIBYGt4LSt1///1hve7222+P6vBdpQ0bNmnSpJCvbdGiRdBpO3fuDGuorSNHjoR8z+zs7LCWm5WVFXRav379Qr7n1VdfHdY9VKNGjQo67aeffgr5nuedd17I6XC3yy+/POi0qlWrhnxtqCG8pkyZEtYQXaWpV69e0Gm33npr0GkPPvhg0GmNGjUK+Z7SqU8wmzdvDjpt8uTJIZcLlEfLli3DyuLPP/8coTXyllD7x1WrVgWdtnr16gitEWCvUPfRDxs2LKxlfvHFFxVYIziJM9oAAAAAANiIhjYAAAAAADaioQ0AAAAAgI1oaAMAAAAAYCMa2gAAAAAA2IiGNgAAAAAANmJ4L5cP7RNquJCPP/446sONPfTQQ0GnVa9ePeRyd+3aFXTaFVdcEXRabm6uioTjx48HnbZw4cKwppU27FqoIc5q1KgRdNr3338f8j3hbb169YrIcmfOnKmiLdQwf6Gy/Pzzz4dcbpMmTYJOmzBhQtBpK1euDDrtu+++C/meQHFnnnlmWMP61KlTR8WD0aNHh5we6jNasGBBBNYIiK5atWoFnXbXXXcFnXb06NGg0w4dOlTh9YIzOKMNAAAAAICNaGgDAAAAAGAjGtoAAAAAANiIhjYAAAAAADaioQ0AAAAAgI1oaAMAAAAAYCMa2gAAAAAA2IhxtF0g1FjZoYQal/Paa68N+doBAwaENU5opUrBj80sXrw47Pdcvny5igfZ2dlOrwJcqEOHDmGNOyt++OGHoNM+/fRT5SaffPJJ0GlVq1YN+dqpU6eG9dr7778/6LQbbrgh5HsCxU2fPj3otMsuuyzotBYtWqhYEeq7R6htmfj111+DTnvllVcqtF6AG4T6rhvKL7/8EnTavHnzKrBGcBJntAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARjS0AQAAAACwEQ1tAAAAAADcPLzXAw88YIaWatmypTp06JBatGiRGjp0qFqzZo1vnuTkZPXcc8+ZoVXk37Nnzzbd4e/YsUPFoy1btgSd1rBhw6DTfvzxx7CG4SrNhg0bgk4bO3Zs0GkvvPBCyOUeP3487HVCdJFj7wz/N2PGjKDT5P8u2jp37hx02hVXXBF02s033xz25xBq2xJqyJR4QJajJ9R+96yzzgp7yKxQQ2I54aWXXgo6rU2bNiFfO2fOnKDTvv/++wqtV6wjy7Ft06ZNTq8CvHBGu1OnTmr8+PHqggsuUN26dVNVqlQxG9Zq1ar55hkzZozq2bOnuv766838DRo0UB9++KHdqwIgTOQYiA1kGYgNZBnwHtvPaBc/Y9GvXz9zNDYzM1PNnz9fpaWlqVtvvVXdeOON6osvvjDz3HLLLWr16tWqffv2aunSpXavEoByIsdAbCDLQGwgy4D3RPwe7erVq5uf+fn55qdsEJKSktS8efN882RnZ5tLJrKyskpchsyfmpoaUACix44cC7IMOIt9MhAbyDIQ5w3thIQE9fzzz6sFCxaon376yTxXr149VVhYqPbu3Rsw7/bt2820kgwbNkwVFBT4KicnJ5KrDSACORZkGXAO+2QgNpBlwBsi2tCWe0latWplOmWoiFGjRplLYqzKyMiwbR0BRCfHgiwDzmGfDMQGsgzE6T3a/r1T9+jRQ3Xs2DHgCNm2bdtMT4hyyYv/Ubf09HQzrSRFRUWmAESXnTkWZBlwBvtkIDaQZSDOG9qyEbjmmmvMMC8bN24MmLZs2TIT6q5du/p6QmzevLlq1KiRWrx4sYpH0nlFMBdffHFE3nPPnj1Bp/3rX/8KOm3t2rURWR+4DzmOnooMw9W7d++g037++eeg0+RsSDjThHzBC0bOigQjveRGwrRp04JOmzRpkop3ZNk+oXpwfvHFF8Mepk8u4Q1GOroKZvr06UGnyTBQ4eZY/l6Cueyyy4JOW7VqVcj3/OMf/xhyOkIjy7Hrvffec3oV4IWGtlzOIj0e9urVS+3bt88cSRNydO3w4cPmHhD54jN69GjTgYM8lg2HjAdIj4iAO5BjIDaQZSA2kGXAe2xvaA8YMMD8/Oqrr04YhuD11183/7733nvV8ePHzVkIucxl9uzZvtcBcB45BmIDWQZiA1kGvCcxEj0hlkZ6RfzLX/5iCoD7kGMgNpBlIDaQZcB7Ij6ONgAAAAAA8YSGNgAAAAAANqKhDQAAAACAF8bRRtnNmzcvrGkAYsPkyZODTsvMzAz52rPOOivqw4WEulcw1DBG0vttMMWHqilu1qxZQadNnTo15GsBu+zcuTPotEceeSTotAceeCDkcgcNGhR02j333GN7Fkt77a+//hrW7/nEE0+EfE8AiCec0QYAAAAAwEY0tAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARjS0AQAAAACwEQ1tAAAAAABsxDjaAOCwUONdhxonW/Tq1SvotAYNGqhImDBhQtBpM2fODDrtyy+/DDrt6NGjFV4vwEmhxpA+fvx4yNc+/vjjYY+HHe7rJk6cGHTaK6+8EnTa999/H9b6APHgueeeCzqtR48eUV0XOI8z2gAAAAAA2IiGNgAAAAAANqKhDQAAAACAjWhoAwAAAABgIxraAAAAAADYiIY2AAAAAAA2SpARIJTHpKamqoKCApWWlqb27dvn9OoAruSFnHhhHQGnuT0nbl8/wA28kBMvrCPgpZxwRhsAAAAAABvR0AYAAAAAwEY0tAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADAzQ3tBx54QH3zzTem2/Pt27er6dOnq+bNmwfM88UXXyitdUC9+OKLdq8KgDCRYyA2kGUgNpBlwHtsb2h36tRJjR8/Xl1wwQWqW7duqkqVKmrOnDmqWrVqAfNNnDhR1atXz1dDhgyxe1UAhIkcA7GBLAOxgSwD3pNo9wKvuOKKgMf9+vVTv/76q8rMzFTz58/3PX/w4EFzRA6A+5BjIDaQZSA2kGXAeyJ+j3b16tXNz/z8/IDnb7rpJrOBWLlypXryySfVSSedFHQZSUlJKjU1NaAARI8dORZkGXAW+2QgNpBlwBt0pCohIUF/9NFHev78+QHP33777fqyyy7TrVq10jfeeKPesmWLnjZtWtDlPProo7okqampEVt3ivJ6ST7syIldOZYiyxTl/SyTY4pyLsdSZJmilFeyHLkVmTBhgt6wYYPOyMgIOV+XLl3MCp9xxhklTk9KSjK/jFUNGjRgQ0BRUdqp25VjKbJMUd7PMjmmKGcb2mSZolR8N7THjh2rN2/erE8//fRS561WrZpZYTkKF4FfkKLisuzISSRzbNc6UlSsl9uzTI4pKno5IcsUpRyt8uTE9s7QxNixY9U111yjOnfurDZu3Fjq/L/5zW/Mz7y8vEisDoAwkGMgNpBlIDaQZcB7bG3ljx8/Xu/evVt37NhRp6en+6pq1apmuly+8vDDD+s2bdroRo0a6Z49e+q1a9fqL7/8MiJHEigqXqsiOYlGjiu6jhQVL+X2LJNjiop8TsgyRSlXlKOXjgdz8803m+mnnnqqCf3OnTv1oUOH9Jo1a/TTTz9drlCzIaCoyOYkGjmu6DpSVLyU27NMjikq8jkhyxSlXFGOXjqekJAQcvrWrVvNJS8A3IscA7GBLAOxgSwD3hPxcbQBAAAAAIgnNLQBAAAAALARDW0AAAAAAGxEQxsAAAAAABvR0AYAAAAAwEY0tAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARjS0AQAAAACwUaLysNTUVKdXAXAtL+XDS+sKRJtX8uGV9QSc4KV8eGldATfnI9HLv2BOTo7TqwJ4Ii/79u1TbkSWAe9nmRwD3s+xIMuAvVlOUEpp5UENGjTw/XLyi8pGISMjw7UbLyfx+cTv5yO/W25urvJClmP5/8EufEbx+/m4Pcvsk8uOzyd+Px+351iQ5bLj84nfzye1jFn25BltUdIvJ/+JsfYfaSc+n/j7fLzw+xTPciz+P9iNzyj+Ph+3/z7sk8uPzyf+Ph8v/D5kufz4fOLv89lXxt+HztAAAAAAALARDW0AAAAAAGwUEw3twsJCNXz4cPMTJ+LzCY3Pxx34fygdn1FofD7uwP9DaHw+ofH5uAf/F6Hx+YRWyOfj3c7QAAAAAABwo5g4ow0AAAAAgFvQ0AYAAAAAwEY0tAEAAAAAsBENbQAAAAAAbOT5hvaAAQPUhg0b1KFDh9SSJUtU27ZtVbzq0KGDmjVrlsrJyVFaa9WrV68T5hkxYoTKzc1VBw8eVHPnzlVNmzZV8eCBBx5Q33zzjSooKFDbt29X06dPV82bNw+YJzk5WY0bN07t3LnTDEQ/depUVbduXcfWOd6Q5f9HjkMjy+5Gjv+HLIdGlt2NLP8/chwaOS6d9mr17t1bHz58WPfr10+feeaZ+uWXX9b5+fm6Tp06jq+bE9W9e3c9cuRIffXVV2vRq1evgOlDhgzRu3fv1ldddZU+55xz9IwZM/S6det0cnKy4+se6frkk0/0zTffrM866yx97rnn6n/9619648aNulq1ar55JkyYoDdt2qS7dOmi27RpoxctWqQXLFjg+LrHQ5Hl/xU5Dl1k2b1FjgOLLIcusuzeIsv/K3IcusixKq0cX4Gwa8mSJXrs2LG+xwkJCXrr1q166NChjq+b01XSxiA3N1cPHjzY9zgtLU0fOnRI9+nTx/H1jXbVrl3bfEYdOnTwfRaFhYX6uuuu883TokULM0/79u0dX99YL7JccpHj0ossu6fIcfAiy6UXWXZPkeWSixyXXuRYBZRnLx2vUqWKyszMVPPmzfM9J5d0yOOsrCxH182NGjdurOrXrx/wecllHkuXLo3Lz6t69ermZ35+vvkpf0tJSUkBn092drbatGlTXH4+0USWy44cn4gsuwM5Lh+yfCKy7A5kuezI8YnIcSDPNrRr166tEhMTzf0A/uRxvXr1HFsvt7I+Ez4vpRISEtTzzz+vFixYoH766SfznHwGhYWFau/evSreP59oI8tlR44DkWX3IMflQ5YDkWX3IMtlR44DkeMTJZbwHBDTxo8fr1q1aqUuvvhip1cFQAWQZSA2kGXA+8hxDJ3Rlp7rjh49qtLT0wOel8fbtm1zbL3cyvpM4v3zGjt2rOrRo4fq0qWL6UHSIp+B9IpoXfISr5+PE8hy2ZHj/yHL7kKOy4cs/w9ZdheyXHbk+H/IcYw1tI8cOaKWLVumunbtGnDJgjxevHixo+vmRjJEQ15eXsDnlZqaqtq3bx83n5dsBK655hp1ySWXqI0bNwZMk7+loqKigM9Hhido1KhR3Hw+TiHLZUeO/x9Zdh9yXD5k+f+RZfchy2VHjv8fOQ5Ne3n4AenZr2/fvrply5b6pZdeMsMP1K1b1/F1c6JSUlJ069atTYlBgwaZfzds2NA3BIF8Pj179tStWrXS06dPj5shCMaPH2+GX+jYsaNOT0/3VdWqVQOGH5AhCTp37myGH1i4cKEpp9c9Hoos/6/Icegiy+4tchxYZDl0kWX3Fln+X5Hj0EWOVWnl+ApUqAYOHGj+82S8PxmOoF27do6vk1PVqVMnXZLJkyf75hkxYoTOy8szG9C5c+fqZs2aOb7e0ahgZOw/ax7ZKI4bN07v2rVL79+/X0+bNs1sLJxe93gpsvz/RY5DF1l2d5Hj/xVZDl1k2d1Flv+/yHHoIscqZCX89x8AAAAAACCe79EGAAAAAMCNaGgDAAAAAGAjGtoAAAAAANiIhjYAAAAAADaioQ0AAAAAgI1oaAMAAAAAYCMa2gAAAAAA2IiGNgAAAAAANqKhDQAAAACAjWhoAwAAAABgIxraAAAAAADYiIY2AAAAAAA2oqENV0hKSlKTJk1SmzZtUnv37lWLFy9WF1xwgdOrBaCcyDIQG8gy4H3k2Fk0tOEKiYmJauPGjeriiy9Wp5xyinr++efVRx99pFJSUpxeNQDlQJaB2ECWAe8jx87TVHzWhg0b9KOPPura987JydFt2rRx/HOiKLcXWaao2CiyTFHeL3JMqf8WZ7Th069fP6W1Vm3btj1h2po1a8y08847L+D5SpUqqS1btqjPPvvM99xll11m5i2p3n333TKtS9OmTVXNmjXV2rVrbfjNgPhCloHYQJYB7yPH8SvR6RWAe8i9GyItLS3geQl2s2bNSpx21VVXqVNPPVUNGjTI91zr1q3Nz7vuukvt3r07YP6VK1eWuh5Vq1ZVb731lho1apQqKCiowG8ExCeyDMQGsgx4HzmOXzS0UeqG4M4771Q//fSTOvvss0uclpOTo2bMmOF77txzz1V79uxR48aNC+tekg8++MAcaXvsscfC/l2AeEaWgdhAlgHvI8fxi0vHccKGIDU11fecHE3r0aOHGj16tDpy5EjAtCZNmqhLL71UvfLKK+rYsWMBR9x++OGHcr9/QkKCevPNN80lMDfffHOFfx8gXpFlIDaQZcD7yHH8oqENH+syEv+janfccYd5/u2331b79u0LmNa/f3+zAZg4caLvuSpVqqgWLVqo1atXq1q1agWUHE0L5eWXX1b169dX119/fcCGBUD5kGUgNpBlwPvIcfyioY2gl7ZIcG+77Tb1z3/+Ux0+fDhgQ5CcnKxuueUWNXPmTJWXl+dbxllnnWXG7JNLXnbu3BlQ1n0oJTnttNPU7bffrtq1a2fmlfeSkuEIAJQPWQZiA1kGvI8cxy/u0UbQDcG1116r0tPT1Ysvvmge+28IevfubY6ijR8/PmAZcv+I6Nu3r8rNzQ2YJkfhgtm8ebO5tAVAxZFlIDaQZcD7yHH8oqENn8LCQlPWfSJy1OzTTz9V69ev920I/KetWrVKffnllwHLkPtHZBlyKQyXpwDOIMtAbCDLgPeR4/hFQxsB5H4ROap25plnqs6dO6srr7zSN8064iZH1bKysszwAsXJtF9++YWNAOAwsgzEBrIMeB85jk/co40TLm+RsMsRtXXr1pkjbsU3BDJt//796vXXXy9xQyBDFQBwFlkGYgNZBryPHMcnzmjjhA2B9EzYqVMnNXLkSDMUgP+GQI7EdevWTU2ZMsU89if3m0ixIQCcR5aB2ECWAe8jx/GJM9o4YUPQtm1bM4yA9IboT4Lfvn17cx/JhAkTTnit3D8i2BAAziPLQGwgy4D3keP4REMbJfaM+M4776jdu3cHTLOOsC1cuFCtWLHihNdaPSJKJw4AnEWWgdhAlgHvI8fxS65doOKwNmzYoB999NG4e2+KirUiyxQVG0WWKcr7RY4p9d/ijDYAAAAAADaioQ0AAAAAgI1oaAMAAAAAYKOE/15DDgAAAAAAbMAZbQAAAAAAYqWhPWDAALVhwwZ16NAhtWTJEjO+HABvIcdAbCDLgPeRY8BdHOnuvHfv3vrw4cO6X79++swzz9Qvv/yyzs/P13Xq1HG8K3aKospW5JiiYqPIMkV5v8gxRSlXlWP3aMtRtm+//Vbddddd5nFCQoLasmWLGjt2rHr66adLfX2DBg18A7wDKFlqaqrKzc11bY4FWQa8n2VyDHg/x4IsA/ZlOVE5oEqVKiozM1ONGjXK95zWWs2bN09lZWWdMH9SUpJKTk72Pa5fv77Kzs6O2voCXpaRkRGRHXt5cyzIMuD9LJNjwPs5FmQZiGyWHWlo165dWyUmJqrt27cHPC+PW7ZsecL8w4YNU8OHDy/xF+SoGxD8aFtOTk7EMlLeHAuyDHg/y+QY8H6OBVkGIptlRxra5SVH50aPHl3iL8iGAPAOsgx4HzkGYgNZBiLLkYb2zp071dGjR1V6enrA8/J427ZtJ8xfVFRkCoB7lDfHgiwD7sM+GfA+9smA+zgyvNeRI0fUsmXLVNeuXX3PSYcN8njx4sVOrBKAciLHQGwgy4D3kWPAnRwbguDQoUO6b9++umXLlvqll14yQxDUrVu31NempqZqIT+d7radotxa0chJRXIcrXWkKK+X27NMjinK+zmO1jpSlPJ4lTMnzq3owIED9caNG82Yf0uWLNHt2rWLxC9IUXFZ0cpJuDmO5jpSlJfL7VkmxxTl/RxHcx0pSnm4ypMTx8bRrgjprKGgoEClpaXRWQPg4Zx4YR0Bp7k9J25fP8ANvJATL6wj4KWcOHKPNgAAAAAAsYqGNgAAAAAANqKhDQAAAACAjWhoAwAAAABgIxraAAAAAADYiIY2AAAAAAA2oqENAAAAAICNaGgDAAAAAGAjGtoAAAAAANiIhjYAAAAAADaioQ0AAAAAgI1oaAMAAAAAYCMa2gAAAAAA2IiGNgAAAAAANqKhDQAAAACAjWhoAwAAAABgIxraAAAAAADYiIY2AAAAAAA2oqENAAAAAICNaGgDAAAAAODmhvYDDzygvvnmG1VQUKC2b9+upk+frpo3bx4wT3Jysho3bpzauXOn2rdvn5o6daqqW7eu3asCIEzkGIgNZBmIDWQZ8B7bG9qdOnVS48ePVxdccIHq1q2bqlKlipozZ46qVq2ab54xY8aonj17quuvv97M36BBA/Xhhx/avSoAwkSOgdhAloHYQJYBb9KRrNq1a2vRoUMH8zgtLU0XFhbq6667zjdPixYtzDzt27cv0zJTU1PN/PIz0utPUV4tO3MSiRzbvY4UFavl9iyTY4qKfk7IMkUpR6o8OYn4PdrVq1c3P/Pz883PzMxMlZSUpObNm+ebJzs7W23atEllZWVFenUAhIEcA7GBLAOxgSwD7pcYyYUnJCSo559/Xi1YsED99NNP5rl69eqpwsJCtXfv3oB55X4TmVYS2XDIfSeW1NTUSK42gAjkWJBlwDnsk4HYQJYBb4joGW25l6RVq1bqhhtuqNByhg0bZjp/sConJ8e2dQQQnRwLsgw4h30yEBvIMhDnDe2xY8eqHj16qC5dugQEd9u2bebomXXJiyU9Pd1MK8moUaNUWlqarzIyMiK12gAilGNBlgFnsE8GYgNZBrzF9pvEx44dq7du3aqbNm16wjSrs4Zrr73W91zz5s3prIGibK6K5iTSObZjHSkqHsrtWSbHFBWdnJBlilKOVzlzYu+bjx8/Xu/evVt37NhRp6en+6pq1aq+eSZMmKA3btyoO3furNu0aaMXLlxoKkK/IEXFZVUkJ9HIcUXXkaLipdyeZXJMUZHPCVmmKOWKcrShHczNN9/smyc5OVmPGzdO79q1S+/fv19PmzbNbCwi9AtSVFxWRXISjRxXdB0pKl7K7VkmxxQV+ZyQZYpSrqjy5CThv//wFOkVUTptkPtJ9u3b5/TqAK7khZx4YR0Bp7k9J25fP8ANvJATL6wj4KWcRHwcbQAAAAAA4gkNbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARjS0AQAAAACwEQ1tAAAAAABsREMbAAAAAAAb0dAGAAAAAMBGNLQBAAAAALARDW0AAAAAAGxEQxsAAAAAABvR0AYAAAAAwEY0tAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARjS0AQAAAACwEQ1tAAAAAABsREMbAAAAAAAb0dAGAAAAAMBGNLQBAAAAAPBSQ3vo0KFKa63GjBnjey45OVmNGzdO7dy5U+3bt09NnTpV1a1bN9KrAiBM5BiIDWQZ8D5yDHhDRBva559/vvrzn/+sli9fHvC8bBh69uyprr/+etWpUyfVoEED9eGHH0ZyVQCEiRwDsYEsA95HjgFv0ZGolJQUnZ2drbt27aq/+OILPWbMGPN8WlqaLiws1Nddd51v3hYtWmjRvn37Mi07NTXVzC8/I7X+FOX1siMnkcyxXetIUbFebs8yOaYo7+fYrnWkqFiv1HLkJGJntMePH6/+/e9/q88++yzg+czMTJWUlKTmzZvney47O1tt2rRJZWVllbgsmT81NTWgAESenTkWZBlwBvtkwPvYJwPekhiJhfbp00e1adNGtW3b9oRp9erVU4WFhWrv3r0Bz2/fvt1MK8mwYcPU8OHDI7GqAKKUY0GWgehjnwx4H/tkwHtsP6N96qmnqn/84x/qpptuMqG3w6hRo1RaWpqvMjIybFkugOjlWJBlILrYJwPexz4Z8CbbG9py+Up6err6/vvv1ZEjR0x17txZ3X333ebfcnRNekasXr16wOvkNdu2bStxmUVFRaYHRf8CEDmRyLEgy0B0sU8GvI99MuBNtl86LveNtGrVKuC5yZMnq9WrV6unn35abdmyxQS7a9euvt4Qmzdvrho1aqQWL15s9+oACAM5BmIDWQa8jxwD3mR7Q3v//v3qp59+CnjuwIEDateuXb7nJ02apEaPHq3y8/NVQUGBGjt2rFq0aJFaunSp3asDIAzkGIgNZBnwPnIMeFNEOkMrzb333quOHz+upk2bZi51mT17thowYIATqwIgTOQYiA1kGfA+cgy4T8J/x/nyFBl+QI7WSccN3E8CeDcnXlhHwGluz4nb1w9wAy/kxAvrCHgpJxEbRxsAAAAAgHhEQxsAAAAAABvR0AYAAAAAwEY0tAEAAAAAsBENbQAAAAAAvD68F7yjfv36qkaNGiopKUlVqlTJDB1x5MgRdejQIfXrr7+aeeS5gwcPKq0914E9gDKQ7FeuXNn8FOnp6ap27drmpzxv2b17t/ruu+/Mv2V7UFRU5Ng6A/ifKlWqqGrVqqmmTZuaHnOtsZmlNm3apI4dO2Yye/ToUfblgAfI/jghQQaPUqpFixZmf/zNN9/49rtk2R1oaCOkCy+8UGVlZZkAWw3tnTt3mh3z3LlzzTyFhYXmMaEGYo/kXr6kn3zyySox8f93Gd27d1edO3dWPXv2VFWrVvXNu2TJEtWnTx+zHZAv7nIwjm0C4LyUlBR1xhlnqKFDh6qzzz7bPJedna3WrFmjJkyYoA4cOGCe27t3r9mXA3A32S9bB7pvvfVWddVVV6krrrhC5efn+7Is+2E4i4Y2ACBs1hF1AAAA/A8NbYQkl5rJgOxyqZmc2bLOVMml43J0XMil5HJpuRw9swZuty4vB+Atctb6pJNOMiXkjPUpp5xitgXWGW25wsW6/NT/jLXM27hxY/OcXOkiR9Y5OwY4Q/IqZ71EzZo1VaNGjUxuZX8t5N+1atVSTZo0Mftrye1//vMfMgt4gJzNtvbJ8m8pybZkXrLMQXB3oKGNkPd9nHvuueZSlOrVqweEVua57777zL+l4S1fqGfPnq3mzJljntu6dataunQpl60AHiI76jp16phbRtq3b2+ek3s6L7/8cnPbiH/+rfJvaLds2VK988475t95eXnqyiuv5FJUwME+VjIyMsy/u3Tpov72t78F7N9PO+001aFDB3XDDTeYx7K/lltCfvzxR0fXG0Dp5AC4dUBc+lKS7+my/7b6UpETX+x7nUdDGyeQL87Wl+ePP/5YrV+/PuA+TAmxHDWTkIvk5GR15plnqgYNGqibbrrJPLd9+3aVmZmpZs6caRrdxZcLwB1kB23dsyn3YcsXcjkrLV/CremSd9lpy5UqYsuWLSbj1j1gsk2Qvhxkm2BtF+SeTzmybu30AUTvgFndunXVJZdcorp27Wqek7PZsq/2P2AmDW7Jr+yj5Qu51dkpAPeTq0qlYS2kc1LJr+yXd+3aZZ4jy+5AQxsn8G8Mf/HFF6ZK6lhFjpYL+WJ94403mrNgbdu29fU+LGfDv/32W3NmS1i9mgJwDzkKbp29liz369fPXCYuX8r9ScP58OHD5t8///yzWrVqle8Lunyxl52+bBfkclT5Ai9H2v17KgcQHZI7ub1DDn7Jvtmf/5Vp8m/ZJ2/evNnc6iFf1OWn9TwA92rYsKE6/fTTfQfEJbNydak1IhDcgW9AAAAAAADYiDPaCItckmJ1fCZntOTMtRwFt854ySWjcrm5nOGWI21CzoDJMGAAnCFnl6XzI8mq/LtVq1bmTPRvfvMb36Xjcpm4jMNpDfcjR8cluzt27PDle926dSonJ8ccPZcrVeQMmgwTJLmXTpcAOEeuJpGz2XLGyzozLXmVMe6tM9dCznrL/lm2CUKel9cUFBSYvANwL7lsXPJq7bvhTjS0ERb5Ii73glikAb1y5Up11llnmcdyz+e1115rLluz7hMZM2aMubfT/x4xANEjPZQ2b97c/JSG9l//+lfVrFkzX4dJQr6Yb9u2zZRYuHChGj16tLnvS76kW/P4k4a7LFemt27dOsq/FYDit4Pcdtttpt8Ua38rHZzdf//95rYu2X+Ljh07mttG7rnnHnPbh8wrB91kn01DG3Av2X/Lvvu8887z3aPN7R7uREMbtpCAS6dp1pfzZcuWqc8//1wNHDhQtWjRwjwnvZvK2TLpIM06MwYgcqQBbN2TKZ0inX/++apXr14mh/K8NLDl39bZa2lM/+Mf/1AbN270dWIoV67IWW25csXakcuZayk5oi7LkTPacgbNv5EtXwRkumSdvAORJaMDSOPaamjLkF2yT54/f755TkYBkf5S/HP8zTffqNWrV5v9tRx8kyzLAfJTTz3VHDgX0vi2rl4D4DzZZ0tfKJJx6YhYyHfvDRs20AGaC9HQhm0OHjxoSkhvxPKlXcbmtMb5k8vT5Ag7nSMB0eHf8ZH0QixHwOVqE7m01BoFQHbMVkNb8irj6FqXhgcbLUCWa423bZ0dl0vG5Qu+/zzSoZqVfwCRI5eOWleUydlpKTnAZXVG6n9FikXObsu+Wp63huu75ZZbfONvS+6loU3naIB7SE4ln1bno0KuFt2zZw85dSFaPAAAAAAA2IhTDYgI6SBJzm7LMECWevXqqSuvvFK988475vI1IWfTOAIHRIaMh211kiL3Yl5wwQXmLLN1hmrJkiVq7dq15j5sIZnNzs42nSFZ93Zal5/LcH5yBlvIWNtymbjcFyZH12W63NspZ7WtK1ZkqLChQ4eqDz74QL3//vvmOesMGQD7SNbkNhC5WkVIHuUea+mk9MMPPzTPBRvyR/IoZ7WtDhK//PJLs42wzo7LWXG5tFz26QCcJx0Ny/dpuYTcIhn997//zW1aLkRDGxEhO2/pcEUuQbUa1dK7sdyvLV/OrUtad+7cyT0lgM2s+6blvk25T1rIl3C5dFy+MEs+5ecPP/wQ8GVcni++o5adeVpamlmWdWn4ZZddpi699FLTiLeyLJed+9/PKc9fccUVpuE+a9Ys85xsC4pfvgogfJIzuadaDqpZPRBLhuUWECm5N1uEaihLdq1lycFxuc3EarRLnmU7QUMbcIdq1aqZrEuD2yIHzBcvXuzr6BDuou2uBg0a6DfffFPv3LlTHzx4UK9YsUJnZmYGzDNixAidm5trps+dO1c3bdq0zMtPTU3VQn5GYv0p+yolJUVXr17d1PPPP2/+zydPnqxffPFFPX78eH3aaac5vo6xWhXNSaRzbMc6UsE/1+bNm+vPP/9c79q1y9SBAwdMLV26VC9atEh//fXXulWrVjo5OfmE11eqVEknJiaa6tKli543b57esGGD+VuQ2rdvny4sLNRFRUWmDh8+rF9//XX95JNP6mHDhpkaOXKk/vHHH/Wzzz6rL7zwQlMtW7Z0/LPxYrk9y+TYuZKMzp8/XxcUFOgjR46YWr9+vW7durWuVatWuZaVkJCgu3fvrocPH653796t9+zZo1euXMn/q01lR07IcnyWZLNy5cqmZJ/82Wefmf36sWPHTN11111mmtPrGS+VWo6cVIrEJUxyGaKcpZSzGXL50eDBg02nG5YhQ4aou+++W/Xv399czigd8cyePdtcroTYIkfX5Gi5lHXmWi4/tTproWM0dyLH3mZdBipHvqWzFCnpPMU6ky1nlqUkl8HOMFuXjFtntP3LuvzcnyxHlmd1iihlnQWTzpWk5Cw7oossxzbJoeRb9qdWZiXn+/fvD/vslmw75GoVKWu5cB5ZhpB9qezb/b8/c1tWHF06LvfkSe93f/rTn3zPyVAx/gYNGqQef/xx3+WEffv2NWMyX3311eq9996ze5XgIrIxsL4MsPN2L3LsbaVlyz+DsrMuvoOW56xGsXUPtj+Z33/HbjXgrZ9Cpsu//eejP4boI8uxycqkfzb9c1bSaAHlZb3e2laQX2eR5fjl/53ZP4/sW+OwoX3VVVeZo2fS+U2nTp3MEDETJkxQr776qpku9xFJpzrz5s3zvUY63pH7iGQcVjYEsUWOvFobB/lbkHu25SisfHmXL+FytBzuQ469Tc5eSF8IxYfWkrPa0k+C1QiW+6yt+7Qt0sCWsbZ79OhhHsv9ny1btjSvtUgnat9//735Mmfd3ynDCMlZbauhLfePbdq0yfztWF8GrXkRPWQ59kiuJZPWlSKStfz8fN/Y15JFaVxVJG/WsF6yr5b7QeXvxv/MKaKPLMcv6fxMhscV0hGp9KEgVzdIp4dC+kKhsR0nDW3p8OrOO+9Uo0ePVk8++aRq27ateuGFF8wlTG+88Yb5YxGyE/Anj61pxcmli/6XvVjjxsEbrPDLl3DppEUueZEv89aOHO4TiRwLshy9A1xy6ag0dK3PW/5f5LJvyZ+Q/GVmZvouEbWek//j888/X7Vp08Y8J6+RL/KrV6/2dXQmX9ykl9Mff/zR13ma5Nt/Ry8Nc/niL+shX/aE1TEiood9cmyRfabcfnXxxRebXMq+VA5YS8/h1gEzGTNb/n/Leymp5Fca7P4Nank/+b8uftAO0UeW41eNGjXMgRSRnp5u8rhq1Sq1Zs0a89y2bdscXkMEY/uWU45+fvfdd+qhhx4yj+WLWKtWrcz9IrIhCMewYcPU8OHDbV5TANHMsSDL0SFfuqX3YBlaS85wiGuvvdbcs+f/hfnmm282jV+5n9pqoEvjXL6UWa+zDoZNmjTJnMW2ejjNzc0NuQ6yLOn1GM5inxxb5ABWrVq11GOPPWa+fFv/xwsWLFAvvviieWz1wRCOFStWmHuBrfs/6UfFPchy/JKrSi688ELfv+VgmFxRJrkXjArgXrZvQeWSJTnK4k++8J122mkBR13kiIw/eRzsiMyoUaMCOuKR8SIBRE4kcizIsjuU5UoS+lGIDeyTY1ekM0r+3YUsA95j+xltuWdA7gH017x5c3OWRGzYsMFsLLp27aqWL1/uu1RFzrRYR2OLk8tiGBvOPeRSNTmyat2zKTtj+becKfO/j7M4OUoul7rRGZr7RSLHgixHj1wGKpdt79mzxzyW/y/5f5P/J+sslXyxEv5nr+QyQv/eweWScDnjLb3XWme+uQTcO9gnxxbZx1r7Uf/bsuR+bCuXduTTWjb3fboHWY5Psl+W20XkO7R1ub9ctSZXjZHPOGxojxkzRi1atMhcjiIdNrRr107dcccdpizPP/+8evjhh9Uvv/xiNgwjR440lyHOmDHD7tVBBMjlajVr1lRNmjTxhf7000839w81atQo6OuaNWtmOnOwhhOSS12kcU5vpu5Djr3Nutf6k08+8R3Qkv9HaVhL77NWY1qGgZHLxP07JaxevXrAQTC5THzatGnqs88+83VqRl69gyzHFrlsVDpCki/fVq/Dcjmx3J8tnWNZKpJR/x7Lybp7kOX4IzmXfbIcLPnDH/5gnpOrGt59912Tdy4Zj8OGtmzwr7nmGnM5yiOPPGKCLsMNvP322755nnnmGfPFbuLEieYIjdxj0L1796DjucI58sVcGtXy5Vwa1PIFXB5Lh0pyn5iQL+zy/yjPW0fcQp3Rts6WyQZCGt/SwZJ1RFZwtsx55Dg2+O+EraG3Fi9e7BvTWnbeZ555pjlLEuwKE/m/Pffcc9Wnn35qzpYIOZJOTr2BLMeWiy66SF1++eW+/bH1fyz3VtvRKJaD5nLAnCvP3Icsxx+r40PJpfXdWc5my9+C1Tkp3E97rVJTU7WQn06vS6xXw4YNdZcuXfS6dev0jh07TBUVFeljx46FXUePHjUlyxk2bJi+9NJL9UknnWSqatWqjv/OsVJeyIkX1jFWq1KlSnrIkCF62rRp+siRI75cFq+9e/fqtWvX6u7du+uaNWuaSk5Odnz946ncnhO3r18s1cSJEwP2o4cPH9Z//OMf9dlnn13hZSckJJicP/bYY75twpYtW3RmZqauU6eO47+718sLOfHCOsZT1apVS48aNUovWrTI9x161qxZ5rs5+2HliZzQnSQAAAAAADZiYEScQO7ZtMZVlPF0zznnnIBLvrdu3WouXdmyZYvvNXIpafH7SuTyVLk01brE3Lp89ddffzWXsMplbnJft3TuIu8pj+W+UrkETsbylBLWfWgAKk7yJpeDSp7r1q3ry6eVM+n0TPJrdZAmz8mliHLJqjUWq4ypLbd7SEatbMql5NzPCdjP/xJu66f/PdTS4aHsk+3EPdqA8+QWEbnFUvbXmzdvNs9JD/LSMSnfi72BhjZO0Lp1a/MFXPzpT39SHTt29PU2LMFesmSJGU9XxugV0miWe0X8d8jSUJf7u1977TXf2H/WvDK2rnW/0KWXXmo6epASMjbg008/rZYuXaqWLVvm+wLP/UVAxcmX9JNPPtn8lANhchBNduKSa3lODnRJByuyc7cOtsk9YrVr11ZDhw71Zfyf//ynGcNT7hOzDrLJNoCOWQD7WZ2GCvkpefU/wCX36soBcDvR0AacYx3oloPc0ifDunXrfGNmy8moXbt2ObyGKCsa2gjYmUsnZ9Kz4W9+8xvznJzBkkAPGDDADBUkO135Il5QUKB27Nhh5pHn5Au2fAGwNg7y5b13797q1FNP9S3/p59+Mr0ljh071ixLSAO7fv36qnPnzuaxnDnv27evuvbaa9XOnTvNc/J+X331lelFU95XyDrJUXy+2ANlJ3kbN26cGfJF8iqdnEnD2+plWHI1fPhwc2DNylZmZqa6/fbbzWut4fu6deumzjvvPHPAzRpiZObMmeaIu3whAGAfuerEOvAl+2g5ICajAMhPyam1X7SDdKBljTxgNerlDBodLwHOkRE/vv76a/Pv9evXO706KAca2vCxxsaWy7nPOuss85y1k5WeiuVss5DxOks6ym01sq2jcE2bNjVnwyzSMJbLzeVonLXTlsa9NMZl2C95vezk+/TpY/5tje0oDWy5TNV6fyENdXpDBcpHzlTLkDAyRJ+VU2uYICFXjsj4q/LF3bqKROaRy8nlC751+4gcHJOSL/nS0JbthFyFYt3uAcA+0si29qWyz5S8yZBNklErg3ZuI6weza197OHDh219DwDlI/tg6+SW3beJILLoDA0AAAAAABtxRhs+coZKznb5j4X98ccfq/nz55szXNYZ5uJns+WotxwBl0tJpYSMyyuXpcpRcOso3MKFC9W///1vc3TcIkfm5SzYF1984bt0XC5fTU9P990nLsuWTtVatWrlG7tXLm2VI3zZ2dm+I+2ybOloDcCJJEdyVloyZp0dk7PZ27dvN7dmCMmP5FGuWrEuHZcz3E8++aS56sR6nWwnJOMZGRkm/7JNkFtOfvzxRzPWttWxmiyLezyBipErUKTPEyH5lf2gXB1mdYhk19lmyXKHDh3U2WefbW71EnJFm+z76XgJiA65tatJkybm33LFp1xJJleEyuXjQv4N76ChDZ86deqYjsusHbqQS8al0zNp1PrvaK1ei4X8lNe2bdtWXXXVVeY5aSSffvrpas2aNb77x+R+zkWLFgUsR/4t0+ULurVc6SxNLjuXL/JCLmXv1auX+bIhjQXrPaUhIJ1DSMNdvszLAQEa2kDJpJEs2ZYv6nIpqv992fPmzTPzSBblsjT/vg/kfjAp/4a2fPG2DoDJpazSYO/atavpNE3u1ba+/NOPAlBxcs+0ZEtIfiVT0oeJ3EIlWbMOQNsxEoF0htqwYUOzPxXyPlY/DACi09CWHEom5bu1/JTbLeUgtqBzYG+hoQ0fadjecccdvsaskDNS0hlZ8aPZ0oGSdcRNGtWPPfaYObtlfRmQM2JyX/WDDz7o6z1cvnSXdlRcdubSqJfGtgwhJGTnP3HiRPNlwLoP3Ppy779MeR2AkkleZect2fEnfR9YZ7TlC3uwjMqZLeueTRlNYM6cOWrEiBG+A3OybOnb4d133zWP5UuBHCCThjv3dwLha9y4sWrUqJH5d82aNU2G5Qu4XKEieS2e6fKQ/erFF19sDr5JvqVRL9uETz75xEyXxnxFG/IAykYyKN/Fx4wZYx5bfajIPtTKIQevvYWGNk7oddw60yVkJ15SqK3hgYQ0zGXnL41vq5Fu9YYqX7KtDpKsS89LI+8tGxT/nbs0ov2HOJF/SwNcnudIO1A62WFbX6b9ScatbIb6Qu3fAJdLVq3bSaSs3okll7ItsA62+XeQCCA8kitrf2tlSn5aV5VVhGRXtgtSskzrVhDrFq+y7rcB2EO+R1tD3koWJYN8z/UuGtoolbXj9X/sv5P3/zJdWgPdTmx4gLKzvkT78z+o5v9cWVhj+VpjcJfEv+diAOHxz6n89B9T2w7Fc2odVCtp+wAguoqPaU8mvYWGNnxK2qlKY1qOdEvnZPJFXep3v/udat68uRlf17r0TDpsWLt2rRmKS8h42TNmzDDPWUfGK9qZipxts74MWI14NjhA2chl3R07dvQN3SNkSK5vvvnG17dBWfMkZ7TlUvLnnnvOd3/niy++qFq2bOkba1tuI7nyyitN3wzSoRqA8EhOrVup5BYN2f9K56Byr6bsV6dOnRr2smV7YPXNIjmWS8U3bNhgxuyV7YHsa7lUFYgOuWxc+iWySMbl9kvJpNXfEd97vYWGNnzkHhAJsv94uc2aNTO9kPo3tLOyskxnKdI5ktUAloa1jI+9cuVK89y6devMv+3uRIUjekB4ZDxsGVHAugJFMiQHwmQHXpZ7qK38Wx0yyXZCOm2xGtrWrR3WmXPZhsh7Wg1vAOGRjpCs2zrki7dkTfbB1i1W/v2qlId0MCqjjcgBMsmykNu9ZIxu6STROvjO/haIPNlvyj5T9q0Wybf0d0LHot5FQxs+EuSff/7ZnPmS+63FPffco+666y7zpdn/0jLpLEU6LLN6JX322WfV5s2bfb0iAnAXOfNlDbtlnan68ssvzRnnspAex61Gs4woICMDDB482LetkM4Q/a9akfvKZJvAUCSAfeRAlhzoklE+rE6S5Mt58Vu8ykKuSrvooovUpZdeanIsr3/jjTfMKCD+w3ACcIbkW0b9kO/c8CZ6qsEJShonu/i9YGW51xOA+9mdW//lsV0AIseOPhCsZdCXAgDYjzPa8JEj2HKvZq1atUyPwcLq7Mh/+BD54ixH13bs2GEeS6/iVi/jANyreEblTJiUf+/FVo/+1nPyWM6gyXzWJar16tUz92DLY+sst3xRl8vcrGH25BJU2aawXQAqxn8UDv88WQexJIfSl4p1C4h15UpJt35Ilq1sS8/Gcm+2XI4uz8lr5PYxuU8bgPOsIW/p/d+7aGgjoMOVO++804y3K1+qg5HQy5doubdTyM5ZOkfizBXgXtLo9c+pfOnu2bOn6X9hy5YtAR0bymXg0pgWMn6vdKImB+CshrZ8WZd/+3esJj83btxoxtiW95D7SpcsWWLeE0D45JYsK2fSEJbGtn/P4HIZuWRS+kYR0iiXg+b+B8xkn163bl3VqVMnk3nRrVs3de6555oOEaWxLcuaNGmSr1NTAM6S79v/+te/fPtoeA8NbfjIjlbOTvuPkV0SOWouX9r9j3pXtEdxAJElB8bkfuzu3bv7xtOWg2r+Z6Wl8S0dpslZLikh42JLx0vSQYvVGZr0OC59M8iVLdYZtq1bt5qaP3+++cIu2xPZTrBtACrGP0OLFi0yHZd17drVZFeydvnll6vzzjvPN3qAdfBbWJmVeeV1derUMfkXmzZtUtnZ2WaZVselkm3OngHuYPXDwH7Uu2how0e+MMsl4/JlGUBsWbNmjdlpW5egisaNG5uSM9ahFO9oSbYRMmSXnPmS5cm0hQsXqu3bt5sGOIDIkANZctvW+eef7+uIUIbRkzPX/hktqXM0eU7OjFm3d7zzzjtqzpw56ocffijTyAMAgPKhMzQAAAAAAGzEGW0AiANyGbcMtSVnr+RMmJzdatCggfl3qD4Z5PJwuexcXmtdUipD+8mQIzk5Ob7hwuTeUS45BSJLzkbLJeLLli0zQ+5Jjjt06OAbnsti3dNtPSf5lT4UVq9ebfpPEHJFitwuxmWpgPMkq5JTuWLFurJUbuWg/yPv03ZWpUqV9GOPPabXr1+vDx48qNeuXasffvjhE+YbMWKEzs3NNfPMnTtXN23atMzvkZqaqoX8tHv9KSpWqiI5iUaOK7qOVPnrpJNO0r169dLXX3+97tOnj/7oo4/0qlWrdGFhYdD6+uuv9e9+9zvdpEkTXbNmTVPJycmO/y7xVG7PMjmOblWpUkW3a9dOX3jhhbpjx446OztbHzlyxJfZoqIi81h+Ws/Nnz9f//73v9ennXaa2Q5IJSYmOv67xFNVNCdkOT6qVatW+rXXXjM1ZswY3bJlS12jRg3H14tSYeXE9jPaQ4cONT1X33zzzeqnn34y9xFNnjzZ9FI9duxYM8+QIUPU3XffbeaRMyUjR45Us2fPVmeddZbpQAeAs8hxbJL/F+kJ3Bo3V3oplk7OpIKxzoTJGWvrPk6G7PIOshx7pF8E6cRMOjqTHN9xxx0mw9aZL/8xsf3PaG/evNlcoWL9n3KmzFvIcnyQTgpHjx5t/i1XiUm/Clwt5m22tvLlDMmrr74a8NzUqVP1m2++6XssR9oGDx7se5yWlqYPHTpkzrDYfSSBouK1KpKTaOS4outIUfFSbs8yOaaoyOeELFOUckWVJye2d4Ymw0TIsBPNmjUzj2WMxosvvlh98skn5rH0cFu/fn01b94832vkTImM4ZyVlVXiMq1hKfwLQOREIseCLAPRxT4ZiA1kGfAe2y8df+qpp8z4q9LhhlxeKENOPPTQQ+rtt9820+vVq2d+yjAw/uSxNa24YcOGqeHDh9u9qgCimGNBloHoYp8MxAayDHiP7We0e/furW666SZ14403qjZt2pj7RO6//37Vt2/fsJc5atQos3GxKiMjw9Z1BhD5HAuyDEQX+2QgNpBlwJtsvW598+bNesCAAQHPPfTQQ/rnn382/27cuLG5rr1169YB83z55Zf6+eeft/3aeIqK16pITqKR44quI0XFS7k9y+SYoiKfE7JMUcoV5eg92tLzZfExGeUSF+kdU0gviHl5eeY+E4vcE9K+fXu1ePFiu1cHQBjIMRAbyDIQG8gy4E22tvInT56st2zZoq+88krdqFEjffXVV+sdO3bop556yjfPkCFDdH5+vu7Zs6cZL2769Ol63bp1ZR6blSNuFBXZnEQjxxVdR4qKl3J7lskxRUU+J2SZopQrqpw5sffNTz75ZDPA+saNG/XBgwf12rVr9ciRI3WVKlUC5hsxYoTOy8szww7MnTtXN2vWLFK/IEXFZVUkJ9HIcUXXkaLipdyeZXJMUZHPCVmmKOWKKk9OEv77D0+RS2FkyALpuGHfvn1Orw7gSl7IiRfWEXCa23Pi9vUD3MALOfHCOgJeyont92gDAAAAABDPaGgDAAAAAGAjGtoAAAAAANiIhjYAAAAAADaioQ0AAAAAgI1oaAMAAAAAYCMa2gAAAAAA2IiGNgAAAAAANqKhDQAAAACAjWhoAwAAAABgIxraAAAAAADYiIY2AAAAAAA2oqENAAAAAICNaGgDAAAAAGAjGtoAAAAAANiIhjYAAAAAADaioQ0AAAAAgI1oaAMAAAAAYCMa2gAAAAAA2IiGNgAAAAAATja0O3TooGbNmqVycnKU1lr16tXrhHlGjBihcnNz1cGDB9XcuXNV06ZNA6bXqFFDvfXWW2rv3r1q9+7d6tVXX1UpKSkV+00AlBk5BmIDWQa8jxwDsancDW0J7fLly9XAgQNLnD5kyBB19913q/79+6v27durAwcOqNmzZ6vk5GTfPFOmTFFnn3226tatm+rRo4fq2LGjmjhxYsV+EwBlRo6B2ECWAe8jx0Ds0uGW6NWrV8Bzubm5evDgwb7HaWlp+tChQ7pPnz7mccuWLc3rMjMzffNcfvnl+tixY7p+/fplet/U1FSzDPlZkfWnqFiusubEqRyXZx0pKp7L7VkmxxTl/RyXZx0pKp4rtRw5sfUe7caNG6v69eurefPm+Z4rKChQS5cuVVlZWeax/JRLWpYtW+abR+Y/fvy4OUoHwFnkGIgNZBnwPnIMeFeinQurV6+e+bl9+/aA5+WxNU1+7tixI2D6sWPHVH5+vm+e4pKSkgIuj0lNTbVztQFEIceCLAPRwz4Z8D72yYB3eaLX8WHDhpmjd1ZJZxEAvIcsA95HjoHYQJYBDzW0t23bZn6mp6cHPC+PrWnys27dugHTK1eurGrWrOmbp7hRo0aptLQ0X2VkZNi52gCikGNBloHoYZ8MeB/7ZMC7bG1ob9iwQeXl5amuXbsGXIYi94csXrzYPJafMgRBmzZtfPNccsklqlKlSuZ+k5IUFRWpffv2BRSAyIhUjgVZBqKHfTLgfeyTAW8rV09rKSkpunXr1qbEoEGDzL8bNmxopg8ZMkTn5+frnj176latWunp06frdevW6eTkZN8yPv74Y71s2TLdtm1bfeGFF+rs7Gw9ZcqUiPT2RlHxWqFy4oYcl7aOFEV5I8vkmKK8n+PS1pGiKBVOTsq38E6dOumSTJ482TfPiBEjdF5enhl6YO7cubpZs2YBy6hRo4YJf0FBgd6zZ4+eNGmS2chE6BekqLisUDlxQ45LW0eKoryRZXJMUd7PcWnrSFGUKndOEv77D0+RS2ak0wa5n4TLXADv5sQL6wg4ze05cfv6AW7ghZx4YR0BL+XEE72OAwAAAADgFTS0AQAAAACwEQ1tAAAAAABsREMbAAAAAAAb0dAGAAAAAMBGNLQBAAAAALARDW0AAAAAAGxEQxsAAAAAABvR0AYAAAAAwEY0tAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARjS0AQAAAACwEQ1tAAAAAABsREMbAAAAAAAb0dAGAAAAAMBGNLQBAAAAALARDW0AAAAAAGxEQxsAAAAAABvR0AYAAAAAwMmGdocOHdSsWbNUTk6O0lqrXr16+aYlJiaqp556Sq1YsULt37/fzPP666+r+vXrByyjRo0a6q233lJ79+5Vu3fvVq+++qpKSUmx5zcCUCpyDMQGsgx4HzkGYlO5G9oS2uXLl6uBAweeMK1atWqqTZs2auTIkebntddeq1q0aGE2Hv6mTJmizj77bNWtWzfVo0cP1bFjRzVx4sSK/SYAyowcA7GBLAPeR46B2KXDLdGrV6+Q85x//vlmvoYNG5rHLVu2NI8zMzN981x++eX62LFjun79+mV639TUVLMM+VmR9aeoWK6y5sSpHJdnHSkqnsvtWSbHFOX9HJdnHSkqniu1HDmJ+D3a1atXV8ePH1d79uwxj7OysswlLcuWLfPNM2/ePDNP+/btI706AMJAjoHYQJYB7yPHgDckRnLhycnJ6umnn1bvvPOO2rdvn3muXr16aseOHQHzHTt2TOXn55tpJUlKSjLLsqSmpkZytQFEIMeCLAPOYZ8MeB/7ZMA7InZGWzpveP/991VCQoK68847K7SsYcOGqYKCAl9JRxAAIs/OHAuyDDiDfTLgfeyTAW+pFMkNQaNGjUynDNYRN7Ft2zZVt27dgPkrV66satasaaaVZNSoUSotLc1XGRkZkVhtABHMsSDLQPSxTwa8j30y4D2VIrUhaNasmbr00kvNZSv+Fi9ebIYgkJ4TLZdccomqVKmSWrp0aYnLLCoqMhsU/wIQOZHIsSDLQHSxTwa8j30yECf3aMsQBE2bNvU9bty4sWrdurUJfV5enpo6daoJugwtIEfT0tPTzXwy/ciRI2r16tXqk08+Ua+88orq37+/qlKliho3bpx69913zesBRB45BmIDWQa8jxwDsatcXZp36tRJl2Ty5Mm6UaNGOhh5nbWMGjVq6ClTpuiCggK9Z88ePWnSJJ2SkhKRbtUpKl4rVE7ckOPS1pGiKG9kmRxTlPdzXNo6UhSlyp2ThP/+w1OkV0TptEHuJ+EyF8C7OfHCOgJOc3tO3L5+gBt4ISdeWEfASzmJ+DjaAAAAAADEExraAAAAAADYiIY2AAAAAAA2oqENAAAAAICTw3u57WZ0AN7Ph5fWFYg2r+TDK+sJOMFL+fDSugJuzkeil3/BnJwcp1cF8ERe3Np7aM2aNc1Psgx4N8vskwHv51iQZcDeLHtyeC/RvHlzlZ2drTIyMly7wXLzH4ZsRPnsYv+zk/XNzc1Vbh8iwSufp5t47W/RTbz42bk9y+yT4+vv0S289tm5PceCLMfP36ObpMZolj15Rlvk5eWZn/Kf4YX/EDfis4v9z84L6+ilz9ON+Ozi47Nz+3qyT644PrvY/+y8sI5kueL47GL/s9tXxnWkMzQAAAAAAGxEQxsAAAAAABt5tqFdWFiohg8fbn6ifPjswsdnZy8+z/Dx2YWPz85+fKbh47MLH5+d/fhMw8dnF77CGP3sPNsZGgAAAAAAbuTZM9oAAAAAALgRDW0AAAAAAGxEQxsAAAAAABvR0AYAAAAAIN4b2gMGDFAbNmxQhw4dUkuWLFFt27Z1epVc59FHH1Va64D6+eeffdOTk5PVuHHj1M6dO82g61OnTlV169ZV8ahDhw5q1qxZKicnx3xOvXr1OmGeESNGqNzcXHXw4EE1d+5c1bRp04DpNWrUUG+99Zbau3ev2r17t3r11VdVSkpKFH8LbyLLpSPLZUeWnUOWQyPHZUeOnUOOS0eWy64DWTa0l6p379768OHDul+/fvrMM8/UL7/8ss7Pz9d16tRxfN3cVI8++qheuXKlTk9P91WtWrV80ydMmKA3bdqku3Tpotu0aaMXLVqkFyxY4Ph6O1Hdu3fXI0eO1FdffbUWvXr1Cpg+ZMgQvXv3bn3VVVfpc845R8+YMUOvW7dOJycn++b5+OOP9Q8//KDbtWunL7roIr1mzRo9ZcoUx383NxdZLluR5bIXWXamyHLpRY7LXuTYmSLHZSuyXPbqTpalHF+BctWSJUv02LFjfY8TEhL01q1b9dChQx1fN7dtCOQPs6RpaWlpurCwUF933XW+51q0aGFC0L59e8fX3ckqaUOQm5urBw8eHPD5HTp0SPfp08c8btmypXldZmamb57LL79cHzt2TNevX9/x38mtRZbLVmQ5vCLL0SuyXHqR4/CKHEevyHHZiiyHV/GaZU9dOl6lShWVmZmp5s2b53tOLkWQx1lZWY6umxs1a9bMXK6xbt06c9lFw4YNzfPyGSYlJQV8jtnZ2WrTpk18jsU0btxY1a9fP+CzKigoUEuXLvV9VvJTLmdZtmyZbx6Z//jx46p9+/aOrLfbkeXyIcsVR5YjgyyXHTmuOHIcGeS4fMhyxTWOkyx7qqFdu3ZtlZiYqLZv3x7wvDyuV6+eY+vlRvKH2q9fP9W9e3d15513mj/o+fPnq5NPPtl8VoWFheZ+B398jieyPo9Qf3Pyc8eOHQHTjx07pvLz8/k8gyDLZUeW7UGWI4Mslw05tgc5jgxyXHZk2R714iTLiU6vACLj008/9f175cqVZsMgR9R69+5tOrkA4A1kGfA+cgzEBrKMmD2jLT34HT16VKWnpwc8L4+3bdvm2Hp5gRxdW7NmjenNTz4r6RWxevXqAfPwOZ7I+jxC/c3Jz+I9SlauXFnVrFmTzzMIshw+shweshwZZDk85Dg85DgyyHH4yHJ4tsVJlj3V0D5y5Ii5Tr9r166+5xISEszjxYsXO7pubidd4Tdp0kTl5eWZz7CoqCjgc2zevLlq1KgRn2MxMsyFfGb+n1Vqaqq5N8T6rOSnDD/Qpk0b3zyXXHKJqlSpkjnSiROR5fCR5fCQ5cggy+Ehx+Ehx5FBjsNHlsOzIY6yrL02/ID0SNe3b1/TG91LL71khh+oW7eu4+vmpnr22Wd1x44ddaNGjXRWVpaeM2eO3rFjh65du7Zv+IGNGzfqzp07m+EHFi5caMrp9XaiUlJSdOvWrU2JQYMGmX83bNjQN/yA/I317NlTt2rVSk+fPr3E4QeWLVum27Ztqy+88EKdnZ3tteEHol5kuWxFlsteZNmZIsulFzkue5FjZ4ocl63IctkrhSxLOb4C5a6BAweaP2IZ70+GI5Cx1ZxeJ7fVO++8o3NycsxntGXLFvP4jDPO8E2XP+Jx48bpXbt26f379+tp06aZsQCdXm8nqlOnTrokkydP9s0zYsQInZeXZ3ZCc+fO1c2aNQtYRo0aNUzwCwoK9J49e/SkSZPMBsbp383tRZZLL7Jc9iLLzhVZDl3kuOxFjp0rclx6keWyVyeyrBP++w8AAAAAABBv92gDAAAAAOB2NLQBAAAAALARDW0AAAAAAGxEQxsAAAAAABvR0AYAAAAAwEY0tAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARjS0AQAAAACwEQ1tAAAAAABsREMbAAAAAAAb0dAGAAAAAMBGNLQBAAAAALARDW0AAAAAAGxEQxsRM3nyZLVhwwanVwNABZFlwPvIMRAbyLJ30NB2gNa6TNWpUyflJllZWerRRx9V1atXd3pVAFcgy4D3kWMgNpBluE2C/F06vRLx5qabbgp43LdvX3XZZZepP/zhDwHPz507V+3YsUO5xeDBg9Xf//53dfrpp6tNmzaVOn9iYqKqVKmSKioqisr6AdFGlgHvI8dAbCDLcJtEp1cgHk2ZMiXg8QUXXGA2BMWfD1fVqlXV4cOHldOOHj3q9CoAEUWWAe8jx0BsIMtwGy4dd6l+/fqpzz77TG3fvt2E+qefflL9+/c/YT65R+Ojjz4yG5Jvv/1WHTp0SP35z38200477TQ1c+ZMtX//frOc0aNHm/lKumymXbt26pNPPlF79uxRBw4cUF9++aW68MILfdPlkhY52iY2btzou/ymUaNGZb6HROaV18iRuwEDBqh169aZ95o9e7Y69dRTzTwPP/yw2rJlizp48KCaMWOGqlGjRsAyr7rqKvWvf/1L5eTkmM9l7dq15jVyZK846z1kWUuXLlUXX3yx+uKLL0z5S0pKUsOHD1e//PKLWebmzZvV008/bZ4HKoosk2V4Hzkmx4gNZJksRxNntF3qzjvvNOGfNWuWOXLVs2dP9eKLL5o/+AkTJgTM26JFC/XOO++ol19+Wb3yyisqOztbVatWTX3++eeqfv366h//+Ifatm2buvHGG1WXLl1OeC95TjYCy5YtUyNGjFDHjx9Xt9xyi3l9hw4dzAbmww8/VM2bNzfLGDRokNq5c6d57a+//hrWpT0SsrFjx6qaNWuqIUOGqPfff9+8X+fOnU0ImzZtqu666y6z8bn11lsDNpCyYZONmvy85JJL1MiRI1VaWppZjkU2muPHj1dff/21GjNmjLkcRzYsu3fvVlu3bvXNl5CQYD5j2UhMnDhR/fzzz+qcc85R9957r/l9r7nmmnL/foA/skyW4X3kmBwjNpBlshxtco825WCNHTtWC//nqlatesJ8n3zyiV67dm3Acxs2bDCvveyyywKev/fee83zV111le+55ORkvWrVKvN8p06dfM9nZ2ebZRd//3Xr1unZs2f7nhs8eLB5baNGjcr0e02ePNmsn/VYXie2b9+u09LSfM8/8cQT5vkffvhBV65c2ff8lClT9OHDh3VSUlLIz+XFF1/U+/fv981XpUoV/euvv+qlS5cGLK9v377mfb744gvfczfddJM+evSovuiiiwKWeccdd5h5s7KyHP/7oLxTZJksU94vckyOqdgoskyWlcPFpeMu5X8PiBxNqlWrlvrqq69UkyZNzGN/69evV3PmzAl4rnv37ubIkhxNshQWFpojcv5+85vfmCNLb7/9tnkPq1JSUsylNR07djRHpez0wQcfqIKCAt9juexEvPXWW+rYsWMBzycnJ6uMjIwSP5eTTz7ZrOv8+fPN+rZs2dI8f/7556vatWub39V/eXKPTn5+fsC6XH/99eYo2+rVqwN+fzn6J0o6QgmUB1kmy/A+ckyOERvIMlmOJi4ddym5f0MuM5Eu/+WP3J90/+8fpJLG0pP7NeT+ieLkngt/zZo1Mz/feOONoOsi7yf3lthF7tHwt3fvXvNT7h0p6Xm5j8T6Hc866yz1+OOPm0taig+DYD227msp/rvKRkHufyn++8syrUt1iqtbt25YvyNgIctkGd5HjskxYgNZJsvRREPbhc444wxztEuOAt13330mINKF/5VXXmkeF++YQDpoCJe1rPvvv1/9+OOPJc4j92rYyf8oWFmet474SdDlqKNsBB955BGzoZMjcG3atFHPPPNMiR02lEZes2LFCvO5lqT4xgkoD7IciCzDi8hxIHIMryLLgchy5NHQdiHpmEGGEJAeAP3/EMtzmYWMwydHkoqTThD8WUflJFyy8Qnl/29zcY505CCXrFx77bXmchZL48aNA+azxiCU31V6d7RUrlzZdNogwff//Vu3bl3q7w6EgyyXjCzDS8hxycgxvIYsl4wsRw73aLuQdeTJ/94NuW9EeiosK6tLf9mYWOR+jNtvvz1gPukJUS4BkSNuxS+hERI8iwwVIE455RTlls+lSpUqZpgBf9999525VEV+Vwm/f2+M0gujP+mNUT6n4p+LkI2x9C4JhIssl4wsw0vIccnIMbyGLJeMLEcOZ7RdSDpekI4VZPw+GVJAOiWQP9QdO3aoBg0alGkZ8rq//OUvZlgCGX4gLy/PBMHq7MA6eiY/b7vtNjP8gAx3IGPzyRh60kGCHOGTI3HWxkQ2GuKJJ55Q7777rjpy5IhZRxlHLxoWLVpkOlt4/fXX1QsvvGDW/Y9//OMJnUnIesm4fePGjTOdLkjY5UibDF0gGz3/I4dvvvmm6t27t3rppZfM77tw4UKz8ZCOH+T5yy+/3Pd7A+VFlktGluEl5Lhk5BheQ5ZLRpYjy/Guz+O9Shp+oEePHvrHH3/UBw8e1OvXr9d//etfdb9+/U7o/l+69//oo49KXO7pp59uph04cMB0+f/ss8/qa665xiyjXbt2AfO2bt1aT5061XTbf+jQIbPcd999V3fp0iVgvoceekhv2bLFdNlf2lAEwYYfkGEM/OeToRDEddddF/D8zTffbJ7PzMz0PSfDASxatMj8Tlu3btVPPfWU7tat2wlDKkj95S9/Me8vv8+SJUvMa7/99lv98ccfB8yXmJhoPt+VK1eaeXft2mXm+9vf/qZTU1Md//ugvFNkmSxT3i9yTI6p2CiyTJaV8+X4ClBRrHvuuceEpkGDBo6vS7QrISFB79y5U0+cONHxdaGoihZZJsuU94sck2MqNoosk2VVQnGPdgyTeyD8yT0kf/7zn9WaNWtUbm6uimXyuxbXt29fM4affwcOgBeQ5UBkGV5EjgORY3gVWQ5EloPjHu0Y9uGHH5ox9WRYAem6/w9/+IM688wz1Y033uj0qkXcBRdcoMaMGaM++OADtWvXLjNEwa233qpWrlxpngO8hCyTZXgfOSbHiA1kmSyXh+On1anIXcYi90Xs27fP3Ivy3Xff6d69ezu+XtEouV9l5syZOi8vTxcWFpqfkyZN0nXq1HF83SiqvEWWyTLl/SLH5JiKjSLLZFmVvZx78wEDBgTcTN+2bVunPwyKospZ5JiiYqPIMkV5v8gxRSk3lTNvLEd+Dh8+bHr6O/PMM/XLL7+s8/PzOSJCUR4qckxRsVFkmaK8X+SYopTbypk3lqNs0u2+f4910p380KFDnf5AKIoqY5FjioqNIssU5f0ixxSlXFWOdIZWpUoVlZmZqUaNGvW/G8W1VvPmzVNZWVllWoYMLL9v374IriXgfampqRHrAdOOHAuyDHg/y+QY8H6OBVkG7MuyIw3t2rVrq8TERLV9+/aA5+Vxy5YtT5g/KSkpoDv5+vXrq+zs7KisK+B1GRkZEdmxlzfHgiwD3s8yOQa8n2NBloHIZtkTw3sNGzZMDR8+vMRfkKNuQPCjbTk5Oa7KCFkGvJ9lcgx4P8eCLAORzbIjDe2dO3eqo0ePqvT09IDn5fG2bdtOmF8ugxk9enSJvyAbAsAZ5c2xIMuA+7BPBryPfTLgPpWceNMjR46oZcuWqa5du/qeS0hIMI8XL158wvxFRUW+0BN+wB3Km2NBlgH3YZ8MeB/7ZMCdHBuCQMb469u3r27ZsqV+6aWXzBAEdevWLfW1qampWshPp3uToyi3VjRyUpEcR2sdKcrr5fYsk2OK8n6Oo7WOFKU8XuXMiXMrOnDgQL1x40Yz5p8MSdCuXbtI/IIUFZcVrZyEm+NoriNFebncnmVyTFHez3E015GilIerPDlJ+O8/PEXuISkoKFBpaWlc5gJ4OCdeWEfAaW7PidvXD3ADL+TEC+sIeCknjtyjDQAAAABArKKhDQAAAACAjWhoAwAAAABgIxraAAAAAADYiIY2AAAAAAA2oqENAAAAAICNaGgDAAAAAGAjGtoAAAAAANiIhjYAAAAAADaioQ0AAAAAgI1oaAMAAAAAYCMa2gAAAAAA2IiGNgAAAAAANqKhDQAAAACAjWhoAwAAAABgIxraAAAAAADYiIY2AAAAAAA2oqENAAAAAICNaGgDAAAAAGAjGtoAAAAAANiIhjYAAAAAAG5uaD/wwAPqm2++UQUFBWr79u1q+vTpqnnz5gHzJCcnq3HjxqmdO3eqffv2qalTp6q6devavSoAwkSOgdhAloHYQJYB77G9od2pUyc1fvx4dcEFF6hu3bqpKlWqqDlz5qhq1ar55hkzZozq2bOnuv766838DRo0UB9++KHdqwIgTOQYiA1kGYgNZBnwJh3Jql27thYdOnQwj9PS0nRhYaG+7rrrfPO0aNHCzNO+ffsyLTM1NdXMLz8jvf4U5dWyMyeRyLHd60hRsVpuzzI5pqjo54QsU5RypMqTk4jfo129enXzMz8/3/zMzMxUSUlJat68eb55srOz1aZNm1RWVlaJy5D5U1NTAwpA9NiRY0GWAWexTwZiA1kG3C+iDe2EhAT1/PPPqwULFqiffvrJPFevXj1VWFio9u7dGzCv3G8i00oybNgwc0+KVTk5OZFcbQARyLEgy4Bz2CcDsYEsA94Q0Ya23EvSqlUrdcMNN1RoOaNGjVJpaWm+ysjIsG0dAUQnx4IsA85hnwzEBrIMeENipBY8duxY1aNHD9WxY8eAI2Tbtm0zvSLKJS/+R93S09PNtJIUFRWZAhBdduZYkGXAGeyTgdhAlgFvsf0m8bFjx+qtW7fqpk2bnjDN6qzh2muv9T3XvHlzOmugKJurojmJdI7tWEeKiodye5bJMUVFJydkmaKU41XOnNj75uPHj9e7d+/WHTt21Onp6b6qWrWqb54JEybojRs36s6dO+s2bdrohQsXmorQL0hRcVkVyUk0clzRdaSoeCm3Z5kcU1Tkc0KWKUq5ohxtaAdz8803++ZJTk7W48aN07t27dL79+/X06ZNMxuLCP2CFBWXVZGcRCPHFV1HioqXcnuWyTFFRT4nZJmilCuqPDlJ+O8/PEWGH5DeEaXjhn379jm9OoAreSEnXlhHwGluz4nb1w9wAy/kxAvrCHgpJxEfRxsAAAAAgHhCQxsAAAAAABvR0AYAAAAAwEY0tAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARjS0AQAAAACwEQ1tAAAAAABsREMbAAAAAAAb0dAGAAAAAMBGNLQBAAAAALARDW0AAAAAAGxEQxsAAAAAABvR0AYAAAAAwEY0tAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARjS0AQAAAACwEQ1tAAAAAAC81NAeOnSo0lqrMWPG+J5LTk5W48aNUzt37lT79u1TU6dOVXXr1o30qgAIEzkGYgNZBryPHAPeENGG9vnnn6/+/Oc/q+XLlwc8LxuGnj17quuvv1516tRJNWjQQH344YeRXBUAYSLHQGwgy4D3kWPAW3QkKiUlRWdnZ+uuXbvqL774Qo8ZM8Y8n5aWpgsLC/V1113nm7dFixZatG/fvkzLTk1NNfPLz0itP0V5vezISSRzbNc6UlSsl9uzTI4pyvs5tmsdKSrWK7UcOYnYGe3x48erf//73+qzzz4LeD4zM1MlJSWpefPm+Z7Lzs5WmzZtUllZWSUuS+ZPTU0NKACRZ2eOBVkGnME+GfA+9smAtyRGYqF9+vRRbdq0UW3btj1hWr169VRhYaHau3dvwPPbt28300oybNgwNXz48EisKoAo5ViQZSD62CcD3sc+GfAe289on3rqqeof//iHuummm0zo7TBq1CiVlpbmq4yMDFuWCyB6ORZkGYgu9smA97FPBrzJ9oa2XL6Snp6uvv/+e3XkyBFTnTt3Vnfffbf5txxdk54Rq1evHvA6ec22bdtKXGZRUZHpQdG/AEROJHIsyDIQXeyTAe9jnwx4k+2Xjst9I61atQp4bvLkyWr16tXq6aefVlu2bDHB7tq1q683xObNm6tGjRqpxYsX2706AMJAjoHYQJYB7yPHgDfZ3tDev3+/+umnnwKeO3DggNq1a5fv+UmTJqnRo0er/Px8VVBQoMaOHasWLVqkli5davfqwENatmxZ5jEf169fr7Zu3RrxdYpX5BiIDWTZHeRso5yVTEws/WvX0aNH1XfffWcaToAgx7EvISHB3IOfkpJSpvlXrFih9uzZE/H1ggs7QyvNvffeq44fP66mTZtmdj6zZ89WAwYMcGJVYtYbSqnAC4hKJ11o9HVwuV1OOkllFLvsKZifkpLUD2VYLiKHHEdHeTNXlrx5cbmIHLIceVMqV1ZXpaWpxCpVSp336JEj6otKldR2h/fJkVguIoccR0ek9nFvKqV6nnyySk1LK9NyFycmqnVk2RNievyyeK2ZEXpNJJc7ZcoUXVaDBw8Oa13iqbyQEy+so9M1M0Lze2258Vxuz4nb188NNadqVb13794y7d/27NmjTz31VMf3yZFYbjyXF3LihXV0uiK1j/soIUGvWLGizN+DZSx1sqzidxxtAAAAAADiEQ1tAAAAAABsREMbAAAAAAAb0dAGAAAAAMBGNLQBAAAAALARDW0AAAAAAGxEQxsAAAAAABvR0AYAAAAAwEaJdi4MqIicnBy1evXqMs2bn58f8fUBAMAOx7VWa9asUSeffHKp8+7bt08dOXIkKusFwB20Umr9+vWqSpUqpc+rtTpw4EBU1gsVQ0MbrvHggw+qhx9+uEzzHjt2TF0d8TUCAKDiCgsL1UUXXVTm+YuKiiK6PgDcRRrP119/vUpISCjT/ByM8wYa2jFqr1JqZhivcXK5044etX25gNeVN3N7Y3S5gJfJ3/kH5Ww8O71PjsRyAa+L5L5zajkbz2TZ/Whox6i+LBeICV7LHFkGvJ83cgzERubIsrPoDA0AAAAAABvR0AYAAAAAwEY0tAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARjS0AQAAAACwEQ1tAAAAAADc3tBu0KCBevPNN9XOnTvVwYMH1YoVK1RmZmbAPCNGjFC5ublm+ty5c1XTpk0jsSoAwkSOgdhAloHYQJaBOG9on3LKKWrhwoXqyJEj6oorrlBnnXWWGjx4sNq9e7dvniFDhqi7775b9e/fX7Vv314dOHBAzZ49WyUnJ9u9OgDCQI6B2ECWgdhAlgFv0nbWqFGj9Ndffx1yntzcXD148GDf47S0NH3o0CHdp0+fMr1HamqqFvLT7vWnqFipiuQkGjmu6DpSVLyU27NMjikq8jkhyxSlXFHlyUmi3a32q666yhw9e//991WnTp1UTk6OmjBhgnr11VfN9MaNG6v69eurefPm+V5TUFCgli5dqrKystR7771n9yrFjDeUUtXL+Zq9Sqm+LLdMy8X/kOPIKu/fcFn/flkuiiPLkeO1fZzXlotAZDlyvLaPI8veYXtD+4wzzlB33nmnGj16tHryySdV27Zt1QsvvKCKiorUG2+8oerVq2fm2759e8Dr5LE1rbikpKSAy15SU1NVPJI//l7lfM1Mllvm5SKyORZkOby/4bL+/bJcFMc+OXK8to/z2nIRiCxHjtf2cWQ5jhvalSpVUt9995166KGHzOMff/xRtWrVytwvIhuCcAwbNkwNHz7c5jUFEM0cC7IMRBf7ZCA2kGXAe2zvDC0vL0+tWrUq4Lmff/5ZnXbaaebf27ZtMz/T09MD5pHH1rTiRo0apdLS0nyVkZFh92oDiHCOBVkGoot9MhAbyDLgPbY3tKVHxBYtWgQ817x5c7Vp0ybz7w0bNpiNRdeuXQMuVZHeERcvXlziMuWymH379gUUgMiJRI4FWQaii30yEBvIMuBNtvbEdv755+uioiI9bNgw3aRJE/373/9e79+/X994442+eYYMGaLz8/N1z549datWrfT06dP1unXrdHJysu29vcVSzYzQa1hubFZFchKNHFd0Hb1cMyM0P8uNzXJ7lsmxva9hubFZFc0JWY5ceW0fR5aVo1XOnNi/Ar/97W/1ihUrzJACq1at0rfddtsJ84wYMULn5eWZeebOnaubNWsWqV8wZsprwfLacmOtKpqTSOfYjnX0arll5xury421cnuWybG9r2G5sVl25IQsR6a8to8jyyq+G9ou+wVjprwWLK8tN9bKCznxwjpGotyy843V5cZauT0nbl+/SJXX9nFeW26slRdy4oV1jER5bR9HlpVncmL7PdoAAAAAAMQzGtoAAAAAANiIhjYAAAAAADaioQ0AAAAAgI1oaAMAAAAAYKNEOxeGyNqrlJoZxmtYbtmWC0RLef+Gy/r3y3KB6PHaPs5rywWixWv7OLLsHQn/7X7cU1JTU1VBQYFKS0tT+/btc3p1AFfyQk68sI6A09yeE7evH+AGXsiJF9YR8FJOuHQcAAAAAAAb0dAGAAAAAMBGNLQBAAAAALARDW0AAAAAAGxEQxsAAAAAABvR0AYAAAAAwEY0tAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARol2Lgzu8YZSqno5X7NXKdU3xpYLeF15s1HWXLyplGp12mkqOSmpTMtdnZenrj1wwLH1BbzMa/tO9slAdPdxZDk20dCOURKqXuV8zcwYXC7gdeXNRllzcUpCgqr8r3+pM885p0zz765TR6kyNLQjtb6Al3lt38k+GYjuPo4sxyYuHQcAAAAAwEY0tAEAAAAAcHNDu1KlSuqxxx5T69evVwcPHlRr165VDz/88AnzjRgxQuXm5pp55s6dq5o2bWr3qgAIEzkGYgNZBmIDWQa8SdtZw4YN07/++qu+8sordaNGjfR1112nCwoK9F133eWbZ8iQIXr37t36qquu0uecc46eMWOGXrdunU5OTi7Te6SmpmohP+1e/1ipmRF6jdeWG89VkZxEI8cVXcd4qZkRmv+jhAS9YsUKXVYLa9d2dH3judyeZXIce/tO9sn2V0VzQpbdUZHax5Fl5ZkqZ07sffOPPvpIv/rqqwHPTZ06Vb/55pu+x7m5uXrw4MG+x2lpafrQoUO6T58+kfgF47K8Flg2BPZXRXISjRxXdB3jpWhoU27PMjmOvX0n+2T7q6I5IcvuKBraVGo5cmL7peOLFi1SXbt2Vc2aNTOPzz33XHXxxRerTz75xDxu3Lixql+/vpo3b57vNQUFBWrp0qUqKyurxGUmJSWp1NTUgAIQOZHIsSDLQHSxTwZiA1kGvMf24b2eeuoplZaWplavXq2OHTumKleurB566CH19ttvm+n16tUzP7dv3x7wOnlsTStu2LBhavjw4XavKoAo5liQZSC62CcDsYEsA95j+xnt3r17q5tuukndeOONqk2bNurmm29W999/v+rbN/yhz0eNGmU2LlZlZGTYus4AIp9jQZaB6GKfDMQGsgx4j+1ntJ999llz1O29994zj//zn/+oRo0amaNmb7zxhtq2bZt5Pj093fdv6/GPP/5Y4jKLiopMAYiOSORYkGUgutgnA7GBLAPeY3tDu1q1aur48eMBz8klLjIsgdiwYYPKy8sz95ksX77cPCf3hLRv3169+OKLdq8OgDCQ49intVYzZsxQy5YtK9O8px8+HJX1gr3IMhAbyDLgPbY3tD/66CNzz8jmzZvVTz/9pM477zx13333qX/+85++eZ5//nkz9t8vv/xiNgwjR440Y/7Jlz4AziPHsU+6w3zkkUfKPP/MiK4NIoUsA7GBLAPeY3tD+6677jLBnjBhgqpbt64J+Msvv6wee+wx3zzPPPOMSklJURMnTlSnnHKKWrBggerevbsqLCy0e3Xi1t4wvhjvjcHlIjzk2D3Km429MbpchIcsu4PX9p3sk92HLLuDW/adZV02WXZWwn9PbHiKXAojQxZIxw379u1zenUAV/JCTrywjoDT3J4Tt68f4AZeyIkX1hHwUk5s73UcAAAAAIB4RkMbAAAAAAAb0dAGAAAAAMBGNLQBAAAAALARDW0AAAAAAGxEQxsAAAAAABvR0AYAAAAAwEY0tAEAAAAAsBENbQAAAAAAbERDGwAAAAAAG9HQBgAAAADARjS0AQAAAACwEQ1tAAAAAABsREMbAAAAAAAb0dAGAAAAAMBGNLQBAAAAALARDW0AAAAAAGxEQxsAAAAAABvR0AYAAAAAwEY0tAEAAAAAcLKh3aFDBzVr1iyVk5OjtNaqV69eJ8wzYsQIlZubqw4ePKjmzp2rmjZtGjC9Ro0a6q233lJ79+5Vu3fvVq+++qpKSUmp2G8CoMzIMRAbyDLgfeQYiE3lbmhLaJcvX64GDhxY4vQhQ4aou+++W/Xv31+1b99eHThwQM2ePVslJyf75pkyZYo6++yzVbdu3VSPHj1Ux44d1cSJEyv2mwAoM3IMxAayDHgfOQZilw63RK9evQKey83N1YMHD/Y9TktL04cOHdJ9+vQxj1u2bGlel5mZ6Zvn8ssv18eOHdP169cv0/umpqaaZcjPiqw/RcVylTUnTuW4POtIUfFcbs8yOaYo7+e4POtIUfFcqeXIia33aDdu3FjVr19fzZs3z/dcQUGBWrp0qcrKyjKP5adc0rJs2TLfPDL/8ePHzVE6AM4ix0BsIMuA95FjwLsS7VxYvXr1zM/t27cHPC+PrWnyc8eOHQHTjx07pvLz833zFJeUlBRweUxqaqqdqw0gCjkWZBmIHvbJgPexTwa8yxO9jg8bNswcvbNKOosA4D1kGfA+cgzEBrIMeKihvW3bNvMzPT094Hl5bE2Tn3Xr1g2YXrlyZVWzZk3fPMWNGjVKpaWl+SojI8PO1QYQhRwLsgxED/tkwPvYJwPeZWtDe8OGDSovL0917do14DIUuT9k8eLF5rH8lCEI2rRp45vnkksuUZUqVTL3m5SkqKhI7du3L6AAREakcizIMhA97JMB72OfDHhbuXpaS0lJ0a1btzYlBg0aZP7dsGFDM33IkCE6Pz9f9+zZU7dq1UpPnz5dr1u3TicnJ/uW8fHHH+tly5bptm3b6gsvvFBnZ2frKVOmRKS3N4qK1wqVEzfkuLR1pCjKG1kmxxTl/RyXto4URalwclK+hXfq1EmXZPLkyb55RowYofPy8szQA3PnztXNmjULWEaNGjVM+AsKCvSePXv0pEmTzEYmQr8gRcVlhcqJG3Jc2jpSFOWNLJNjivJ+jktbR4qiVLlzkvDff3iKXDIjnTbI/SRc5gJ4NydeWEfAaW7PidvXD3ADL+TEC+sIeCknnuh1HAAAAAAAr6ChDQAAAACAjWhoAwAAAABgIxraAAAAAADYiIY2AAAAAAA2oqENAAAAAICNaGgDAAAAAGAjGtoAAAAAANiIhjYAAAAAADaioQ0AAAAAgI1oaAMAAAAAYCMa2gAAAAAA2IiGNgAAAAAANqKhDQAAAACAjWhoAwAAAABgIxraAAAAAADYiIY2AAAAAAA2oqENAAAAAICNaGgDAAAAAGAjGtoAAAAAANiIhjYAAAAAAE42tDt06KBmzZqlcnJylNZa9erVyzctMTFRPfXUU2rFihVq//79Zp7XX39d1a9fP2AZNWrUUG+99Zbau3ev2r17t3r11VdVSkqKPb8RgFKRYyA2kGXA+8gxEJvK3dCW0C5fvlwNHDjwhGnVqlVTbdq0USNHjjQ/r732WtWiRQuz8fA3ZcoUdfbZZ6tu3bqpHj16qI4dO6qJEydW7DcBUGbkGIgNZBnwPnIMxC4dbolevXqFnOf888838zVs2NA8btmypXmcmZnpm+fyyy/Xx44d0/Xr1y/T+6amppplyM+KrD9FxXKVNSdO5bg860hR8VxuzzI5pijv57g860hR8Vyp5chJxO/Rrl69ujp+/Ljas2ePeZyVlWUuaVm2bJlvnnnz5pl52rdvX+IykpKSVGpqakABiB47cizIMuAs9smA97FPBrwhog3t5ORk9fTTT6t33nlH7du3zzxXr149tWPHjoD5jh07pvLz8820kgwbNkwVFBT4Su5PARAdduVYkGXAOeyTAe9jnwx4R8Qa2tJ5w/vvv68SEhLUnXfeWaFljRo1SqWlpfkqIyPDtvUEEJ0cC7IMOIN9MuB97JMBb0mM5IagUaNG6pJLLvEdcRPbtm1TdevWDZi/cuXKqmbNmmZaSYqKikwBiB67cyzIMhB97JMB72OfDHhPpUhtCJo1a6YuvfRSc9mKv8WLF5shCKTnRItsMCpVqqSWLl1q9+oACAM5BmIDWQa8jxwDcXJGW4YgaNq0qe9x48aNVevWrU3o8/Ly1NSpU03QZWgBOZqWnp5u5pPpR44cUatXr1affPKJeuWVV1T//v1VlSpV1Lhx49S7775rXg8g8sgxEBvIMuB95BiIXeXq0rxTp066JJMnT9aNGjXSwcjrrGXUqFFDT5kyRRcUFOg9e/boSZMm6ZSUlIh0q05R8VqhcuKGHJe2jhRFeSPL5JiivJ/j0taRoihV7pwk/PcfniLDD0jviNJxg/89KgC8lRMvrCPgNLfnxO3rB7iBF3LihXUEvJSTiI+jDQAAAABAPKGhDQAAAACAjWhoAwAAAABgIxraAAAAAAA4ObyX225GB+D9fHhpXYFo80o+vLKegBO8lA8vrSvg5nwkevkXzMnJcXpVAE/kxa29h9asWdP8JMuAd7PMPhnwfo4FWQbszbInh/cSzZs3V9nZ2SojI8O1Gyw3/2HIRpTPLvY/O1nf3Nxc5fYhErzyebqJ1/4W3cSLn53bs8w+Ob7+Ht3Ca5+d23MsyHL8/D26SWqMZtmTZ7RFXl6e+Sn/GV74D3EjPrvY/+y8sI5e+jzdiM8uPj47t68n++SK47OL/c/OC+tIliuOzy72P7t9ZVxHOkMDAAAAAMBGNLQBAAAAALCRZxvahYWFavjw4eYnyofPLnx8dvbi8wwfn134+Ozsx2caPj678PHZ2Y/PNHx8duErjNHPzrOdoQEAAAAA4EaePaMNAAAAAIAb0dAGAAAAAMBGNLQBAAAAALARDW0AAAAAAOK9oT1gwAC1YcMGdejQIbVkyRLVtm1bp1fJdR599FGltQ6on3/+2Tc9OTlZjRs3Tu3cudMMuj516lRVt25dFY86dOigZs2apXJycszn1KtXrxPmGTFihMrNzVUHDx5Uc+fOVU2bNg2YXqNGDfXWW2+pvXv3qt27d6tXX31VpaSkRPG38CayXDqyXHZk2TlkOTRyXHbk2DnkuHRkuew6kGVDe6l69+6tDx8+rPv166fPPPNM/fLLL+v8/Hxdp04dx9fNTfXoo4/qlStX6vT0dF/VqlXLN33ChAl606ZNukuXLrpNmzZ60aJFesGCBY6vtxPVvXt3PXLkSH311Vdr0atXr4DpQ4YM0bt379ZXXXWVPuecc/SMGTP0unXrdHJysm+ejz/+WP/www+6Xbt2+qKLLtJr1qzRU6ZMcfx3c3OR5bIVWS57kWVniiyXXuS47EWOnSlyXLYiy2Wv7mRZyvEVKFctWbJEjx071vc4ISFBb926VQ8dOtTxdXPbhkD+MEualpaWpgsLC/V1113ne65FixYmBO3bt3d83Z2skjYEubm5evDgwQGf36FDh3SfPn3M45YtW5rXZWZm+ua5/PLL9bFjx3T9+vUd/53cWmS5bEWWwyuyHL0iy6UXOQ6vyHH0ihyXrchyeBWvWfbUpeNVqlRRmZmZat68eb7n5FIEeZyVleXourlRs2bNzOUa69atM5ddNGzY0Dwvn2FSUlLA55idna02bdrE51hM48aNVf369QM+q4KCArV06VLfZyU/5XKWZcuW+eaR+Y8fP67at2/vyHq7HVkuH7JccWQ5Mshy2ZHjiiPHkUGOy4csV1zjOMmypxratWvXVomJiWr79u0Bz8vjevXqObZebiR/qP369VPdu3dXd955p/mDnj9/vjr55JPNZ1VYWGjud/DH53gi6/MI9TcnP3fs2BEw/dixYyo/P5/PMwiyXHZk2R5kOTLIctmQY3uQ48ggx2VHlu1RL06ynOj0CiAyPv30U9+/V65caTYMckStd+/eppMLAN5AlgHvI8dAbCDLiNkz2tKD39GjR1V6enrA8/J427Ztjq2XF8jRtTVr1pje/OSzkl4Rq1evHjAPn+OJrM8j1N+c/Czeo2TlypVVzZo1+TyDIMvhI8vhIcuRQZbDQ47DQ44jgxyHjyyHZ1ucZNlTDe0jR46Y6/S7du3qey4hIcE8Xrx4saPr5nbSFX6TJk1UXl6e+QyLiooCPsfmzZurRo0a8TkWI8NcyGfm/1mlpqaae0Osz0p+yvADbdq08c1zySWXqEqVKpkjnTgRWQ4fWQ4PWY4MshwechwechwZ5Dh8ZDk8G+Ioy9prww9Ij3R9+/Y1vdG99NJLZviBunXrOr5ubqpnn31Wd+zYUTdq1EhnZWXpOXPm6B07dujatWv7hh/YuHGj7ty5sxl+YOHChaacXm8nKiUlRbdu3dqUGDRokPl3w4YNfcMPyN9Yz549datWrfT06dNLHH5g2bJlum3btvrCCy/U2dnZXht+IOpFlstWZLnsRZadKbJcepHjshc5dqbIcdmKLJe9UsiylOMrUO4aOHCg+SOW8f5kOAIZW83pdXJbvfPOOzonJ8d8Rlu2bDGPzzjjDN90+SMeN26c3rVrl96/f7+eNm2aGQvQ6fV2ojp16qRLMnnyZN88I0aM0Hl5eWYnNHfuXN2sWbOAZdSoUcMEv6CgQO/Zs0dPmjTJbGCc/t3cXmS59CLLZS+y7FyR5dBFjste5Ni5IselF1kue3Uiyzrhv/8AAAAAAADxdo82AAAAAABuR0MbAAAAAAAb0dAGAAAAAMBGNLQBAAAAALARDW0AAAAAAGxEQxsAAAAAABvR0AYAAAAA4P/ar2MCAAAAhEH2T22JndCCkGgDAABASLQBAAAgJNoAAAAQEm0AAAAIiTYAAACsc0qLWiN82I49AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1200x960 with 12 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot several EXAMPLES from TRAIN dataset\n",
    "n_examples= 4  # number of examples to plot\n",
    "# choosing indecies of images (from train) to plot\n",
    "random.seed(78)\n",
    "train_examples_ids = random.sample(range(len(mnist_train_ds)), n_examples)\n",
    "\n",
    "all_examples_wavefronts = []\n",
    "\n",
    "n_lines = 3\n",
    "fig, axs = plt.subplots(n_lines, n_examples, figsize=(n_examples * 3, n_lines * 3.2))\n",
    "for ind_ex, ind_train in enumerate(train_examples_ids):\n",
    "    image, label = mnist_train_ds[ind_train]\n",
    "\n",
    "    axs[0][ind_ex].set_title(f'id={ind_train} [{label}]')\n",
    "    axs[0][ind_ex].imshow(image, cmap='gray')\n",
    "\n",
    "    wavefront, target_image = mnist_wf_train_ds[ind_train]\n",
    "    assert isinstance(wavefront, Wavefront)\n",
    "\n",
    "    all_examples_wavefronts.append(wavefront)\n",
    "\n",
    "    axs[1][ind_ex].set_title(f'$|WF|^2$')\n",
    "    # here we can plot intensity for a wavefront\n",
    "    axs[1][ind_ex].imshow(\n",
    "        wavefront.intensity, cmap='gray',\n",
    "        vmin=0, vmax=1\n",
    "    )\n",
    "\n",
    "    # axs[2][ind_ex].set_title(f'phase of $WF$')\n",
    "    # axs[2][ind_ex].imshow(\n",
    "    #     wavefront.phase[0], cmap='gray',\n",
    "    #     vmin=0, vmax= 2 * torch.pi\n",
    "    # )\n",
    "\n",
    "    axs[2][ind_ex].set_title(f'Target image')\n",
    "    axs[2][ind_ex].imshow(\n",
    "        target_image, cmap='gray',\n",
    "        vmin=0, vmax= 1\n",
    "    )\n",
    "\n",
    "    for zone in get_zones_patches(selected_detector_mask):\n",
    "        # add zone's patches to the axis\n",
    "        # zone_copy = copy(zone)\n",
    "        axs[2][ind_ex].add_patch(zone)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Optical network\n",
    "\n",
    "Info from a supplementary material of [[1]](https://www.science.org/doi/suppl/10.1126/science.aat8084/suppl_file/aat8084-lin-sm-rev-3.pdf) for MNIST classification:\n",
    "\n",
    "> Following the corresponding $D^2NN$ design, the axial distance between two successive 3D-printed layers was set to be $3.0$ $cm$...\n",
    "\n",
    "> The distance between detector/output plane and the last layer of the optical neural network was adjusted as $3$ $cm$...\n",
    "\n",
    "#### <span style=\"color:red\">Additional information</span>\n",
    "\n",
    "From [[2]](https://ieeexplore.ieee.org/abstract/document/8732486):\n",
    "\n",
    "> ... the axial distance between the successive diffractive layers is set to be $\\sim 40 \\times \\lambda$ as in [[1]](https://www.science.org/doi/10.1126/science.aat8084) ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Difference.</span>** You can use an another number of diffractive layers (for phase-only training)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_DIFF_LAYERS = 5  # number of diffractive layers\n",
    "FREE_SPACE_DISTANCE = 40 * working_wavelength  # [m] - distance between difractive layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Distance between layers is 2.998 cm\n"
     ]
    }
   ],
   "source": [
    "print(f'Distance between layers is {FREE_SPACE_DISTANCE * 1e2:.3f} cm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Architecture\n",
    "\n",
    "See Figure 2A from [[1]](https://www.science.org/doi/10.1126/science.aat8084).\n",
    "\n",
    "See Figure 1(a) from [[2]](https://ieeexplore.ieee.org/abstract/document/8732486)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1. List of Elements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_PHASE = 2 * np.pi  # max phase for phase masks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Information from [1,2]: </span>**\n",
    "> a $5$-layer, phase-only (complex-valued) diffractive optical network ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Difference.</span>** An another method for `FreeSpace`'s in contrast to [2]!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FREESPACE_METHOD = 'AS'  # we use another method in contrast to [2]!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Information from [2]: </span>**\n",
    "> a diffractive layer ... neurons ... were initialized with $\\pi$ for phase values and $1$ for amplitude values ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INIT_PHASES = torch.ones(NUM_OF_DIFF_LAYERS) * np.pi  # initial values for phase masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Comment</span>**\n",
    "\n",
    "Here we are using a default `ConstrainedParameter` which is using the sigmoid function to limit a parameter range.\n",
    "\n",
    "In [[2]](https://ieeexplore.ieee.org/abstract/document/8732486) authors discuss such approach in the section Results and Discussion A. and underline that limiting parameters with the sigmoid function may lead to Vanishing Gradients. Authors also propose an another way to limit parameters - by using ReLU.\n",
    "\n",
    "In our case the sigmoid function works well but it is possible to realize the ReLU approach via specifying `bound_func` for `Constrained Parameter` (<span style=\"color:red\">examples of customizing `bound_func` are provided in ...</span>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions that return single elements for further architecture\n",
    "\n",
    "def get_free_space(\n",
    "    freespace_sim_params,\n",
    "    freespace_distance,  # in [m]!\n",
    "    freespace_method='AS',\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns FreeSpace layer with a bounded distance parameter.\n",
    "    \"\"\"\n",
    "    return elements.FreeSpace(\n",
    "        simulation_parameters=freespace_sim_params,\n",
    "        distance=freespace_distance,  # distance is not learnable!\n",
    "        method=freespace_method\n",
    "    )\n",
    "\n",
    "\n",
    "def get_const_phase_layer(\n",
    "    sim_params: SimulationParameters,\n",
    "    value, max_phase=2 * torch.pi\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns DiffractiveLayer with a constant phase mask.\n",
    "    \"\"\"\n",
    "    x_nodes, y_nodes = sim_params.axes_size(axs=('W', 'H'))\n",
    "\n",
    "    const_mask = torch.ones(size=(y_nodes, x_nodes)) * value\n",
    "\n",
    "    return elements.DiffractiveLayer(\n",
    "        simulation_parameters=sim_params,\n",
    "        mask=ConstrainedParameter(\n",
    "            const_mask,\n",
    "            min_value=0,\n",
    "            max_value=max_phase\n",
    "        ),  # HERE WE ARE USING CONSTRAINED PARAMETER!\n",
    "    )  # ATTENTION TO DOCUMENTATION!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_const_phase_layer_no_train(\n",
    "    sim_params: SimulationParameters,\n",
    "    value\n",
    "):\n",
    "    \"\"\"\n",
    "    Returns DiffractiveLayer with a constant phase mask.\n",
    "    \"\"\"\n",
    "    x_nodes, y_nodes = sim_params.axes_size(axs=('W', 'H'))\n",
    "\n",
    "    const_mask = torch.ones(size=(y_nodes, x_nodes)) * value\n",
    "\n",
    "    return elements.DiffractiveLayer(\n",
    "        simulation_parameters=sim_params,\n",
    "        mask=const_mask,  # HERE WE ARE USING CONSTRAINED PARAMETER!\n",
    "    )  # ATTENTION TO DOCUMENTATION!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function to construct a list of elements to reproduce an architecture from [the extended article](https://ieeexplore.ieee.org/abstract/document/8732486):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elements_list(\n",
    "    num_layers,\n",
    "    num_layers_no_train,\n",
    "    simulation_parameters,\n",
    "    freespace_method,\n",
    "    phase_values,\n",
    "):\n",
    "    \"\"\"\n",
    "    Composes a list of elements for the setup.\n",
    "    ...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_layers : int\n",
    "        Number of layers in the system.\n",
    "    simulation_parameters : SimulationParameters()\n",
    "        A simulation parameters for a task.\n",
    "    freespace_method : str\n",
    "        Propagation method for free spaces in a setup.\n",
    "    phase_values : torch.Tensor()\n",
    "        Torch tensor of phase values to generate constant masks for diffractive layers.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    elements_list : list(Element)\n",
    "        List of Elements for an optical setup.\n",
    "    \"\"\"\n",
    "    elements_list = []  # list of elements\n",
    "\n",
    "    # first FreeSpace layer before first DiffractiveLayer\n",
    "    elements_list.append(\n",
    "        get_free_space(\n",
    "            simulation_parameters,  # simulation parameters for the notebook\n",
    "            FREE_SPACE_DISTANCE,  # in [m]\n",
    "            freespace_method=freespace_method,\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # compose the architecture\n",
    "    for ind_layer in range(num_layers):\n",
    "\n",
    "        # -----------------------------------------------------------------------\n",
    "        # add DiffractiveLayer (learnable phase mask)\n",
    "        elements_list.append(\n",
    "            get_const_phase_layer(\n",
    "                simulation_parameters,  # simulation parameters for the notebook\n",
    "                value=phase_values[ind_layer].item(),\n",
    "                max_phase=MAX_PHASE\n",
    "            )\n",
    "        )\n",
    "        # -----------------------------------------------------------------------\n",
    "\n",
    "        # add FreeSpace\n",
    "        elements_list.append(\n",
    "            get_free_space(\n",
    "                simulation_parameters,  # simulation parameters for the notebook\n",
    "                FREE_SPACE_DISTANCE,  # in [m]\n",
    "                freespace_method=freespace_method,\n",
    "            )\n",
    "        )\n",
    "    # print(1111111111111111111111)\n",
    "    for ind_layer in range(num_layers_no_train):\n",
    "\n",
    "        # -----------------------------------------------------------------------\n",
    "        # add DiffractiveLayer (untrained phase mask)\n",
    "        elements_list.append(\n",
    "            get_const_phase_layer_no_train(\n",
    "                simulation_parameters,  # simulation parameters for the notebook\n",
    "                value=phase_values[(ind_layer % (num_layers))].item()\n",
    "            )\n",
    "        )\n",
    "        # -----------------------------------------------------------------------\n",
    "\n",
    "        # add FreeSpace\n",
    "        elements_list.append(\n",
    "            get_free_space(\n",
    "                simulation_parameters,  # simulation parameters for the notebook\n",
    "                FREE_SPACE_DISTANCE,  # in [m]\n",
    "                freespace_method=freespace_method,\n",
    "            )\n",
    "        )\n",
    "\n",
    "    # ---------------------------------------------------------------------------\n",
    "    # add Detector in the end of the system!\n",
    "    elements_list.append(\n",
    "        Detector(\n",
    "            simulation_parameters=simulation_parameters,\n",
    "            func='intensity'  # detector that returns intensity\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return elements_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_OF_DIFF_LAYERS_NO_TRAIN = 507"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of elements in the system (including Detector): 1026\n"
     ]
    }
   ],
   "source": [
    "architecture_elements_list = get_elements_list(\n",
    "    num_layers=NUM_OF_DIFF_LAYERS,\n",
    "    num_layers_no_train=NUM_OF_DIFF_LAYERS_NO_TRAIN,\n",
    "    simulation_parameters=SIM_PARAMS,\n",
    "    freespace_method=FREESPACE_METHOD,\n",
    "    phase_values=INIT_PHASES,\n",
    ")\n",
    "\n",
    "print(f'Number of elements in the system (including Detector): {len(architecture_elements_list)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2. Compose `LinearOpticalSetup`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_setup():\n",
    "    \"\"\"\n",
    "    Returns an optical setup. Recreates all elements.\n",
    "    \"\"\"\n",
    "    elements_list = get_elements_list(\n",
    "        num_layers=NUM_OF_DIFF_LAYERS,\n",
    "        num_layers_no_train=NUM_OF_DIFF_LAYERS_NO_TRAIN,\n",
    "        simulation_parameters=SIM_PARAMS,\n",
    "        freespace_method=FREESPACE_METHOD,\n",
    "        phase_values=INIT_PHASES,\n",
    "    )  # recreate a list of elements\n",
    "\n",
    "    return LinearOpticalSetup(elements=elements_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creaye an optical setup\n",
    "optical_setup = get_setup()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Comment:</span>** Setup ends with `Detector` that returns an output tensor of intensities for each input `Wavefront`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.3 Detector processor (to calculate accuracies only)\n",
    "\n",
    "> ... size of these detectors $(6.4 \\lambda \\times 6.4 \\lambda)$ ...\n",
    "\n",
    "**<span style=\"color:red\">Comment:</span>** `DetectorProcessor` in our library is used to process an information on detector. For example, for the current task `DetectorProcessor` must return only 10 values (1 value per 1 class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CALCULATE_ACCURACIES = True  # if False, accuracies will not be calculated!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a DetectorProcessorOzcanClf object\n",
    "if CALCULATE_ACCURACIES:\n",
    "    detector_processor = DetectorProcessorClf(\n",
    "        simulation_parameters=SIM_PARAMS,\n",
    "        num_classes=number_of_classes,\n",
    "        segmented_detector=DETECTOR_MASK,\n",
    "    )\n",
    "else:\n",
    "    detector_processor = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Training of the network\n",
    "\n",
    "Variables at the moment\n",
    "- `lin_optical_setup` : `LinearOpticalSetup` – a linear optical network composed of Elements\n",
    "- `detector_processor` : `DetectorProcessorClf` – this layer process an image from the detector and calculates probabilities of belonging to classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = 'cuda'  # 'mps' is not support a CrossEntropyLoss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Prepare some stuff for training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. `DataLoader`'s\n",
    "\n",
    "Info from a supplementary material of [[1]](https://www.science.org/doi/suppl/10.1126/science.aat8084/suppl_file/aat8084-lin-sm-rev-3.pdf) for MNIST classification:\n",
    "\n",
    "> The training batch size was set to be $8$..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_bs = 128  # a batch size for training set\n",
    "val_bs = 64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Forthis task, phase-only transmission masks weredesigned by training a five-layer $D^2 NN$ with $55000$ images ($5000$ validation images) from theMNIST (Modified National Institute of Stan-dards and Technology) handwritten digit data-base."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mnist_wf_train_ds\n",
    "train_wf_ds, val_wf_ds = torch.utils.data.random_split(\n",
    "    dataset=mnist_wf_train_ds,\n",
    "    lengths=[55000, 5000],  # sizes from the article\n",
    "    generator=torch.Generator().manual_seed(178)  # for reproducibility\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_wf_loader = torch.utils.data.DataLoader(\n",
    "    train_wf_ds,\n",
    "    batch_size=train_bs,\n",
    "    shuffle=True,\n",
    "    # num_workers=2,\n",
    "    drop_last=False,\n",
    ")\n",
    "\n",
    "val_wf_loader = torch.utils.data.DataLoader(\n",
    "    val_wf_ds,\n",
    "    batch_size=val_bs,\n",
    "    shuffle=False,\n",
    "    # num_workers=2,\n",
    "    drop_last=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Optimizer and loss function\n",
    "\n",
    "Info from a supplementary material of [[1]](https://www.science.org/doi/suppl/10.1126/science.aat8084/suppl_file/aat8084-lin-sm-rev-3.pdf) for MNIST classification:\n",
    "\n",
    "> We used the stochastic gradient descent algorithm, Adam, to back-propagate the errors and update the\n",
    "layers of the network to minimize the loss function.\n",
    "\n",
    "**<span style=\"color:red\">Additional info</span>** from [[2]](https://ieeexplore.ieee.org/abstract/document/8732486):\n",
    "> a back-propagation method by applying the adaptive moment estimation optimizer (Adam) with a learning rate of $10^{−3}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LR = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_adam_optimizer(net):\n",
    "    return torch.optim.Adam(\n",
    "        params=net.parameters(),  # NETWORK PARAMETERS!\n",
    "        lr=LR\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<span style=\"color:red\">Comment:</span>** We are using `MSELoss` as in [1] (that was clarified in [2])! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func_clf = nn.MSELoss()  # by default: reduction='mean'\n",
    "loss_func_name = 'MSE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3. Training and evaluation loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onn_train_mse(\n",
    "    optical_net, wavefronts_dataloader,\n",
    "    detector_processor_clf,  # DETECTOR PROCESSOR needed for accuracies only!\n",
    "    loss_func, optimizer,\n",
    "    device='cpu', show_process=False\n",
    "):\n",
    "    \"\"\"\n",
    "    Function to train `optical_net` (classification task)\n",
    "    ...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        optical_net : torch.nn.Module\n",
    "            Neural Network composed of Elements.\n",
    "        wavefronts_dataloader : torch.utils.data.DataLoader\n",
    "            A loader (by batches) for the train dataset of wavefronts.\n",
    "        detector_processor_clf : DetectorProcessorClf\n",
    "            A processor of a detector image for a classification task, that returns `probabilities` of classes.\n",
    "        loss_func :\n",
    "            Loss function for a multi-class classification task.\n",
    "        optimizer: torch.optim\n",
    "            Optimizer...\n",
    "        device : str\n",
    "            Device to computate on...\n",
    "        show_process : bool\n",
    "            Flag to show (or not) a progress bar.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        batches_losses : list[float]\n",
    "            Losses for each batch in an epoch.\n",
    "        batches_accuracies : list[float]\n",
    "            Accuracies for each batch in an epoch.\n",
    "        epoch_accuracy : float\n",
    "            Accuracy for an epoch.\n",
    "    \"\"\"\n",
    "    optical_net.train()  # activate 'train' mode of a model\n",
    "    batches_losses = []  # to store loss for each batch\n",
    "    batches_accuracies = []  # to store accuracy for each batch\n",
    "\n",
    "    correct_preds = 0\n",
    "    size = 0\n",
    "\n",
    "    for batch_wavefronts, batch_targets in tqdm(\n",
    "        wavefronts_dataloader,\n",
    "        total=len(wavefronts_dataloader),\n",
    "        desc='train', position=0,\n",
    "        leave=True, disable=not show_process\n",
    "    ):  # go by batches\n",
    "        # batch_wavefronts - input wavefronts, batch_labels - labels\n",
    "        batch_size = batch_wavefronts.size()[0]\n",
    "\n",
    "        batch_wavefronts = batch_wavefronts.to(device)\n",
    "        batch_targets = batch_targets.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # forward of an optical network\n",
    "        detector_output = optical_net(batch_wavefronts)\n",
    "\n",
    "        # calculate loss for a batch\n",
    "        loss = loss_func(detector_output, batch_targets)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # ACCURACY\n",
    "        if CALCULATE_ACCURACIES:\n",
    "            # process a detector image\n",
    "            batch_labels = detector_processor_clf.batch_forward(batch_targets).argmax(1)\n",
    "            batch_probas = detector_processor_clf.batch_forward(detector_output)\n",
    "\n",
    "            batch_correct_preds = (\n",
    "                batch_probas.argmax(1) == batch_labels\n",
    "            ).type(torch.float).sum().item()\n",
    "\n",
    "            correct_preds += batch_correct_preds\n",
    "            size += batch_size\n",
    "\n",
    "        # accumulate losses and accuracies for batches\n",
    "        batches_losses.append(loss.item())\n",
    "        if CALCULATE_ACCURACIES:\n",
    "            batches_accuracies.append(batch_correct_preds / batch_size)\n",
    "        else:\n",
    "            batches_accuracies.append(0.)\n",
    "\n",
    "    if CALCULATE_ACCURACIES:\n",
    "        epoch_accuracy = correct_preds / size\n",
    "    else:\n",
    "        epoch_accuracy = 0.\n",
    "\n",
    "    return batches_losses, batches_accuracies, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def onn_validate_mse(\n",
    "    optical_net, wavefronts_dataloader,\n",
    "    detector_processor_clf,  # DETECTOR PROCESSOR NEEDED!\n",
    "    loss_func,\n",
    "    device='cpu', show_process=False\n",
    "    ):\n",
    "    \"\"\"\n",
    "    Function to validate `optical_net` (classification task)\n",
    "    ...\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "        optical_net : torch.nn.Module\n",
    "            Neural Network composed of Elements.\n",
    "        wavefronts_dataloader : torch.utils.data.DataLoader\n",
    "            A loader (by batches) for the train dataset of wavefronts.\n",
    "        detector_processor_clf : DetectorProcessorClf\n",
    "            A processor of a detector image for a classification task, that returns `probabilities` of classes.\n",
    "        loss_func :\n",
    "            Loss function for a multi-class classification task.\n",
    "        device : str\n",
    "            Device to computate on...\n",
    "        show_process : bool\n",
    "            Flag to show (or not) a progress bar.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "        batches_losses : list[float]\n",
    "            Losses for each batch in an epoch.\n",
    "        batches_accuracies : list[float]\n",
    "            Accuracies for each batch in an epoch.\n",
    "        epoch_accuracy : float\n",
    "            Accuracy for an epoch.\n",
    "    \"\"\"\n",
    "    optical_net.eval()  # activate 'eval' mode of a model\n",
    "    batches_losses = []  # to store loss for each batch\n",
    "    batches_accuracies = []  # to store accuracy for each batch\n",
    "\n",
    "    correct_preds = 0\n",
    "    size = 0\n",
    "\n",
    "    for batch_wavefronts, batch_targets in tqdm(\n",
    "        wavefronts_dataloader,\n",
    "        total=len(wavefronts_dataloader),\n",
    "        desc='validation', position=0,\n",
    "        leave=True, disable=not show_process\n",
    "    ):  # go by batches\n",
    "        # batch_wavefronts - input wavefronts, batch_labels - labels\n",
    "        batch_size = batch_wavefronts.size()[0]\n",
    "\n",
    "        batch_wavefronts = batch_wavefronts.to(device)\n",
    "        batch_targets = batch_targets.to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            detector_outputs = optical_net(batch_wavefronts)\n",
    "            # calculate loss for a batch\n",
    "            loss = loss_func(detector_outputs, batch_targets)\n",
    "\n",
    "        # ACCURACY\n",
    "        if CALCULATE_ACCURACIES:\n",
    "            # process a detector image\n",
    "            batch_labels = detector_processor_clf.batch_forward(batch_targets).argmax(1)\n",
    "            batch_probas = detector_processor_clf.batch_forward(detector_outputs)\n",
    "\n",
    "            batch_correct_preds = (\n",
    "                batch_probas.argmax(1) == batch_labels\n",
    "            ).type(torch.float).sum().item()\n",
    "\n",
    "            correct_preds += batch_correct_preds\n",
    "            size += batch_size\n",
    "\n",
    "        # accumulate losses and accuracies for batches\n",
    "        batches_losses.append(loss.item())\n",
    "        if CALCULATE_ACCURACIES:\n",
    "            batches_accuracies.append(batch_correct_preds / batch_size)\n",
    "        else:\n",
    "            batches_accuracies.append(0.)\n",
    "\n",
    "    if CALCULATE_ACCURACIES:\n",
    "        epoch_accuracy = correct_preds / size\n",
    "    else:\n",
    "        epoch_accuracy = 0.\n",
    "\n",
    "    return batches_losses, batches_accuracies, epoch_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Training of the optical network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Before training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> a diffractive layer ... neurons ... were initialized with $\\pi$ for phase values and $1$ for amplitude values ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics for Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_wf_loader = torch.utils.data.DataLoader(\n",
    "    mnist_wf_test_ds,\n",
    "    batch_size=10,\n",
    "    shuffle=False,\n",
    "    # num_workers=2,\n",
    "    drop_last=False,\n",
    ")  # data loader for a test MNIST data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optical_setup.net = optical_setup.net.to(DEVICE)\n",
    "SIM_PARAMS = SIM_PARAMS.to(DEVICE)\n",
    "detector_processor = detector_processor.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_losses_0, _, test_accuracy_0 = onn_validate_mse(\n",
    "#     optical_setup.net,  # optical network composed in 3.\n",
    "#     test_wf_loader,  # dataloader of training set\n",
    "#     detector_processor,  # detector processor\n",
    "#     loss_func_clf,\n",
    "#     device=DEVICE,\n",
    "#     show_process=True,\n",
    "# )  # evaluate the model\n",
    "\n",
    "# print(\n",
    "#     'Results before training on TEST set:\\n' +\n",
    "#     f'\\t{loss_func_name} : {np.mean(test_losses_0):.6f}\\n' +\n",
    "#     f'\\tAccuracy : {(test_accuracy_0*100):>0.1f} %'\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2. Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10\n",
    "print_each = 2  # print each n'th epoch info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = None  # sheduler for a lr tuning during training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recreate a system to restart training!\n",
    "ozcan_optical_setup = get_setup(SIM_PARAMS)\n",
    "\n",
    "# Linc optimizer to a recreated net!\n",
    "optimizer_clf = get_adam_optimizer(ozcan_optical_setup.net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ozcan_optical_setup.net = ozcan_optical_setup.net.to(DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch #1: "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "train:   0%|          | 2/430 [00:12<43:36,  6.11s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)\n",
      "Cell \u001b[1;32mIn[112], line 18\u001b[0m\n",
      "\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# TRAIN\u001b[39;00m\n",
      "\u001b[0;32m     17\u001b[0m start_train_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()  \u001b[38;5;66;03m# start time of the epoch (train)\u001b[39;00m\n",
      "\u001b[1;32m---> 18\u001b[0m train_losses, _, train_accuracy \u001b[38;5;241m=\u001b[39m \u001b[43monn_train_mse\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m     19\u001b[0m \u001b[43m    \u001b[49m\u001b[43mozcan_optical_setup\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnet\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# optical network composed in 3.\u001b[39;49;00m\n",
      "\u001b[0;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain_wf_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# dataloader of training set\u001b[39;49;00m\n",
      "\u001b[0;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdetector_processor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# detector processor\u001b[39;49;00m\n",
      "\u001b[0;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss_func_clf\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer_clf\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mDEVICE\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshow_process\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshow_progress\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m     26\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# train the model\u001b[39;00m\n",
      "\u001b[0;32m     27\u001b[0m mean_train_loss \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mmean(train_losses)\n",
      "\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (epoch \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m ((epoch \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m print_each \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (epoch \u001b[38;5;241m==\u001b[39m n_epochs \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m):  \u001b[38;5;66;03m# train info\u001b[39;00m\n",
      "\n",
      "Cell \u001b[1;32mIn[96], line 64\u001b[0m, in \u001b[0;36monn_train_mse\u001b[1;34m(optical_net, wavefronts_dataloader, detector_processor_clf, loss_func, optimizer, device, show_process)\u001b[0m\n",
      "\u001b[0;32m     61\u001b[0m \u001b[38;5;66;03m# calculate loss for a batch\u001b[39;00m\n",
      "\u001b[0;32m     62\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(detector_output, batch_targets)\n",
      "\u001b[1;32m---> 64\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;32m     65\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "\u001b[0;32m     67\u001b[0m \u001b[38;5;66;03m# ACCURACY\u001b[39;00m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\gunne\\projects\\python\\dnn\\SVETlANNa.docs\\.venv\\Lib\\site-packages\\torch\\_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n",
      "\u001b[0;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n",
      "\u001b[0;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n",
      "\u001b[0;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n",
      "\u001b[0;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n",
      "\u001b[1;32m   (...)\u001b[0m\n",
      "\u001b[0;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n",
      "\u001b[0;32m    625\u001b[0m     )\n",
      "\u001b[1;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n",
      "\u001b[0;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\gunne\\projects\\python\\dnn\\SVETlANNa.docs\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n",
      "\u001b[0;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n",
      "\u001b[0;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n",
      "\u001b[0;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n",
      "\u001b[0;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n",
      "\u001b[1;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n",
      "\u001b[0;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n",
      "\u001b[0;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\n",
      "File \u001b[1;32mc:\\Users\\gunne\\projects\\python\\dnn\\SVETlANNa.docs\\.venv\\Lib\\site-packages\\torch\\autograd\\graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[1;34m(t_outputs, *args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n",
      "\u001b[0;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[1;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n",
      "\u001b[0;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n",
      "\u001b[0;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n",
      "\u001b[0;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
      "\u001b[0;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_epochs_losses = []\n",
    "val_epochs_losses = []  # to store losses of each epoch\n",
    "\n",
    "train_epochs_acc = []\n",
    "val_epochs_acc = []  # to store accuracies\n",
    "\n",
    "torch.manual_seed(98)  # for reproducability?\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    if (epoch == 0) or ((epoch + 1) % print_each == 0) or (epoch == n_epochs - 1):\n",
    "        print(f'Epoch #{epoch + 1}: ', end='')\n",
    "        show_progress = True\n",
    "    else:\n",
    "        show_progress = False\n",
    "\n",
    "    # TRAIN\n",
    "    start_train_time = time.time()  # start time of the epoch (train)\n",
    "    train_losses, _, train_accuracy = onn_train_mse(\n",
    "        ozcan_optical_setup.net,  # optical network composed in 3.\n",
    "        train_wf_loader,  # dataloader of training set\n",
    "        detector_processor,  # detector processor\n",
    "        loss_func_clf,\n",
    "        optimizer_clf,\n",
    "        device=DEVICE,\n",
    "        show_process=show_progress,\n",
    "    )  # train the model\n",
    "    mean_train_loss = np.mean(train_losses)\n",
    "\n",
    "    if (epoch == 0) or ((epoch + 1) % print_each == 0) or (epoch == n_epochs - 1):  # train info\n",
    "        print('Training results')\n",
    "        print(f'\\t{loss_func_name} : {mean_train_loss:.6f}')\n",
    "        if CALCULATE_ACCURACIES:\n",
    "            print(f'\\tAccuracy : {(train_accuracy*100):>0.1f} %')\n",
    "        print(f'\\t------------   {time.time() - start_train_time:.2f} s')\n",
    "\n",
    "    # VALIDATION\n",
    "    start_val_time = time.time()  # start time of the epoch (validation)\n",
    "    val_losses, _, val_accuracy = onn_validate_mse(\n",
    "        ozcan_optical_setup.net,  # optical network composed in 3.\n",
    "        val_wf_loader,  # dataloader of validation set\n",
    "        detector_processor,  # detector processor\n",
    "        loss_func_clf,\n",
    "        device=DEVICE,\n",
    "        show_process=show_progress,\n",
    "    )  # evaluate the model\n",
    "    mean_val_loss = np.mean(val_losses)\n",
    "\n",
    "    if (epoch == 0) or ((epoch + 1) % print_each == 0) or (epoch == n_epochs - 1):  # validation info\n",
    "        print('Validation results')\n",
    "        print(f'\\t{loss_func_name} : {mean_val_loss:.6f}')\n",
    "        if CALCULATE_ACCURACIES:\n",
    "            print(f'\\tAccuracy : {(val_accuracy*100):>0.1f} %')\n",
    "        print(f'\\t------------   {time.time() - start_val_time:.2f} s')\n",
    "\n",
    "    if scheduler:\n",
    "        scheduler.step(mean_val_loss)\n",
    "\n",
    "    # save losses\n",
    "    train_epochs_losses.append(mean_train_loss)\n",
    "    val_epochs_losses.append(mean_val_loss)\n",
    "    # seve accuracies\n",
    "    train_epochs_acc.append(train_accuracy)\n",
    "    val_epochs_acc.append(val_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Learning curves (MSELoss and Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning curve\n",
    "fig, axs = plt.subplots(1, 2, figsize=(10, 3))\n",
    "\n",
    "axs[0].plot(range(1, n_epochs + 1), np.array(train_epochs_losses) * 1e3, label='train')\n",
    "axs[0].plot(range(1, n_epochs + 1), np.array(val_epochs_losses) * 1e3, linestyle='dashed', label='validation')\n",
    "\n",
    "axs[1].plot(range(1, n_epochs + 1), train_epochs_acc, label='train')\n",
    "axs[1].plot(range(1, n_epochs + 1), val_epochs_acc, linestyle='dashed', label='validation')\n",
    "\n",
    "axs[0].set_ylabel(loss_func_name + r' $\\times 10^3$')\n",
    "axs[0].set_xlabel('Epoch')\n",
    "axs[0].legend()\n",
    "\n",
    "axs[1].set_ylabel('Accuracy')\n",
    "axs[1].set_xlabel('Epoch')\n",
    "axs[1].legend()\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# array with all losses\n",
    "# TODO: make with PANDAS?\n",
    "all_lasses_header = ','.join([\n",
    "    f'{loss_func_name.split()[0]}_train', f'{loss_func_name.split()[0]}_val',\n",
    "    'accuracy_train', 'accuracy_val'\n",
    "])\n",
    "all_losses_array = np.array(\n",
    "    [train_epochs_losses, val_epochs_losses, train_epochs_acc, val_epochs_acc]\n",
    ").T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Trained phase masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = NUM_OF_DIFF_LAYERS  # number of columns for DiffractiveLayer's masks visualization\n",
    "n_rows = 1\n",
    "\n",
    "# plot wavefronts phase\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3.2))\n",
    "ind_diff_layer = 0\n",
    "\n",
    "cmap = 'gist_stern'  # 'gist_stern' 'rainbow'\n",
    "\n",
    "for ind_layer, layer in enumerate(ozcan_optical_setup.net.to(torch.device(\"cpu\"))):\n",
    "    if isinstance(layer, elements.DiffractiveLayer):  # plot masks for Diffractive layers\n",
    "        if n_rows > 1:\n",
    "            ax_this = axs[ind_diff_layer // n_cols][ind_diff_layer % n_cols]\n",
    "        else:\n",
    "            ax_this = axs[ind_diff_layer % n_cols]\n",
    "\n",
    "        ax_this.set_title(f'{ind_diff_layer + 1}. DiffractiveLayer')\n",
    "\n",
    "        trained_mask = layer.mask.detach()\n",
    "\n",
    "        ax_this.imshow(\n",
    "            trained_mask, cmap=cmap,\n",
    "            vmin=0, vmax=MAX_PHASE\n",
    "        )\n",
    "        ind_diff_layer += 1\n",
    "\n",
    "    # select only a part within apertures!\n",
    "    x_frame = (x_layer_nodes - DETECTOR_SIZE[1]) / 2\n",
    "    y_frame = (y_layer_nodes - DETECTOR_SIZE[0]) / 2\n",
    "    ax_this.set_xlim([x_frame, x_layer_nodes - x_frame])\n",
    "    ax_this.set_ylim([y_frame, y_layer_nodes - y_frame])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3. Saving the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pathes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FOLDER = 'models/reproduced_results/MNIST_MSE_Ozcan_2018-2020_GPU'\n",
    "\n",
    "if not os.path.exists(RESULTS_FOLDER):\n",
    "    os.makedirs(RESULTS_FOLDER)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filepath to save the model\n",
    "model_filepath = f'{RESULTS_FOLDER}/optical_setup_net_gpu.pth'\n",
    "# filepath to save losses\n",
    "losses_filepath = f'{RESULTS_FOLDER}/training_curves_gpu.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving model weights and learning curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving model\n",
    "torch.save(ozcan_optical_setup.net.state_dict(), model_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving losses\n",
    "np.savetxt(\n",
    "    losses_filepath, all_losses_array,\n",
    "    delimiter=',', header=all_lasses_header, comments=\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Load saved weights for the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RESULTS_FOLDER = 'models/reproduced_results/MNIST_MSE_Ozcan_2018-2020_gpu'\n",
    "\n",
    "load_model_filepath = f'{RESULTS_FOLDER}/optical_setup_net_gpu.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# setup to load weights\n",
    "ozcan_optical_setup_loaded = get_setup(SIM_PARAMS)\n",
    "\n",
    "# LOAD WEIGHTS\n",
    "ozcan_optical_setup_loaded.net.load_state_dict(torch.load(load_model_filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1. Calculate metrics on test set for the loaded model\n",
    "\n",
    "Checking if the loaded model works correctly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_losses_1, _, test_accuracy_1 = onn_validate_mse(\n",
    "    ozcan_optical_setup_loaded.net.to(torch.device(\"cuda\")),  # optical network with loaded weights\n",
    "    test_wf_loader,  # dataloader of training set\n",
    "    detector_processor,  # detector processor\n",
    "    loss_func_clf,\n",
    "    device=DEVICE,\n",
    "    show_process=True,\n",
    ")  # evaluate the model\n",
    "\n",
    "print(\n",
    "    'Results after training on TEST set:\\n' +\n",
    "    f'\\t{loss_func_name} : {np.mean(test_losses_1):.6f}\\n' +\n",
    "    f'\\tAccuracy : {(test_accuracy_1 * 100):>0.1f} %'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2. Example of classification (propagation through the setup)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.1. Select a sample to propagate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot an image\n",
    "# '1' - 3214, good\n",
    "# '4' - 6152, good\n",
    "# '6' - 123, good\n",
    "# '8' - 128, good\n",
    "# '0' - 3, good\n",
    "ind_test = 128\n",
    "cmap = 'hot'\n",
    "\n",
    "fig, axs = plt.subplots(1, 2, figsize=(2 * 3, 3))\n",
    "\n",
    "test_wavefront, test_target = mnist_wf_test_ds[ind_test]\n",
    "\n",
    "axs[0].set_title(f'intensity (id={ind_test})')\n",
    "axs[0].imshow(test_wavefront.intensity, cmap=cmap)\n",
    "\n",
    "axs[1].set_title(f'phase')\n",
    "axs[1].imshow(\n",
    "    test_wavefront.phase, cmap=cmap,\n",
    "    vmin=0, vmax=2 * torch.pi\n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# propagation of the example through the trained network\n",
    "ozcan_optical_setup_loaded.net.to(torch.device(\"cpu\"))\n",
    "setup_scheme, test_wavefronts = ozcan_optical_setup_loaded.stepwise_forward(test_wavefront)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.2. Amplitude profiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(setup_scheme)  # prints propagation scheme\n",
    "\n",
    "n_cols = 5  # number of columns to plot all wavefronts during propagation\n",
    "n_rows = (len(ozcan_optical_setup_loaded.net) // n_cols) + 1\n",
    "\n",
    "to_plot = 'amp'  # <--- chose what to plot\n",
    "cmap = 'grey'  # choose colormaps\n",
    "detector_cmap = 'hot'\n",
    "\n",
    "within_aperture = True  # if true plots only the field which is within apertures!\n",
    "\n",
    "# create a figure with subplots\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3.2))\n",
    "\n",
    "# turn off unecessary axes\n",
    "for ind_row in range(n_rows):\n",
    "    for ind_col in range(n_cols):\n",
    "        ax_this = axs[ind_row][ind_col]\n",
    "        if ind_row * n_cols + ind_col >= len(test_wavefronts):\n",
    "            ax_this.axis('off')\n",
    "\n",
    "# plot wavefronts\n",
    "for ind_wf, wavefront in enumerate(test_wavefronts):\n",
    "    ax_this = axs[ind_wf // n_cols][ind_wf % n_cols]\n",
    "\n",
    "    # delete unnecessary ticks\n",
    "    if not (ind_wf // n_cols) == n_rows - 1:\n",
    "        ax_this.set_xticks([])\n",
    "    if not (ind_wf % n_cols) == 0:\n",
    "        ax_this.set_yticks([])\n",
    "\n",
    "    if to_plot == 'phase':\n",
    "        # plot angle for each wavefront, because intensities pictures are indistinguishable from each other\n",
    "        if ind_wf < len(wavefronts) - 1:\n",
    "            ax_this.set_title('Phase for $WF_{' + f'{ind_wf}' + '}$')\n",
    "            ax_this.imshow(\n",
    "                wavefront.phase.detach().numpy(), cmap=cmap,\n",
    "                vmin=0, vmax=2 * torch.pi\n",
    "            )\n",
    "        else:  # (not a wavefront!)\n",
    "            ax_this.set_title('Detector phase ($WF_{' + f'{ind_wf}' + '})$')\n",
    "            # Detector has no phase!\n",
    "\n",
    "    if to_plot == 'amp':\n",
    "        # plot angle for each wavefront, because intensities pictures are indistinguishable from each other\n",
    "        if ind_wf < len(test_wavefronts) - 1:\n",
    "            ax_this.set_title('Intensity for $WF_{' + f'{ind_wf}' + '}$')\n",
    "            ax_this.imshow(\n",
    "                wavefront.intensity.detach().numpy(), cmap=cmap,\n",
    "                # vmin=0, vmax=max_intensity  # uncomment to make the same limits\n",
    "            )\n",
    "        else:  # Detector output (not a wavefront!)\n",
    "            ax_this.set_title('Detector Intensity ($WF_{' + f'{ind_wf}' + '})$')\n",
    "            ax_this.imshow(\n",
    "                wavefront.detach().numpy(), cmap=detector_cmap,\n",
    "                # vmin=0, vmax=max_intensity  # uncomment to make the same limits\n",
    "            )\n",
    "\n",
    "    # Comment: Detector output is Tensor! It has no methods of Wavefront (like .phase or .intensity)!\n",
    "    if within_aperture:\n",
    "        # select only a part within apertures!\n",
    "        x_frame = (x_layer_nodes - DETECTOR_SIZE[1]) / 2\n",
    "        y_frame = (y_layer_nodes - DETECTOR_SIZE[0]) / 2\n",
    "        ax_this.axis([x_frame, x_layer_nodes - x_frame, y_layer_nodes - y_frame, y_frame])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3. Detector picture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a figure with subplots\n",
    "fig, ax_this = plt.subplots(1, 1, figsize=(3, 3.2))\n",
    "\n",
    "# Detector output (not a wavefront!)\n",
    "ax_this.set_title('Detector Intensity')\n",
    "ax_this.imshow(\n",
    "    test_wavefronts[-1].detach().numpy(), cmap='hot',\n",
    "    # vmin=0, vmax=1  # uncomment to make the same limits\n",
    ")\n",
    "\n",
    "for zone in get_zones_patches(selected_detector_mask):\n",
    "    # add zone's patches to the axis\n",
    "    # zone_copy = copy(zone)\n",
    "    ax_this.add_patch(zone)\n",
    "\n",
    "# select only a part within apertures!\n",
    "x_frame = (x_layer_nodes - DETECTOR_SIZE[1]) / 2\n",
    "y_frame = (y_layer_nodes - DETECTOR_SIZE[0]) / 2\n",
    "plt.axis([x_frame, x_layer_nodes - x_frame, y_layer_nodes - y_frame, y_frame])\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get probabilities of an example classification\n",
    "if detector_processor:\n",
    "    test_probas = detector_processor.forward(test_wavefronts[-1])\n",
    "    # Comment: forward() method is from DetectorProcessorClf\n",
    "    #          p_i = I(detector_i) / sum_j(I(detector_j))\n",
    "\n",
    "    assert np.isclose(test_probas.sum().item(), 1)\n",
    "\n",
    "    for label, prob in enumerate(test_probas[0]):\n",
    "        print(f'{label} : {prob * 100:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3. Energy _efficiency_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.1. Predict all Test dataset and save all results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_test_lst = []\n",
    "preds_test_lst = []\n",
    "\n",
    "detector_sums_by_classes = [\n",
    "    torch.zeros(size=SIM_PARAMS.axes_size(axs=('H', 'W'))) for _ in range(number_of_classes)\n",
    "]\n",
    "samples_by_classes = [0 for _ in range(number_of_classes)]\n",
    "probas_sums_by_classes = [\n",
    "    torch.zeros(number_of_classes) for _ in range(number_of_classes)\n",
    "]\n",
    "\n",
    "# loop over the test dataset\n",
    "for ind, (wavefront_this, target_this) in enumerate(tqdm(mnist_wf_test_ds)):\n",
    "    ozcan_optical_setup_loaded.net.eval()\n",
    "\n",
    "    batch_wavefronts = torch.unsqueeze(wavefront_this, 0)\n",
    "    batch_targets = torch.unsqueeze(torch.tensor(target_this), 0)  # to use forwards for batches\n",
    "\n",
    "    batch_labels = detector_processor.batch_forward(batch_targets).argmax(1)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        detector_output = ozcan_optical_setup_loaded.net(batch_wavefronts)\n",
    "        # process a detector image\n",
    "        batch_probas = detector_processor.batch_forward(detector_output)\n",
    "\n",
    "        for ind_in_batch in range(batch_labels.size()[0]):\n",
    "            label_this = batch_labels[ind_in_batch].item()  # true label\n",
    "            targets_test_lst.append(label_this)\n",
    "\n",
    "            detector_sums_by_classes[label_this] += detector_output[ind_in_batch]\n",
    "            probas_sums_by_classes[label_this] += batch_probas[ind_in_batch]\n",
    "            samples_by_classes[label_this] += 1\n",
    "\n",
    "            preds_test_lst.append(batch_probas[ind_in_batch].argmax().item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.2. Confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for class_ind in range(number_of_classes):\n",
    "    probas_sums_by_classes[class_ind] /= samples_by_classes[class_ind]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_probas_mat = torch.zeros(size=(number_of_classes, number_of_classes))\n",
    "\n",
    "for ind_class in range(number_of_classes):\n",
    "    avg_probas_mat[ind_class, :] = probas_sums_by_classes[ind_class]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ordinary confusion matrix\n",
    "confusion_matrix = torch.zeros(size=(number_of_classes, number_of_classes), dtype=torch.int32)\n",
    "\n",
    "for ind in range(len(mnist_wf_test_ds)):\n",
    "    confusion_matrix[targets_test_lst[ind], preds_test_lst[ind]] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "# CONFUSION MATRIX\n",
    "ax0.set_title('Confusion matrix')\n",
    "ax0.matshow(confusion_matrix, cmap='Blues')\n",
    "\n",
    "for i in range(number_of_classes):\n",
    "    for j in range(number_of_classes):\n",
    "        val = confusion_matrix[j, i].item()\n",
    "        ax0.text(\n",
    "            i, j, str(val),\n",
    "            va='center', ha='center',\n",
    "            c='k', fontsize=9\n",
    "        )\n",
    "\n",
    "ax0.set_ylabel('Target')\n",
    "ax0.set_xlabel('Predicted')\n",
    "\n",
    "ax0.set_xticks(range(number_of_classes))\n",
    "ax0.set_yticks(range(number_of_classes))\n",
    "\n",
    "# AVERAGED PREDICTED PROBAS\n",
    "ax1.set_title('Averaged confidences')\n",
    "ax1.matshow(avg_probas_mat, cmap='Greens')\n",
    "\n",
    "for i in range(number_of_classes):\n",
    "    for j in range(number_of_classes):\n",
    "        val = avg_probas_mat[j, i].item()\n",
    "        ax1.text(\n",
    "            i, j, f'{val:.1f}',\n",
    "            va='center', ha='center',\n",
    "            c='k', fontsize=9\n",
    "        )\n",
    "\n",
    "ax1.set_xlabel(r'$\\sum I_i / \\left( \\sum I_0 + \\dots + \\sum I_9 \\right)$')\n",
    "\n",
    "ax1.set_xticks(range(number_of_classes))\n",
    "ax1.set_yticks(range(number_of_classes))\n",
    "# ax1.set_yticks(range(number_of_classes), labels=['' for _ in range(number_of_classes)])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# save figure\n",
    "# fig.savefig(f'{RESULTS_FOLDER}/confusion_matrix.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.3.3. Averaged detector for a selected class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_cols = 5  # number of columns to plot all wavefronts during propagation\n",
    "n_rows = (number_of_classes // n_cols)\n",
    "\n",
    "detector_cmap = 'hot'\n",
    "\n",
    "# create a figure with subplots\n",
    "fig, axs = plt.subplots(n_rows, n_cols, figsize=(n_cols * 3, n_rows * 3))\n",
    "\n",
    "# turn off unecessary axes\n",
    "for ind_row in range(n_rows):\n",
    "    for ind_col in range(n_cols):\n",
    "        ax_this = axs[ind_row][ind_col]\n",
    "        if ind_row * n_cols + ind_col >= number_of_classes:\n",
    "            ax_this.axis('off')\n",
    "\n",
    "# plot wavefronts\n",
    "for selected_class in range(number_of_classes):\n",
    "    ax_this = axs[selected_class // n_cols][selected_class % n_cols]\n",
    "\n",
    "    # focus \"efficiency\"\n",
    "    int_over_detector_zones = 0\n",
    "\n",
    "    for ind_class in range(number_of_classes):\n",
    "        int_over_detector_zones += detector_processor.batch_zone_integral(\n",
    "            detector_sums_by_classes[selected_class].unsqueeze(0).unsqueeze(0),\n",
    "            ind_class=ind_class,\n",
    "        )[0].item()\n",
    "\n",
    "    detector_int = detector_sums_by_classes[selected_class].sum().item()\n",
    "    detector_efficiency = int_over_detector_zones / detector_int\n",
    "\n",
    "    # Detector output (not a wavefront!)\n",
    "    ax_this.set_title(\n",
    "        f'`{selected_class}`: ' + r'$E_{zones}\\approx$' +\n",
    "        f'{detector_efficiency * 100:.2f} %'\n",
    "    )\n",
    "    ax_this.imshow(\n",
    "        detector_sums_by_classes[selected_class] / samples_by_classes[selected_class],\n",
    "        cmap=detector_cmap,\n",
    "        # vmin=0, vmax=0.02  # uncomment to make the same limits\n",
    "    )\n",
    "\n",
    "    for zone in get_zones_patches(selected_detector_mask):\n",
    "        # add zone's patches to the axis\n",
    "        # zone_copy = copy(zone)\n",
    "        ax_this.add_patch(zone)\n",
    "\n",
    "    ax_this.set_xticks([])\n",
    "    ax_this.set_yticks([])\n",
    "\n",
    "    # select only a part within apertures!\n",
    "    x_frame = (x_layer_nodes - DETECTOR_SIZE[1]) / 2\n",
    "    y_frame = (y_layer_nodes - DETECTOR_SIZE[0]) / 2\n",
    "    ax_this.axis([x_frame, x_layer_nodes - x_frame, y_layer_nodes - y_frame, y_frame])\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# save figure\n",
    "# fig.savefig(f'{RESULTS_FOLDER}/averaged_detector_for_classes.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.6.3. Detector _efficiency_\n",
    "\n",
    "$$\n",
    "\\frac{\\sum\\limits_{\\text{class}=0}^9 \\left( \\iint\\limits_{S_\\text{class}} I(x,y) \\right)}{\\iint\\limits_{S_\\text{detector}} I(x,y)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_efficiency_by_classes = {}\n",
    "\n",
    "for selected_class in range(number_of_classes):\n",
    "    int_over_detector_zones = 0\n",
    "\n",
    "    for ind_class in range(number_of_classes):\n",
    "        int_over_detector_zones += detector_processor.batch_zone_integral(\n",
    "            detector_sums_by_classes[selected_class].unsqueeze(0).unsqueeze(0),\n",
    "            ind_class=ind_class,\n",
    "        )[0].item()\n",
    "\n",
    "    detector_int = detector_sums_by_classes[selected_class].sum().item()\n",
    "    detector_efficiency_by_classes[selected_class] = int_over_detector_zones / detector_int"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detector_efficiency_by_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
